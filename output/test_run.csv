ID,date,title,author,link,journal,comments,primary_cat,all_cat,abstract
1809.04768,2018-09-13 04:42:37,Deep Learning for Waveform Estimation and Imaging in Passive Radar,"Bariscan Yonel,Eric Mason,Birsen Yazici",https://arxiv.org/abs/1809.04768,    ,"21 pages, submitted to IET Journal of Radar, Sonar and Navigation Special Issue on Passive High Resolution and Imaging Radar",eess.SP,eess.SP,"We consider a bistatic configuration with a stationary transmitter transmitting unknown waveforms of opportunity and a moving receiver, and present a Deep Learning (DL) framework for passive synthetic aperture radar (SAR) imaging. Existing passive radar methods require two or more antennas which are either spatially separated or colocated with sufficient directivity to estimate the underlying waveform prior to imaging. Our approach to passive radar only requires a single receiver, hence reduces cost and increases versatility. We approach DL from an optimization perspective and formulate image reconstruction as a  machine learning  task. By unfolding the iterations of a proximal gradient descent algorithm, we construct a deep recurrent neural network (RNN) that is parameterized by transmitted waveforms. We cascade the RNN structure with a decoder stage to form a recurrent-auto encoder architecture. We then utilize backpropagation to learn transmitted waveforms by training the network in an unsupervised manner using SAR measurements. The highly non-convex problem of backpropagation is guided to a feasible solution over the parameter space by initializing the network with the known components of the SAR forward model. Moreover, prior information regarding the waveform structure is incorporated during initialization and backpropagation. We demonstrate the effectiveness of the DL-based approach through extensive numerical simulations that show focused, high contrast imagery using a single receiver antenna at realistic SNR levels."
1809.04598,2018-09-12 18:00:01,Bayesian sparse reconstruction: a brute-force approach to astronomical imaging and,"Edward Higson,Will Handley,Michael Hobson,Anthony Lasenby",https://arxiv.org/abs/1809.04598,    ,"16 pages + appendix, 19 figures",astro-ph.IM,"astro-ph.IM,stat.ME,stat.ML","We present a principled Bayesian framework for signal reconstruction, in which the signal is modelled by basis functions whose number (and form, if required) is determined by the data themselves. This approach is based on a Bayesian interpretation of conventional sparse reconstruction and regularisation techniques, in which sparsity is imposed through priors via Bayesian model selection. We demonstrate our method for noisy 1- and 2-dimensional signals, including astronomical images. Furthermore, by using a product-space approach, the number and type of basis functions can be treated as integer parameters and their posterior distributions sampled directly. We show that order-of-magnitude increases in computational efficiency are possible from this technique compared to calculating the Bayesian evidences separately, and that further computational gains are possible using it in combination with dynamic nested sampling. Our approach can be readily applied to neural networks, where it allows the network architecture to be determined by the data in a principled Bayesian manner by treating the number of nodes and hidden layers as parameters."
1809.04758,2018-09-13 03:54:22,Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series,"Dan Li,Dacheng Chen,Jonathan Goh,See-kiong Ng",https://arxiv.org/abs/1809.04758,    ,"This paper is accepted by the 7th International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications on the ACM Knowledge Discovery and Data Mining conference, August 2018, London, United Kingdom",cs.LG,"cs.LG,stat.ML","Today's Cyber-Physical Systems (CPSs) are large, complex, and affixed with networked sensors and actuators that are targets for cyber-attacks. Conventional detection techniques are unable to deal with the increasingly dynamic and complex nature of the CPSs. On the other hand, the networked sensors and actuators generate large amounts of data streams that can be continuously monitored for intrusion events. Unsupervised  machine learning  techniques can be used to model the system behaviour and classify deviant behaviours as possible attacks. In this work, we proposed a novel Generative Adversarial Networks-based Anomaly Detection (GAN-AD) method for such complex networked CPSs. We used LSTM-RNN in our GAN to capture the distribution of the multivariate time series of the sensors and actuators under normal working conditions of a CPS. Instead of treating each sensor's and actuator's time series independently, we model the time series of multiple sensors and actuators in the CPS concurrently to take into account of potential latent interactions between them. To exploit both the generator and the discriminator of our GAN, we deployed the GAN-trained discriminator together with the residuals between generator-reconstructed data and the actual samples to detect possible anomalies in the complex CPS. We used our GAN-AD to distinguish abnormal attacked situations from normal working conditions for a complex six-stage Secure Water Treatment (SWaT) system. Experimental results showed that the proposed strategy is effective in identifying anomalies caused by various attacks with high detection rate and low false positive rate as compared to existing methods."
1809.04684,2018-09-12 21:29:20,Fair lending needs explainable models for responsible recommendation,Jiahao Chen,https://arxiv.org/abs/1809.04684,"          J.1; I.5.1
        
      ","4 pages, position paper accepted for FATREC 2018 conference at ACM RecSys",cs.LG,"cs.LG,cs.AI,cs.CY,stat.AP,stat.ML",The financial services industry has unique explainability and fairness challenges arising from compliance and ethical considerations in credit decisioning. These challenges complicate the use of model  machine learning  and artificial intelligence methods in business decision processes.
1809.04680,2018-09-12 21:23:40,Near-deterministic production of universal quantum photonic gates enhanced by,"Krishna Kumar Sabapathy,Haoyu Qi,Josh Izaac,Christian Weedbrook",https://arxiv.org/abs/1809.04680,    ,"11 pages (6+supp), 9 figs",quant-ph,"quant-ph,physics.optics","We introduce architectures for near-deterministic implementation of fully tunable weak cubic phase gates requisite for universal quantum computation. The first step is to produce a resource state which is a superposition of the first four Fock states with a probability $\geq 10^{-2}$, an increase by a factor of $10^4$ over standard sequential photon-subtraction techniques. The resource state is produced from a quantum gadget that uses displaced squeezed states, interferometers and photon-number resolving detectors. The parameters of this gadget are trained using  machine learning  algorithms for variational circuits. Stacking these gadgets in parallel we build quantum resource farms in a scalable manner depending on the error tolerance. Using conventional teleportation techniques we can implement weak cubic phase gates, in principle, at a rate $\sim {\rm 100 kHz}$ dictated by the photon number resolving detectors. Our proposal is realizable with current photonic technologies without the need for quantum memories. The methods for non-Gaussian state preparation is of independent interest to the resource theory of non-Gaussianity."
1809.04737,2018-09-13 01:56:57,"Fairness-aware Classification: Criterion, Convexity, and Bounds","Yongkai Wu,Lu Zhang,Xintao Wu",https://arxiv.org/abs/1809.04737,,,cs.LG,"cs.LG,cs.AI,cs.CY,stat.ML","Fairness-aware classification is receiving increasing attention in the  machine learning  fields. Recently research proposes to formulate the fairness-aware classification as constrained optimization problems. However, several limitations exist in previous works due to the lack of a theoretical framework for guiding the formulation. In this paper, we propose a general framework for learning fair classifiers which addresses previous limitations. The framework formulates various commonly-used fairness metrics as convex constraints that can be directly incorporated into classic classification models. Within the framework, we propose a constraint-free criterion on the training data which ensures that any classifier learned from the data is fair. We also derive the constraints which ensure that the real fairness metric is satisfied when surrogate functions are used to achieve convexity. Our framework can be used to for formulating fairness-aware classification with fairness guarantee and computational efficiency. The experiments using real-world datasets demonstrate our theoretical results and show the effectiveness of proposed framework and methods."
1809.04621,2018-09-12 18:14:12,A Two-Step Learning Method For Detecting Landmarks on Faces From Different Domains,"Bruna Vieira Frade,Erickson R. Nascimento",https://arxiv.org/abs/1809.04621,    ,https://ieeexplore.ieee.org/document/8451026/,cs.CV,"cs.CV,cs.LG","The detection of fiducial points on faces has significantly been favored by the rapid progress in the field of  machine learning , in particular in the convolution networks. However, the accuracy of most of the detectors strongly depends on an enormous amount of annotated data. In this work, we present a domain adaptation approach based on a two-step learning to detect fiducial points on human and animal faces. We evaluate our method on three different datasets composed of different animal faces (cats, dogs, and horses). The experiments show that our method performs better than state of the art and can use few annotated data to leverage the detection of landmarks reducing the demand for large volume of annotated data."
1809.04750,2018-09-13 02:53:46,Important descriptors and descriptor groups of Curie temperatures of rare-earth transition-metal binary alloys,"Hieu Chi Dam,Viet Cuong Nguyen,Tien Lam Pham,Anh Tuan Nguyen,Kiyoyuki Terakura,Takashi Miyake,Hiori Kino",https://arxiv.org/abs/1809.04750,    ,"5 pages, 2 figures",cond-mat.mtrl-sci,cond-mat.mtrl-sci,"We analyze Curie temperatures of rare-earth transition metal binary alloys with  machine learning  method. In order to select important descriptors and descriptor groups, we introduce newly developed subgroup relevance analysis and adopt the hierarchical clustering in the representation. We execute the exhaustive search and successfully illustrate the importance of descriptors and descriptor groups. We execute the exhaustive search and illustrate that our approach indeed leads to the successful selection of important descriptors and descriptor groups. It helps us to choose the combination of the descriptors and to understand the meaning of the selected combination of descriptors."
1809.04673,2018-09-12 21:01:55,A Unified Batch Online Learning Framework for Click Prediction,"Rishabh Iyer,Nimit Acharya,Tanuja Bompada,Denis Charles,Eren Manavoglu",https://arxiv.org/abs/1809.04673,,,cs.LG,"cs.LG,cs.AI,stat.ML","We present a unified framework for Batch Online Learning (OL) for Click Prediction in Search Advertisement.  machine learning  models once deployed, show non-trivial accuracy and calibration degradation over time due to model staleness. It is therefore necessary to regularly update models, and do so automatically. This paper presents two paradigms of Batch Online Learning, one which incrementally updates the model parameters via an early stopping mechanism, and another which does so through a proximal regularization. We argue how both these schemes naturally trade-off between old and new data. We then theoretically and empirically show that these two seemingly different schemes are closely related. Through extensive experiments, we demonstrate the utility of of our OL framework; how the two OL schemes relate to each other and how they trade-off between the new and historical data. We then compare batch OL to full model retrains, and show how online learning is more robust to data issues. We also demonstrate the long term impact of Online Learning, the role of the initial Models in OL, the impact of delays in the update, and finally conclude with some implementation details and challenges in deploying a real world online learning system in production. While this paper mostly focuses on application of click prediction for search advertisement, we hope that the lessons learned here can be carried over to other problem domains."
1809.04679,2018-09-12 21:16:38,Supervised,"S. Pilati,P. Pieri",https://arxiv.org/abs/1809.04679,    ,"9 pages, 8 figures",cond-mat.quant-gas,"cond-mat.quant-gas,physics.comp-ph","We analyze how accurately supervised  machine learning  techniques can predict the lowest energy levels of one-dimensional noninteracting ultracold atoms subject to the correlated disorder due to an optical speckle field. Deep neural networks with different numbers of hidden layers and neurons per layer are trained on large sets of instances of the speckle field, whose energy levels have been preventively determined via a high-order finite difference technique. The Fourier components of the speckle field are used as feature vector to represent the speckle-field instances. A comprehensive analysis of the details that determine the possible success of supervised  machine learning  tasks, namely the depth and the width of the neural network, the size of the training set, and the magnitude of the regularization parameter, is presented. It is found that ground state energies of previously unseen instances can be predicted with essentially arbitrary accuracy. First and second excited state energies can be predicted too, albeit with slightly lower accuracy and using more layers of hidden neurons."
1809.04676,2018-09-12 21:09:19,Improved Basic Block Reordering,"Andy Newell,Sergey Pupyrev",https://arxiv.org/abs/1809.04676,,,cs.PL,cs.PL,"Basic block reordering is an important step for profile-guided binary optimization. The state-of-the-art for basic block reordering is to maximize the number of fall-through branches. However, we demonstrate that such orderings may impose suboptimal performance on instruction and I-TLB caches. We propose a new algorithm that relies on a model combining the effects of fall-through and caching behavior. As details of modern processor caching is quite complex and often unknown, we show how to use  machine learning  in selecting parameters that best trade off different caching effects to maximize binary performance.
  An extensive evaluation on a variety of applications, including Facebook production workloads, the open-source compiler Clang, and SPEC CPU 2006 benchmarks, indicate that the new method outperforms existing block reordering techniques, improving the resulting performance of large-scale data-center applications. We have open sourced the code of the new algorithm as a part of a post-link binary optimization tool, BOLT."
1809.04547,2018-09-12 16:34:44,Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization with Medical Applications,"Geir Thore Berge,Ole-Christoffer Granmo,Tor Oddbjørn Tveit,Morten Goodwin,Lei Jiao,Bernt Viggo Matheussen",https://arxiv.org/abs/1809.04547,    ,"9 pages, 4 figures",cs.LG,"cs.LG,stat.ML","Medical applications challenge today's text categorization techniques by demanding both high accuracy and ease-of-interpretation. Although deep learning has provided a leap ahead in accuracy, this leap comes at the sacrifice of interpretability. To address this accuracy-interpretability challenge, we here introduce, for the first time, a text categorization approach that leverages the recently introduced Tsetlin Machine. In all brevity, we represent the terms of a text as propositional variables. From these, we capture categories using simple propositional formulae, such as: if ""rash"" and ""reaction"" and ""penicillin"" then Allergy. The Tsetlin  machine learning  these formulae from a labelled text, utilizing conjunctive clauses to represent the particular facets of each category. Indeed, even the absence of terms (negated features) can be used for categorization purposes. Our empirical results are quite conclusive. The Tsetlin Machine either performs on par with or outperforms all of the evaluated methods on both the 20 Newsgroups and IMDb datasets, as well as on a non-public clinical dataset. On average, the Tsetlin Machine delivers the best recall and precision scores across the datasets. The GPU implementation of the Tsetlin Machine is further 8 times faster than the GPU implementation of the neural network. We thus believe that our novel approach can have a significant impact on a wide range of text analysis applications, forming a promising starting point for deeper natural language understanding with the Tsetlin Machine."
1809.04559,2018-09-12 16:51:18,Benchmarking and Optimization of Gradient Boosted Decision Tree Algorithms,"Andreea Anghel,Nikolaos Papandreou,Thomas Parnell,Alessandro De Palma,Haralampos Pozidis",https://arxiv.org/abs/1809.04559,    ,8 pages,cs.LG,"cs.LG,stat.ML","Gradient boosted decision trees (GBDTs) have seen widespread adoption in academia, industry and competitive data science due to their state-of-the-art performance in a wide variety of  machine learning  tasks. In this paper, we present an extensive empirical comparison of XGBoost, LightGBM and CatBoost, three popular GBDT algorithms, to aid the data science practitioner in the choice from the multitude of available implementations. Specifically, we evaluate their behavior on four large-scale datasets with varying shapes, sparsities and learning tasks, in order to evaluate the algorithms' generalization performance, training times (on both CPU and GPU) and their sensitivity to hyper-parameter tuning. In our analysis, we first make use of a distributed grid-search to benchmark the algorithms on fixed configurations, and then employ a state-of-the-art algorithm for Bayesian hyper-parameter optimization to fine-tune the models."
1809.04570,2018-09-12 17:24:49,FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks,"Michaela Blott,Thomas Preusser,Nicholas Fraser,Giulio Gambardella,Kenneth O'Brien,Yaman Umuroglu",https://arxiv.org/abs/1809.04570,    ,to be published in ACM TRETS Special Edition on Deep Learning,cs.AR,cs.AR,"Convolutional Neural Networks have rapidly become the most successful  machine learning  algorithm, enabling ubiquitous machine vision and intelligent decisions on even embedded computing-systems. While the underlying arithmetic is structurally simple, compute and memory requirements are challenging. One of the promising opportunities is leveraging reduced-precision representations for inputs, activations and model parameters. The resulting scalability in performance, power efficiency and storage footprint provides interesting design compromises in exchange for a small reduction in accuracy. FPGAs are ideal for exploiting low-precision inference engines leveraging custom precisions to achieve the required numerical accuracy for a given application. In this article, we describe the second generation of the FINN framework, an end-to-end tool which enables design space exploration and automates the creation of fully customized inference engines on FPGAs. Given a neural network description, the tool optimizes for given platforms, design targets and a specific precision. We introduce formalizations of resource cost functions and performance predictions, and elaborate on the optimization algorithms. Finally, we evaluate a selection of reduced precision neural networks ranging from CIFAR-10 classifiers to YOLO-based object detection on a range of platforms including PYNQ and AWS\,F1, demonstrating new unprecedented measured throughput at 50TOp/s on AWS-F1 and 5TOp/s on embedded devices."
1809.04578,2018-09-12 17:40:18,"Simplicity Creates Inequity: Implications for Fairness, Stereotypes, and Interpretability","Jon Kleinberg,Sendhil Mullainathan",https://arxiv.org/abs/1809.04578,,,cs.LG,"cs.LG,cs.CY,cs.DS,cs.SI,stat.ML","Algorithmic predictions are increasingly used to aid, or in some cases supplant, human decision-making, and this development has placed new demands on the outputs of  machine learning  procedures. To facilitate human interaction, we desire that they output prediction functions that are in some fashion simple or interpretable. And because they influence consequential decisions, we also desire equitable prediction functions, ones whose allocations benefit (or at the least do not harm) disadvantaged groups.
  We develop a formal model to explore the relationship between simplicity and equity. Although the two concepts appear to be motivated by qualitatively distinct goals, our main result shows a fundamental inconsistency between them. Specifically, we formalize a general framework for producing simple prediction functions, and in this framework we show that every simple prediction function is strictly improvable: there exists a more complex prediction function that is both strictly more efficient and also strictly more equitable. Put another way, using a simple prediction function both reduces utility for disadvantaged groups and reduces overall welfare. Our result is not only about algorithms but about any process that produces simple models, and as such connects to the psychology of stereotypes and to an earlier economics literature on statistical discrimination."
1809.04564,2018-09-12 17:02:08,On the Stability and Convergence of Stochastic Gradient Descent with Momentum,"Ali Ramezani-Kebrya,Ashish Khisti,Ben Liang",https://arxiv.org/abs/1809.04564,,,cs.LG,"cs.LG,stat.ML","While momentum-based methods, in conjunction with the stochastic gradient descent, are widely used when training  machine learning  models, there is little theoretical understanding on the generalization error of such methods. In practice, the momentum parameter is often chosen in a heuristic fashion with little theoretical guidance. In the first part of this paper, for the case of general loss functions, we analyze a modified momentum-based update rule, i.e., the method of early momentum, and develop an upper-bound on the generalization error using the framework of algorithmic stability. Our results show that  machine learning  models can be trained for multiple epochs of this method while their generalization errors are bounded. We also study the convergence of the method of early momentum by establishing an upper-bound on the expected norm of the gradient. In the second part of the paper, we focus on the case of strongly convex loss functions and the classical heavy-ball momentum update rule. We use the framework of algorithmic stability to provide an upper-bound on the generalization error of the stochastic gradient method with momentum. We also develop an upper-bound on the expected true risk, in terms of the number of training steps, the size of the training set, and the momentum parameter. Experimental evaluations verify the consistency between the numerical results and our theoretical bounds and the effectiveness of the method of early momentum for the case of non-convex loss functions."
1809.03267,2018-09-07 09:31:52,Feature Learning for Meta-Paths in Knowledge Graphs,Sebastian Bischoff,https://arxiv.org/abs/1809.03267,    ,Bachelor's Thesis,cs.LG,"cs.LG,cs.SI,stat.ML","In this thesis, we study the problem of feature learning on heterogeneous knowledge graphs. These features can be used to perform tasks such as link prediction, classification and clustering on graphs. Knowledge graphs provide rich semantics encoded in the edge and node types. Meta-paths consist of these types and abstract paths in the graph. Until now, meta-paths can only be used as categorical features with high redundancy and are therefore unsuitable for  machine learning  models. We propose meta-path embeddings to solve this problem by learning semantical and compact vector representations of them. Current graph embedding methods only embed nodes and edge types and therefore miss semantics encoded in the combination of them. Our method embeds meta-paths using the skipgram model with an extension to deal with the redundancy and high amount of meta-paths in big knowledge graphs. We critically evaluate our embedding approach by predicting links on Wikidata. The experiments indicate that we learn a sensible embedding of the meta-paths but can improve it further."
1809.03359,2018-09-10 14:41:17,Improving Optimization Bounds using,"Quentin Cappart,Emmanuel Goutierre,David Bergman,Louis-Martin Rousseau",https://arxiv.org/abs/1809.03359,,,cs.AI,cs.AI,"Finding tight bounds on the optimal solution is a critical element of practical solution methods for discrete optimization problems. In the last decade, decision diagrams (DDs) have brought a new perspective on obtaining upper and lower bounds that can be significantly better than classical bounding mechanisms, such as linear relaxations. It is well known that the quality of the bound achieved through this flexible bounding method is highly reliant on the ordering of variables chosen for building the diagram, and finding an ordering that optimizes standard metrics, or even improving one, is an NP-hard problem. In this paper, we propose an innovative and generic approach based on deep reinforcement learning for obtaining an ordering for tightening the bounds obtained with relaxed and restricted DDs. We apply the approach to both the Maximum Independent Set Problem and the Maximum Cut Problem. Experimental results on synthetic instances show that the deep reinforcement learning approach, by achieving tighter objective function bounds, generally outperforms ordering methods commonly used in the literature when the distribution of instances is known. To the best knowledge of the authors, this is the first paper to apply  machine learning  to directly improve relaxation bounds obtained by general-purpose bounding mechanisms for combinatorial optimization problems."
1809.03276,2018-09-10 12:47:59,Grasp success prediction with quality metrics,"Carlos Rubert,Daniel Kappler,Jeannette Bohg,Antonio Morales",https://arxiv.org/abs/1809.03276,,,cs.RO,cs.RO,"Current robotic manipulation requires reliable methods to predict whether a certain grasp on an object will be successful or not prior to its execution. Different methods and metrics have been developed for this purpose but there is still work to do to provide a robust solution.
  In this article we combine different metrics to evaluate real grasp executions. We use different  machine learning  algorithms to train a classifier able to predict the success of candidate grasps. Our experiments are performed with two different robotic grippers and different objects. Grasp candidates are evaluated in both simulation and real world.
  We consider 3 different categories to label grasp executions: robust, fragile and futile. Our results shows the proposed prediction model has success rate of 76\%."
1809.03272,2018-09-10 12:36:05,Privacy-Preserving Deep Learning for any Activation Function,"Le Trieu Phong,Tran Thi Phuong",https://arxiv.org/abs/1809.03272,"          68P25; 94A60
        

        
      ",,cs.LG,"cs.LG,cs.AI,cs.CR,stat.ML","This paper considers the scenario that multiple data owners wish to apply a  machine learning  method over the combined dataset of all owners to obtain the best possible learning output but do not want to share the local datasets owing to privacy concerns. We design systems for the scenario that the stochastic gradient descent (SGD) algorithm is used as the  machine learning  method because SGD (or its variants) is at the heart of recent deep learning techniques over neural networks. Our systems differ from existing systems in the following features: {\bf (1)} any activation function can be used, meaning that no privacy-preserving-friendly approximation is required; {\bf (2)} gradients computed by SGD are not shared but the weight parameters are shared instead; and {\bf (3)} robustness against colluding parties even in the extreme case that only one honest party exists. We prove that our systems, while privacy-preserving, achieve the same learning accuracy as SGD and hence retain the merit of deep learning with respect to accuracy. Finally, we conduct several experiments using benchmark datasets, and show that our systems outperform previous system in terms of learning accuracies."
1809.03299,2018-09-10 13:31:02,Monte Carlo Tree Search for Verifying Reachability in Markov Decision Processes,"Pranav Ashok,Tomáš Brázdil,Jan Křetínský,Ondřej Slámečka",https://arxiv.org/abs/1809.03299,,,cs.LO,cs.LO,"The maximum reachability probabilities in a Markov decision process can be computed using value iteration (VI). Recently, simulation-based heuristic extensions of VI have been introduced, such as bounded real-time dynamic programming (BRTDP), which often manage to avoid explicit analysis of the whole state space while preserving guarantees on the computed result. In this paper, we introduce a new class of such heuristics, based on Monte Carlo tree search (MCTS), a technique celebrated in various  -  settings. We provide a spectrum of algorithms ranging from MCTS to BRTDP. We evaluate these techniques and show that for larger examples, where VI is no more applicable, our techniques are more broadly applicable than BRTDP with only a minor additional overhead."
1809.03137,2018-09-10 04:59:25,Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers,"Zhen He,Jian Li,Daxue Liu,Hangen He,David Barber",https://arxiv.org/abs/1809.03137,    ,Submitted to AAAI 2019,cs.CV,"cs.CV,cs.LG,stat.ML","Online Multi-Object Tracking (MOT) from videos is a challenging computer vision task which has been extensively studied for decades. Most of the existing MOT algorithms are based on the Tracking-by-Detection (TBD) paradigm combined with popular  machine learning  approaches which largely reduce the human effort to tune algorithm parameters. However, the commonly used supervised learning approaches require the labeled data (e.g., bounding boxes), which is expensive for videos. Also, the TBD framework is usually suboptimal since it is not end-to-end, i.e., it considers the task as detection and tracking, but not jointly. To achieve both label-free and end-to-end learning of MOT, we propose a Tracking-by-Animation framework, where a differentiable neural model first tracks objects from input frames and then animates these objects into reconstructed frames. Learning is then driven by the reconstruction error through backpropagation. We further propose a Reprioritized Attentive Tracking to improve the robustness of data association. Experiments conducted on both synthetic and real video datasets show the potential of the proposed model."
1809.03378,2018-09-10 14:56:05,,"Yiwei Sun,Zhen Gao,Hua Wang,Di Wu",https://arxiv.org/abs/1809.03378,    ,This paper has been accepted by 2018 GLOBECOM workshop,cs.IT,cs.IT,"Hybrid precoding design can be challenging for broadband millimeter-wave (mmWave) massive MIMO due to the frequency-flat analog precoder in radio frequency (RF). Prior broadband hybrid precoding work usually focuses on fully-connected array (FCA), while seldom considers the energy-efficient partially-connected subarray (PCS) including the fixed subarray (FS) and dynamic subarray (DS). Against this background, this paper proposes a  machine learning  based broadband hybrid precoding for mmWave massive MIMO with DS. Specifically, we first propose an optimal hybrid precoder based on principal component analysis (PCA) for the FS, whereby the frequency-flat RF precoder for each subarray is extracted from the principle component of the optimal frequency-selective precoders for fully-digital MIMO. Moreover, we extend the PCA-based hybrid precoding to DS, where a shared agglomerative hierarchical clustering (AHC) algorithm developed from  machine learning  is proposed to group the DS for improved spectral efficiency (SE). Finally, we investigate the energy efficiency (EE) of the proposed scheme for both passive and active antennas. Simulations have confirmed that the proposed scheme outperforms conventional schemes in both SE and EE."
1809.03538,2018-09-10 18:31:53,Convolutional Graph Auto-encoder: A Deep Generative Neural Architecture for Probabilistic Spatio-temporal Solar Irradiance Forecasting,"Mahdi Khodayar,Saeed Mohammadi,Mohammad Khodayar,Jianhui Wang,Guangyi Liu",https://arxiv.org/abs/1809.03538,    ,"8 pages, 11 figures",cs.LG,"cs.LG,stat.ML","machine learning  on graph-structured data is an important and omnipresent task for a vast variety of applications including anomaly detection and dynamic network analysis. In this paper, a deep generative model is introduced to capture continuous probability densities corresponding to the nodes of an arbitrary graph. In contrast to all learning formulations in the area of discriminative pattern recognition, we propose a scalable generative optimization/algorithm theoretically proved to capture distributions at the nodes of a graph. Our model is able to generate samples from the probability densities learned at each node. This probabilistic data generation model, i.e. convolutional graph auto-encoder (CGAE), is devised based on the localized first-order approximation of spectral graph convolutions, deep learning, and the variational Bayesian inference. We apply our CGAE to a new problem, the spatio-temporal probabilistic solar irradiance prediction. Multiple solar radiation measurement sites in a wide area in northern states of the US are modeled as an undirected graph. Using our proposed model, the distribution of future irradiance given historical radiation observations is estimated for every site/node. Numerical results on the National Solar Radiation Database show state-of-the-art performance for probabilistic radiation prediction on geographically distributed irradiance data in terms of reliability, sharpness, and continuous ranked probability score."
1809.03559,2018-09-10 19:28:57,Deep Learning Towards Mobile Applications,"Ji Wang,Bokai Cao,Philip S. Yu,Lichao Sun,Weidong Bao,Xiaomin Zhu",https://arxiv.org/abs/1809.03559,    ,Conference version accepted by ICDCS'18,cs.LG,"cs.LG,cs.AI,cs.DC","Recent years have witnessed an explosive growth of mobile devices. Mobile devices are permeating every aspect of our daily lives. With the increasing usage of mobile devices and intelligent applications, there is a soaring demand for mobile applications with  machine learning  services. Inspired by the tremendous success achieved by deep learning in many  machine learning  tasks, it becomes a natural trend to push deep learning towards mobile applications. However, there exist many challenges to realize deep learning in mobile applications, including the contradiction between the miniature nature of mobile devices and the resource requirement of deep neural networks, the privacy and security concerns about individuals' data, and so on. To resolve these challenges, during the past few years, great leaps have been made in this area. In this paper, we provide an overview of the current challenges and representative achievements about pushing deep learning on mobile devices from three aspects: training with mobile data, efficient inference on mobile devices, and applications of mobile deep learning. The former two aspects cover the primary tasks of deep learning. Then, we go through our two recent applications that apply the data collected by mobile devices to inferring mood disturbance and user identification. Finally, we conclude this paper with the discussion of the future of this area."
1809.03652,2018-09-11 02:04:05,Exploiting the structure effectively and efficiently in low rank matrix recovery,"Jian-Feng Cai,Ke Wei",https://arxiv.org/abs/1809.03652,"        Book chapter for ""Handbook of Numerical Analysis"", 2018
      ",,math.NA,"math.NA,cs.NA","Low rank model arises from a wide range of applications, including  machine learning , signal processing, computer algebra, computer vision, and imaging science. Low rank matrix recovery is about reconstructing a low rank matrix from incomplete measurements. In this survey we review recent developments on low rank matrix recovery, focusing on three typical scenarios: matrix sensing, matrix completion and phase retrieval. An overview of effective and efficient approaches for the problem is given, including nuclear norm minimization, projected gradient descent based on matrix factorization, and Riemannian optimization based on the embedded manifold of low rank matrices. Numerical recipes of different approaches are emphasized while accompanied by the corresponding theoretical recovery guarantees."
1809.03416,2018-09-10 15:55:15,Identifying Relationships Among Sentences in Court Case Transcripts Using Discourse Relations,"Gathika Ratnayaka,Thejan Rupasinghe,Nisansa de Silva,Menuka Warushavithana,Viraj Gamage,Amal Shehan Perera",https://arxiv.org/abs/1809.03416,    ,Conference: 2018 International Conference on Advances in ICT for Emerging Regions (ICTer),cs.CL,"cs.CL,cs.LG,stat.ML","Case Law has a significant impact on the proceedings of legal cases. Therefore, the information that can be obtained from previous court cases is valuable to lawyers and other legal officials when performing their duties. This paper describes a methodology of applying discourse relations between sentences when processing text documents related to the legal domain. In this study, we developed a mechanism to classify the relationships that can be observed among sentences in transcripts of United States court cases. First, we defined relationship types that can be observed between sentences in court case transcripts. Then we classified pairs of sentences according to the relationship type by combining a  machine learning  model and a rule-based approach. The results obtained through our system were evaluated using human judges. To the best of our knowledge, this is the first study where discourse relationships between sentences have been used to determine relationships among sentences in legal court case transcripts."
1809.03960,2018-09-11 15:10:07,Atomic positions independent descriptor for,"Ankit Jain,Thomas Bligaard",https://arxiv.org/abs/1809.03960,    ,"7 pages, 5 figures",cond-mat.mtrl-sci,"cond-mat.mtrl-sci,cond-mat.dis-nn,physics.data-an","The high-throughput screening of periodic inorganic solids using  machine learning  methods requires atomic positions to encode structural and compositional into appropriate material descriptors. These atomic positions are not available a priori for new materials which severely limits exploration of novel materials. We overcome this limitation by using only crystallographic symmetry information in the structural description of materials. We show that for materials with identical structural symmetry,  machine learning  is trivially simple and accuracies similar to that of density functional theory calculations can be achieved by using only atomic numbers in the material description. For  machine learning  of formation energies of bulk crystalline solids, this simple material descriptor is able to achieve prediction mean absolute errors of only 0.07 eV/atom on a test dataset consisting of more than 85,000 diverse materials. This atomic-positions independent material descriptor presents a new paradigm of materials discovery wherein millions of materials can be screened by training a ML model over a drastically reduced subspace of materials."
1809.03832,2018-09-11 13:04:19,Learning rate adaptation for differentially private stochastic gradient descent,"Antti Koskela,Antti Honkela",https://arxiv.org/abs/1809.03832,    ,"17 pages, 7 figures",stat.ML,"stat.ML,cs.CR,cs.LG","Differentially private learning has recently emerged as the leading approach for privacy-preserving  machine learning . Differential privacy can complicate learning procedures because each access to the data needs to be carefully designed and carries a privacy cost. For example, standard parameter tuning with a validation set cannot be easily applied. In this paper, we propose a differentially private algorithm for the adaptation of the learning rate for differentially private stochastic gradient descent (SGD) that avoids the need for validation set use. The idea for the adaptiveness comes from the technique of extrapolation in classical numerical analysis: to get an estimate for the error against the gradient flow which underlies SGD, we compare the result obtained by one full step and two half-steps. We prove the privacy of the method using the moments accountant mechanism. This allows us to compute tight privacy bounds. Empirically we show that our method is competitive with manually tuned commonly used optimisation methods for training deep neural networks and differentially private variational inference."
1809.03857,2018-09-11 13:22:52,EXS: Explainable Search Using Local Model Agnostic Interpretability,"Jaspreet Singh,Avishek Anand",https://arxiv.org/abs/1809.03857,,,cs.IR,cs.IR,"Retrieval models in information retrieval are used to rank documents for typically under-specified queries. Today  machine learning  is used to learn retrieval models from click logs and/or relevance judgments that maximizes an objective correlated with user satisfaction. As these models become increasingly powerful and sophisticated, they also become harder to understand. Consequently, it is hard for to identify artifacts in training, data specific biases and intents from a complex trained model like neural rankers even if trained purely on text features. EXS is a search system designed specifically to provide its users with insight into the following questions: `What is the intent of the query according to the ranker?', `Why is this document ranked higher than another?' and `Why is this document relevant to the query?'. EXS uses a version of a popular posthoc explanation method for classifiers -- LIME, adapted specifically to answer these questions. We show how such a system can effectively help a user understand the results of neural rankers and highlight areas of improvement."
1809.03995,2018-09-11 16:01:30,Toward Automated Early Sepsis Alerting: Identifying Infection Patients from Nursing Notes,"Emilia Apostolova,Tom Velez",https://arxiv.org/abs/1809.03995,    ,BioNLP 2017 (2017): 257-262,cs.CY,cs.CY,"Severe sepsis and septic shock are conditions that affect millions of patients and have close to 50% mortality rate. Early identification of at-risk patients significantly improves outcomes. Electronic surveillance tools have been developed to monitor structured Electronic Medical Records and automatically recognize early signs of sepsis. However, many sepsis risk factors (e.g. symptoms and signs of infection) are often captured only in free text clinical notes. In this study, we developed a method for automatic monitoring of nursing notes for signs and symptoms of infection. We utilized a creative approach to automatically generate an annotated dataset. The dataset was used to create a  machine learning  model that achieved an F1-score ranging from 79 to 96%."
1809.04019,2018-09-11 16:43:52,"Training and Prediction Data Discrepancies: Challenges of Text Classification with Noisy, Historical Data","Emilia Apostolova,R. Andrew Kreek",https://arxiv.org/abs/1809.04019,    ,2018 The 4th Workshop on Noisy User-generated Text (W-NUT),cs.IR,"cs.IR,cs.CL,cs.LG,stat.ML","Industry datasets used for text classification are rarely created for that purpose. In most cases, the data and target predictions are a by-product of accumulated historical data, typically fraught with noise, present in both the text-based document, as well as in the targeted labels. In this work, we address the question of how well performance metrics computed on noisy, historical data reflect the performance on the intended future  machine learning  model input. The results demonstrate the utility of dirty training datasets used to build prediction models for cleaner (and different) prediction inputs."
1809.04028,2018-09-11 16:50:57,p-Bits for Probabilistic Spin Logic,"Kerem Y. Camsari,Brian M. Sutton,Supriyo Datta",https://arxiv.org/abs/1809.04028,,,cs.ET,cs.ET,"We introduce the concept of a probabilistic or p-bit, intermediate between the standard bits of digital electronics and the emerging q-bits of quantum computing. We show that low barrier magnets or LBM's provide a natural physical representation for p-bits and can be built either from perpendicular magnets (PMA) designed to be close to the in-plane transition or from circular in-plane magnets (IMA). Magnetic tunnel junctions (MTJ) built using LBM's as free layers can be combined with standard NMOS transistors to provide three-terminal building blocks for large scale probabilistic circuits that can be designed to perform useful functions. Interestingly, this three-terminal unit looks just like the 1T/MTJ device used in embedded MRAM technology, with only one difference: the use of an LBM for the MTJ free layer. We hope that the concept of p-bits and p-circuits will help open up new application spaces for this emerging technology. However, a p-bit need not involve an MTJ, any fluctuating resistor could be combined with a transistor to implement it, while completely digital implementations using conventional CMOS technology are also possible. The p-bit also provides a conceptual bridge between two active but disjoint fields of research, namely stochastic  machine learning  and quantum computing. First, there are the applications that are based on the similarity of a p-bit to the binary stochastic neuron (BSN), a well-known concept in  machine learning . Three-terminal p-bits could provide an efficient hardware accelerator for the BSN. Second, there are the applications that are based on the p-bit being like a poor man's q-bit. Initial demonstrations based on full SPICE simulations show that several optimization problems including quantum annealing are amenable to p-bit implementations which can be scaled up at room temperature using existing technology."
1809.01827,2018-09-06 05:19:38,Eigendecomposition-Free Sampling Set Selection for Graph Signals,"Akie Sakiyama,Yuichi Tanaka,Toshihisa Tanaka,Antonio Ortega",https://arxiv.org/abs/1809.01827,,,eess.SP,eess.SP,"This paper addresses the problem of selecting an optimal sampling set for signals on graphs. The proposed sampling set selection (SSS) is based on a localization operator that can consider both vertex domain and spectral domain localization. We clarify the relationships among the proposed method, sensor position selection methods in  machine learning , and conventional SSS methods based on graph frequency. In contrast to the conventional graph signal processing-based approaches, the proposed method does not need to compute the eigendecomposition of a variation operator, while still considering (graph) frequency information. We evaluate the performance of our approach through comparisons of prediction errors and execution time."
1809.04041,2018-09-11 17:15:56,Identifying Unmaintained Projects in GitHub,"Jailton Coelho,Marco Tulio Valente,Luciana L. Silva,Emad Shihab",https://arxiv.org/abs/1809.04041,    ,"Accepted at 12th International Symposium on Empirical Software Engineering and Measurement (ESEM), 10 pages, 2018",cs.SE,cs.SE,"Background: Open source software has an increasing importance in modern software development. However, there is also a growing concern on the sustainability of such projects, which are usually managed by a small number of developers, frequently working as volunteers. Aims: In this paper, we propose an approach to identify GitHub projects that are not actively maintained. Our goal is to alert users about the risks of using these projects and possibly motivate other developers to assume the maintenance of the projects. Method: We train  machine learning  models to identify unmaintained or sparsely maintained projects, based on a set of features about project activity (commits, forks, issues, etc). We empirically validate the model with the best performance with the principal developers of 129 GitHub projects. Results: The proposed  machine learning  approach has a precision of 80%, based on the feedback of real open source developers; and a recall of 96%. We also show that our approach can be used to assess the risks of projects becoming unmaintained. Conclusions: The model proposed in this paper can be used by open source users and developers to identify GitHub projects that are not actively maintained anymore."
1809.04166,2018-09-11 21:09:25,"Leabra7: a Python package for modeling recurrent, biologically-realistic neural networks","C. Daniel Greenidge,Noam Miller,Kenneth A. Norman",https://arxiv.org/abs/1809.04166,,,cs.NE,"cs.NE,q-bio.NC","Emergent is a software package that uses the AdEx neural dynamics model and LEABRA learning algorithm to simulate and train arbitrary recurrent neural network architectures in a biologically-realistic manner. We present Leabra7, a complementary Python library that implements these same algorithms. Leabra7 is developed and distributed using modern software development principles, and integrates tightly with Python's scientific stack. We demonstrate recurrent Leabra7 networks using traditional pattern-association tasks and a standard  machine learning  task, classifying the IRIS dataset."
1809.04067,2018-09-11 23:46:33,"Zoom: SSD-based Vector Search for Optimizing Accuracy, Latency and Memory","Minjia Zhang,Yuxiong He",https://arxiv.org/abs/1809.04067,,,cs.CV,"cs.CV,cs.LG,cs.PF","With the advancement of  machine learning  and deep learning, vector search becomes instrumental to many information retrieval systems, to search and find best matches to user queries based on their semantic similarities.These online services require the search architecture to be both effective with high accuracy and efficient with low latency and memory footprint, which existing work fails to offer. We develop, Zoom, a new vector search solution that collaboratively optimizes accuracy, latency and memory based on a multiview approach. (1) A ""preview"" step generates a small set of good candidates, leveraging compressed vectors in memory for reduced footprint and fast lookup. (2) A ""fullview"" step on SSDs reranks those candidates with their full-length vector, striking high accuracy. Our evaluation shows that, Zoom achieves an order of magnitude improvements on efficiency while attaining equal or higher accuracy, comparing with the state-of-the-art."
1809.04120,2018-09-11 19:39:51,Taking a machine's perspective: Human deciphering of adversarial images,"Zhenglong Zhou,Chaz Firestone",https://arxiv.org/abs/1809.04120,    ,"14 pages, 4 figures",cs.CV,"cs.CV,cs.CY,cs.LG","How similar is the human mind to the sophisticated  -  systems that mirror its performance? Models of object categorization based on convolutional neural networks (CNNs) have achieved human-level benchmarks in assigning known labels to novel images. These advances support transformative technologies such as autonomous vehicles and machine diagnosis; beyond this, they also serve as candidate models for the visual system itself -- not only in their output but perhaps even in their underlying mechanisms and principles. However, unlike human vision, CNNs can be ""fooled"" by adversarial examples -- carefully crafted images that appear as nonsense patterns to humans but are recognized as familiar objects by machines, or that appear as one object to humans and a different object to machines. This seemingly extreme divergence between human and machine classification challenges the promise of these new advances, both as applied image-recognition systems and also as models of the human mind. Surprisingly, however, little work has empirically investigated human classification of such adversarial stimuli: Does human and machine performance fundamentally diverge? Or could humans decipher such images and predict the machine's preferred labels? Here, we show that human and machine classification of adversarial stimuli are robustly related: In seven experiments on five prominent and diverse adversarial imagesets, human subjects reliably identified the machine's chosen label over relevant foils. This pattern persisted for images with strong antecedent identities, and even for images described as ""totally unrecognizable to human eyes"". We suggest that human intuition may be a more reliable guide to machine (mis)classification than has typically been imagined, and we explore the consequences of this result for minds and machines alike."
1809.01740,2018-09-05 21:37:27,Predicting Smoking Events with a Time-Varying Semi-Parametric Hawkes Process Model,"Matthew Engelhard,Hongteng Xu,Lawrence Carin,Jason A Oliver,Matthew Hallyburton,F Joseph McClernon",https://arxiv.org/abs/1809.01740,    ,Presented at ,stat.ML,"stat.ML,cs.LG,stat.AP","Health risks from cigarette smoking -- the leading cause of preventable death in the United States -- can be substantially reduced by quitting. Although most smokers are motivated to quit, the majority of quit attempts fail. A number of studies have explored the role of self-reported symptoms, physiologic measurements, and environmental context on smoking risk, but less work has focused on the temporal dynamics of smoking events, including daily patterns and related nicotine effects. In this work, we examine these dynamics and improve risk prediction by modeling smoking as a self-triggering process, in which previous smoking events modify current risk. Specifically, we fit smoking events self-reported by 42 smokers to a time-varying semi-parametric Hawkes process (TV-SPHP) developed for this purpose. Results show that the TV-SPHP achieves superior prediction performance compared to related and existing models, with the incorporation of time-varying predictors having greatest benefit over longer prediction windows. Moreover, the impact function illustrates previously unknown temporal dynamics of smoking, with possible connections to nicotine metabolism to be explored in future work through a randomized study design. By more effectively predicting smoking events and exploring a self-triggering component of smoking risk, this work supports development of novel or improved cessation interventions that aim to reduce death from smoking."
1809.01564,2018-09-05 15:03:23,Traffic Density Estimation using a Convolutional Neural Network,"Julian Nubert,Nicholas Giai Truong,Abel Lim,Herbert Ilhan Tanujaya,Leah Lim,Mai Anh Vu",https://arxiv.org/abs/1809.01564,    ,Machine,cs.LG,"cs.LG,cs.AI,cs.CV,stat.ML","The goal of this project is to introduce and present a  machine learning  application that aims to improve the quality of life of people in Singapore. In particular, we investigate the use of  machine learning  solutions to tackle the problem of traffic congestion in Singapore. In layman's terms, we seek to make Singapore (or any other city) a smoother place. To accomplish this aim, we present an end-to-end system comprising of 1. A traffic density estimation algorithm at traffic lights/junctions and 2. a suitable traffic signal control algorithms that make use of the density information for better traffic control. Traffic density estimation can be obtained from traffic junction images using various  machine learning  techniques (combined with CV tools). After research into various advanced  machine learning  methods, we decided on convolutional neural networks (CNNs). We conducted experiments on our algorithms, using the publicly available traffic camera dataset published by the Land Transport Authority (LTA) to demonstrate the feasibility of this approach. With these traffic density estimates, different traffic algorithms can be applied to minimize congestion at traffic junctions in general."
1809.01577,2018-09-03 11:39:11,From Bayesian Inference to Logical Bayesian Inference: A New Mathematical Frame for Semantic Communication and,Chenguang Lu,https://arxiv.org/abs/1809.01577,"          H.1.1; F.4.1; I.2.3; I.2.6; I.5.2; I.5.3
        
      ","12 Pages, 1 figure, 31 equations",cs.AI,"cs.AI,cs.LG","Bayesian Inference (BI) uses the Bayes' posterior whereas Logical Bayesian Inference (LBI) uses the truth function or membership function as the inference tool. LBI was proposed because BI was not compatible with the classical Bayes' prediction and didn't use logical probability and hence couldn't express semantic meaning. In LBI, statistical probability and logical probability are strictly distinguished, used at the same time, and linked by the third kind of Bayes' Theorem. The Shannon channel consists of a set of transition probability functions whereas the semantic channel consists of a set of truth functions. When a sample is large enough, we can directly derive the semantic channel from Shannon's channel. Otherwise, we can use parameters to construct truth functions and use the Maximum Semantic Information (MSI) criterion to optimize the truth functions. The MSI criterion is equivalent to the Maximum Likelihood (ML) criterion, and compatible with the Regularized Least Square (RLS) criterion. By matching the two channels one with another, we can obtain the Channels' Matching (CM) algorithm. This algorithm can improve multi-label classifications, maximum likelihood estimations (including unseen instance classifications), and mixture models. In comparison with BI, LBI 1) uses the prior P(X) of X instead of that of Y or θ and fits cases where the source P(X) changes, 2) can be used to solve the denotations of labels, and 3) is more compatible with the classical Bayes' prediction and likelihood method. LBI also provides a confirmation measure between -1 and 1 for induction."
1809.01643,2018-09-05 17:41:34,Efficient Difference-in-Differences Estimation with High-Dimensional Common Trend Confounding,Michael Zimmert,https://arxiv.org/abs/1809.01643,,,econ.EM,econ.EM,"We contribute to the theoretical literature on difference-in-differences estimation for policy evaluation by allowing the common trend assumption to hold conditional on a high-dimensional covariate set. In particular, the covariates can enter the difference-in-differences model in a very flexible form leading to estimation procedures that involve supervised  machine learning  methods. We derive asymptotic results for semiparametric and parametric estimators for repeated cross-sections and panel data and show desirable statistical properties. Notably, a non-standard semiparametric efficiency bound for difference-in-differences estimation that incorporates the repeated cross-section case is established. Our proposed semiparametric estimator is shown to attain this bound. The usability of the methods is assessed by replicating a study on an employment protection reform. We demonstrate that the notion of high-dimensional common trend confounding has implications for the economic interpretation of policy evaluation results via difference-in-differences."
1809.01697,2018-09-04 00:47:50,HASP: A High-Performance Adaptive Mobile Security Enhancement Against Malicious Speech Recognition,"Zirui Xu,Fuxun Yu,Chenchen Liu,Xiang Chen",https://arxiv.org/abs/1809.01697,    ,"8 pages, 10 figures",cs.CR,"cs.CR,cs.LG,cs.SD,eess.AS,eess.SP,stat.ML","Nowadays,  machine learning  based Automatic Speech Recognition (ASR) technique has widely spread in smartphones, home devices, and public facilities. As convenient as this technology can be, a considerable security issue also raises -- the users' speech content might be exposed to malicious ASR monitoring and cause severe privacy leakage. In this work, we propose HASP -- a high-performance security enhancement approach to solve this security issue on mobile devices. Leveraging ASR systems' vulnerability to the adversarial examples, HASP is designed to cast human imperceptible adversarial noises to real-time speech and effectively perturb malicious ASR monitoring by increasing the Word Error Rate (WER). To enhance the practical performance on mobile devices, HASP is also optimized for effective adaptation to the human speech characteristics, environmental noises, and mobile computation scenarios. The experiments show that HASP can achieve optimal real-time security enhancement: it can lead an average WER of 84.55% for perturbing the malicious ASR monitoring, and the data processing speed is 15x to 40x faster compared to the state-of-the-art methods. Moreover, HASP can effectively perturb various ASR systems, demonstrating a strong transferability."
1809.01434,2018-09-05 11:06:06,Stellar Cluster Detection using GMM with Deep Variational Autoencoder,"Arnab Karmakar,Deepak Mishra,Anandmayee Tej",https://arxiv.org/abs/1809.01434,    ,"5 pages, 7 figures, under review in IEEE RAICS 2018",cs.LG,"cs.LG,astro-ph.GA,astro-ph.SR,stat.ML","Detecting stellar clusters have always been an important research problem in Astronomy. Although images do not convey very detailed information in detecting stellar density enhancements, we attempt to understand if new  machine learning  techniques can reveal patterns that would assist in drawing better inferences from the available image data. This paper describes an unsupervised approach in detecting star clusters using Deep Variational Autoencoder combined with a Gaussian Mixture Model. We show that our method works significantly well in comparison with state-of-the-art detection algorithm in recognizing a variety of star clusters even in the presence of noise and distortion."
1809.01715,2018-09-05 20:16:14,Bridging,"Olga Taran,Shideh Rezaeifar,Slava Voloshynovskiy",https://arxiv.org/abs/1809.01715,,,cs.CR,"cs.CR,cs.LG,stat.ML","In the last decade, deep learning algorithms have become very popular thanks to the achieved performance in many  machine learning  and computer vision tasks. However, most of the deep learning architectures are vulnerable to so called adversarial examples. This questions the security of deep neural networks (DNN) for many security- and trust-sensitive domains. The majority of the proposed existing adversarial attacks are based on the differentiability of the DNN cost function.Defence strategies are mostly based on  machine learning  and signal processing principles that either try to detect-reject or filter out the adversarial perturbations and completely neglect the classical cryptographic component in the defence. In this work, we propose a new defence mechanism based on the second Kerckhoffs's cryptographic principle which states that the defence and classification algorithm are supposed to be known, but not the key. To be compliant with the assumption that the attacker does not have access to the secret key, we will primarily focus on a gray-box scenario and do not address a white-box one. More particularly, we assume that the attacker does not have direct access to the secret block, but (a) he completely knows the system architecture, (b) he has access to the data used for training and testing and (c) he can observe the output of the classifier for each given input. We show empirically that our system is efficient against most famous state-of-the-art attacks in black-box and gray-box scenarios."
1809.01712,2018-09-05 19:59:38,Controlled Random Search Improves Sample Mining and Hyper-Parameter Optimization,"Gowtham Muniraju,Bhavya Kailkhura,Jayaraman J. Thiagarajan,Peer-Timo Bremer",https://arxiv.org/abs/1809.01712,,,cs.LG,"cs.LG,stat.ML","A common challenge in  machine learning  and related fields is the need to efficiently explore high dimensional parameter spaces using small numbers of samples. Typical examples are hyper-parameter optimization in deep learning and sample mining in predictive modeling tasks. All such problems trade-off exploration, which samples the space without knowledge of the target function, and exploitation where information from previous evaluations is used in an adaptive feedback loop. Much of the recent focus has been on the exploitation while exploration is done with simple designs such as Latin hypercube or even uniform random sampling. In this paper, we introduce optimal space-filling sample designs for effective exploration of high dimensional spaces. Specifically, we propose a new parameterized family of sample designs called space-filling spectral designs, and introduce a framework to choose optimal designs for a given sample size and dimension. Furthermore, we present an efficient algorithm to synthesize a given spectral design. Finally, we evaluate the performance of spectral designs in both data space and model space applications. The data space exploration is targeted at recovering complex regression functions in high dimensional spaces. The model space exploration focuses on selecting hyper-parameters for a given neural network architecture. Our empirical studies demonstrate that the proposed approach consistently outperforms state-of-the-art techniques, particularly with smaller design sizes."
1809.01753,2018-09-05 22:24:17,Automatic convergence and,"Kamal Choudhary,Francesca Tavazza",https://arxiv.org/abs/1809.01753,,,cond-mat.mtrl-sci,cond-mat.mtrl-sci,"In this work, we developed an automatic convergence procedure for k-points and plane wave cut-off in density functional (DFT) calculations and applied it to more than 25000 materials. The computational framework for automatic convergence can take a user-defined input as a convergence criterion. From the analysis of our results, we could relate k-point density and plane wave cut-off to material parameters such as density, bandgap, the slope of bands, number of band-crossings, the maximum plane-wave cut-off used in pseudopotential generation, crystal systems, and the number of unique species in materials. We also identified some material species that would require more careful convergence than others. Moreover, we statistically investigated the dependence of k-points and cutoff on exchange-correlation functionals and dimensionality (3D vs 2D) of materials. We utilized all this data to train  machine learning  models to predict the k-point line density and plane-wave cut-off for generalized materials. This would provide users with a good starting point towards converged DFT calculations. The code used, and the converged data are available on the JARVIS-DFT websites https://jarvis.nist.gov/ , and https://github.com/usnistgov/jarvis ."
1809.01771,2018-09-06 00:31:51,An Analysis of Hierarchical Text Classification Using Word Embeddings,"Roger A. Stein,Patricia A. Jaques,Joao F. Valiati",https://arxiv.org/abs/1809.01771,    ,"Article accepted for publication in Information Sciences on Sep 1st, 2018",cs.CL,"cs.CL,cs.AI,cs.LG","Efficient distributed numerical word representation models (word embeddings) combined with modern  machine learning  algorithms have recently yielded considerable improvement on automatic document classification tasks. However, the effectiveness of such techniques has not been assessed for the hierarchical text classification (HTC) yet. This study investigates the application of those models and algorithms on this specific problem by means of experimentation and analysis. We trained classification models with prominent  machine learning  algorithm implementations---fastText, XGBoost, SVM, and Keras' CNN---and noticeable word embeddings generation methods---GloVe, word2vec, and fastText---with publicly available data and evaluated them with measures specifically appropriate for the hierarchical context. FastText achieved an ${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An analysis indicates that using word embeddings and its flavors is a very promising approach for HTC."
1809.01804,2018-09-06 03:33:06,Discovering Influential Factors in Variational Autoencoder,"Shiqi Liu,Jingxin Liu,Qian Zhao,Xiangyong Cao,Huibin Li,Hongying Meng,Sheng Liu,Deyu Meng",https://arxiv.org/abs/1809.01804,    ,"15 pages, 8 figures",cs.LG,"cs.LG,stat.ML","In the field of  machine learning , it is still a critical issue to identify and supervise the learned representation without manually intervention or intuition assistance to extract useful knowledge or serve for the latter tasks in  machine learning . In this work, we focus on supervising the influential factors extracted by the variational autoencoder(VAE). The VAE is proposed to learn independent low dimension representation while facing the problem that sometimes pre-set factors are ignored. We argue that the mutual information of the input and each learned factor of the representation plays a necessary indicator. We find the VAE objective inclines to induce mutual information sparsity in factor dimension over the data intrinsic dimension and results in some non-influential factors whose function on data reconstruction could be ignored. We show mutual information also influences the lower bound of VAE's reconstruction error and latter classification task. To make such indicator applicable, we design an algorithm on calculating the mutual information for VAE and prove its consistency. Experimental results on Mnist, CelebA and Deap datasets show that mutual information can help determine influential factors, of which some are interpretable and can be used to further generation and classification tasks, and help discover the variant that connects with emotion on Deap dataset."
1809.01833,2018-09-06 05:48:50,Wasserstein Soft Label Propagation on Hypergraphs: Algorithm and Generalization Error Bounds,"Tingran Gao,Shahab Asoodeh,Yi Huang,James Evans",https://arxiv.org/abs/1809.01833,    ,12 pages,stat.ML,"stat.ML,cs.LG","Inspired by recent interests of developing  machine learning  and data mining algorithms on hypergraphs, we investigate in this paper the semi-supervised learning algorithm of propagating ""soft labels"" (e.g. probability distributions, class membership scores) over hypergraphs, by means of optimal transportation. Borrowing insights from Wasserstein propagation on graphs [Solomon et al. 2014], we re-formulate the label propagation procedure as a message-passing algorithm, which renders itself naturally to a generalization applicable to hypergraphs through Wasserstein barycenters. Furthermore, in a PAC learning framework, we provide generalization error bounds for propagating one-dimensional distributions on graphs and hypergraphs using 2-Wasserstein distance, by establishing the \textit{algorithmic stability} of the proposed semi-supervised learning algorithm. These theoretical results also shed new lights upon deeper understandings of the Wasserstein propagation on graphs."
1809.01772,2018-09-06 00:34:38,Multi-view Factorization AutoEncoder with Network Constraints for Multi-omic Integrative Analysis,"Tianle Ma,Aidong Zhang",https://arxiv.org/abs/1809.01772,    ,"12 pages, 2 figures",cs.LG,"cs.LG,stat.ML","Multi-omic data provides multiple views of the same patients. Integrative analysis of multi-omic data is crucial to elucidate the molecular underpinning of disease etiology. However, multi-omic data has the ""big p, small N"" problem (the number of features is large, but the number of samples is small), it is challenging to train a complicated  machine learning  model from the multi-omic data alone and make it generalize well. Here we propose a framework termed Multi-view Factorization AutoEncoder with network constraints to integrate multi-omic data with domain knowledge (biological interactions networks). Our framework employs deep representation learning to learn feature embeddings and patient embeddings simultaneously, enabling us to integrate feature interaction network and patient view similarity network constraints into the training objective. The whole framework is end-to-end differentiable. We applied our approach to the TCGA Pan-cancer dataset and achieved satisfactory results to predict disease progression-free interval (PFI) and patient overall survival (OS) events. Code will be made publicly available."
1809.01859,2018-09-06 07:44:33,Deep Learning-Based Decoding for Constrained Sequence Codes,"Congzhe Cao,Duanshun Li,Ivan Fair",https://arxiv.org/abs/1809.01859,    ,"7 pages, 6 figures, accepted by IEEE Global Communications Conference Workshop - ",cs.IT,"cs.IT,cs.LG,eess.SP,stat.ML","Constrained sequence codes have been widely used in modern communication and data storage systems. Sequences encoded with constrained sequence codes satisfy constraints imposed by the physical channel, hence enabling efficient and reliable transmission of coded symbols. Traditional encoding and decoding of constrained sequence codes rely on table look-up, which is prone to errors that occur during transmission. In this paper, we introduce constrained sequence decoding based on deep learning. With multiple layer perception (MLP) networks and convolutional neural networks (CNNs), we are able to achieve low bit error rates that are close to maximum a posteriori probability (MAP) decoding as well as improve the system throughput. Moreover, implementation of capacity-achieving fixed-length codes, where the complexity is prohibitively high with table look-up decoding, becomes practical with deep learning-based decoding."
1809.01898,2018-09-06 09:26:03,Propheticus: Generalizable,"João R. Campos,Marco Vieira,Ernesto Costa",https://arxiv.org/abs/1809.01898,,,cs.LG,"cs.LG,cs.AI,stat.ML","Due to recent technological developments,  machine learning  (ML), a subfield of Artificial Intelligence (AI), has been successfully used to process and extract knowledge from a variety of complex problems. However, a thorough ML approach is complex and highly dependent on the problem at hand. Additionally, implementing the logic required to execute the experiments is no small nor trivial deed, consequentially increasing the probability of faulty code which can compromise the results. Propheticus is a data-driven framework which results of the need for a tool that abstracts some of the inherent complexity of ML, whilst being easy to understand and use, as well as to adapt and expand to assist the user's specific needs. Propheticus systematizes and enforces various complex concepts of an ML experiment workflow, taking into account the nature of both the problem and the data. It contains functionalities to execute all the different tasks, from data preprocessing, to results analysis and comparison. Notwithstanding, it can be fairly easily adapted to different problems due to its flexible architecture, and customized as needed to address the user's needs."
1809.01887,2018-09-08 07:39:40,Travel Speed Prediction with a Hierarchical Convolutional Neural Network and Long Short-Term Memory Model Framework,"Wei Wang,Xucheng Li",https://arxiv.org/abs/1809.01887,    ,"17 pages, 10 Figures, 4 Tables; To be presented in European Transport Conference in Dublin, Oct 2018",cs.LG,"cs.LG,stat.ML","Advanced travel information and warning, if provided accurately, can help road users avoid traffic congestion through dynamic route planning and behavior change. It also enables traffic control centres mitigate the impact of congestion by activating Intelligent Transport System (ITS) proactively. Deep learning has become increasingly popular in recent years, following a surge of innovative GPU technology, high-resolution, big datasets and thriving  machine learning  algorithms. However, there are few examples exploiting this emerging technology to develop applications for traffic prediction. This is largely due to the difficulty in capturing random, seasonal, non-linear, and spatio-temporal correlated nature of traffic data. In this paper, we propose a data-driven modelling approach with a novel hierarchical D-CLSTM-t deep learning model for short-term traffic speed prediction, a framework combined with convolutional neural network (CNN) and long short-term memory (LSTM) models. A deep CNN model is employed to learn the spatio-temporal traffic patterns of the input graphs, which are then fed into a deep LSTM model for sequence learning. To capture traffic seasonal variations, time of the day and day of the week indicators are fused with trained features. The model is trained end-to-end to predict travel speed in 15 to 90 minutes in the future. We compare the model performance against other baseline models including CNN, LGBM, LSTM, and traditional speed-flow curves. Experiment results show that the D-CLSTM-t outperforms other models considerably. Model tests show that speed upstream also responds sensibly to a sudden accident occurring downstream. Our D-CLSTM-t model framework is also highly scalable for future extension such as for network-wide traffic prediction, which can also be improved by including additional features such as weather, long term seasonality and accident information."
1809.01931,2018-09-06 11:56:29,An unexpected connection between Bayes $A-$optimal designs and the Group Lasso,"Guillaume Sagnol,Edouard Pauwels",https://arxiv.org/abs/1809.01931,"          62K05
        

        
      ",,math.OC,math.OC,We show that the $A$-optimal design optimization problem over $m$ design points in $\mathbb{R}^n$ is equivalent to minimizing a quadratic function plus a group lasso sparsity inducing term over $n\times m$ real matrices. This observation allows to describe several new algorithms for $A$-optimal design based on splitting and block coordinate decomposition. These techniques are well known and proved powerful to treat large scale problems in  machine learning  and signal processing communities. The proposed algorithms come with rigorous convergence guaranties and convergence rate estimate stemming from the optimization literature. Performances are illustrated on synthetic benchmarks and compared to existing methods for solving the optimal design problem.
1809.02069,2018-09-06 16:03:18,Deep learning for in vitro prediction of pharmaceutical formulations,"Yilong Yang,Zhuyifan Ye,Yan Su,Qianqian Zhao,Xiaoshan Li,Defang Ouyang",https://arxiv.org/abs/1809.02069,,,cs.LG,"cs.LG,stat.ML","Current pharmaceutical formulation development still strongly relies on the traditional trial-and-error approach by individual experiences of pharmaceutical scientists, which is laborious, time-consuming and costly. Recently, deep learning has been widely applied in many challenging domains because of its important capability of automatic feature extraction. The aim of this research is to use deep learning to predict pharmaceutical formulations. In this paper, two different types of dosage forms were chosen as model systems. Evaluation criteria suitable for pharmaceutics were applied to assessing the performance of the models. Moreover, an automatic dataset selection algorithm was developed for selecting the representative data as validation and test datasets. Six  machine learning  methods were compared with deep learning. The result shows the accuracies of both two deep neural networks were above 80% and higher than other  machine learning  models, which showed good prediction in pharmaceutical formulations. In summary, deep learning with the automatic data splitting algorithm and the evaluation criteria suitable for pharmaceutical formulation data was firstly developed for the prediction of pharmaceutical formulations. The cross-disciplinary integration of pharmaceutics and artificial intelligence may shift the paradigm of pharmaceutical researches from experience-dependent studies to data-driven methodologies."
1809.02154,2018-09-06 18:23:36,From FATS to feets: Further improvements to an astronomical feature extraction tool based on,"J. B. Cabral,B. Sánchez,F. Ramos,S. Gurovich,P. Granitto,J. Vanderplas",https://arxiv.org/abs/1809.02154,    ,accepted in Astronomy and Computing,astro-ph.IM,"astro-ph.IM,cs.LG","machine learning  algorithms are highly useful for the classification of time series data in astronomy in this era of peta-scale public survey data releases. These methods can facilitate the discovery of new unknown events in most astrophysical areas, as well as improving the analysis of samples of known phenomena.  machine learning  algorithms use features extracted from collected data as input predictive variables. A public tool called Feature Analysis for Time Series (FATS) has proved an excellent workhorse for feature extraction, particularly light curve classification for variable objects. In this study, we present a major improvement to FATS, which corrects inconvenient design choices, minor details, and documentation for the re-engineering process. This improvement comprises a new Python package called ""feets"", which is important for future code-refactoring for astronomical software tools."
1809.02077,2018-09-07 03:57:00,IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection,"Zilong Lin,Yong Shi,Zhi Xue",https://arxiv.org/abs/1809.02077,    ,"8 pages, 5 figures",cs.CR,"cs.CR,cs.AI","As an important tool in security, the intrusion detection system bears the responsibility of the defense to network attacks performed by malicious traffic. Nowadays, with the help of  machine learning  algorithms, the intrusion detection system develops rapidly. However, the robustness of this system is questionable when it faces the adversarial attacks. To improve the detection system, more potential attack approaches should be researched. In this paper, a framework of the generative adversarial networks, IDSGAN, is proposed to generate the adversarial attacks, which can deceive and evade the intrusion detection system. Considering that the internal structure of the detection system is unknown to attackers, adversarial attack examples perform the black-box attacks against the detection system. IDSGAN leverages a generator to transform original malicious traffic into adversarial malicious traffic. A discriminator classifies traffic examples and simulates the black-box detection system. More significantly, we only modify part of the attacks' nonfunctional features to guarantee the validity of the intrusion. Based on the dataset NSL-KDD, the feasibility of the model is demonstrated to attack many detection systems with different attacks and the excellent results are achieved. Moreover, the robustness of IDSGAN is verified by changing the amount of the unmodified features."
1809.02255,2018-09-07 00:00:39,Adversarial Domain Adaptation for Duplicate Question Detection,"Darsh J Shah,Tao Lei,Alessandro Moschitti,Salvatore Romeo,Preslav Nakov",https://arxiv.org/abs/1809.02255,    ,EMNLP 2018 short paper - camera ready. 8 pages,cs.CL,cs.CL,"We address the problem of detecting duplicate questions in forums, which is an important step towards automating the process of answering new questions. As finding and annotating such potential duplicates manually is very tedious and costly, automatic methods based on  machine learning  are a viable alternative. However, many forums do not have annotated data, i.e., questions labeled by experts as duplicates, and thus a promising solution is to use domain adaptation from another forum that has such annotations. Here we focus on adversarial domain adaptation, deriving important findings about when it performs well and what properties of the domains are important in this regard. Our experiments with StackExchange data show an average improvement of 5.6% over the best baseline across multiple pairs of domains."
1809.02232,2018-09-06 21:53:39,Automated Game Design via Conceptual Expansion,"Matthew Guzdial,Mark Riedl",https://arxiv.org/abs/1809.02232,    ,"7 pages, 3 figures, Artificial Intelligence and Interactive Digital Entertainment",cs.AI,cs.AI,"Automated game design has remained a key challenge within the field of Game AI. In this paper, we introduce a method for recombining existing games to create new games through a process called conceptual expansion. Prior automated game design approaches have relied on hand-authored or crowd-sourced knowledge, which limits the scope and applications of such systems. Our approach instead relies on  machine learning  to learn approximate representations of games. Our approach recombines knowledge from these learned representations to create new games via conceptual expansion. We evaluate this approach by demonstrating the ability for the system to recreate existing games. To the best of our knowledge, this represents the first  machine learning -based automated game design system."
1809.02268,2018-09-07 01:22:52,Computation of Total Kidney Volume from CT images in Autosomal Dominant Polycystic Kidney Disease using Multi-Task 3D Convolutional Neural Networks,"Deepak Keshwani,Yoshiro Kitamura,Yuanzhong Li",https://arxiv.org/abs/1809.02268,    ,"8 pages, 5 figures, To appear in the Proceedings of the 21st International Conference On Medical Image Computing & Computer Assisted Intervention, ",cs.CV,cs.CV,"Autosomal Dominant Polycystic Kidney Disease (ADPKD) characterized by progressive growth of renal cysts is the most prevalent and potentially lethal monogenic renal disease, affecting one in every 500-100 people. Total Kidney Volume (TKV) and its growth computed from Computed Tomography images has been accepted as an essential prognostic marker for renal function loss. Due to large variation in shape and size of kidney in ADPKD, existing methods to compute TKV (i.e. to segment ADKP) including those based on 2D convolutional neural networks are not accurate enough to be directly useful in clinical practice. In this work, we propose multi-task 3D Convolutional Neural Networks to segment ADPK and achieve a mean DICE score of 0.95 and mean absolute percentage TKV error of 3.86. Additionally, to solve the challenge of class imbalance, we propose to simply bootstrap cross entropy loss and compare results with recently prevalent dice loss in medical image segmentation community."
1809.02352,2018-09-07 08:38:02,Multi-Target Prediction: A Unifying View on Problems and Methods,"Willem Waegeman,Krzysztof Dembczynski,Eyke Huellermeier",https://arxiv.org/abs/1809.02352,,,stat.ML,"stat.ML,cs.LG","Multi-target prediction (MTP) is concerned with the simultaneous prediction of multiple target variables of diverse type. Due to its enormous application potential, it has developed into an active and rapidly expanding research field that combines several subfields of  machine learning , including multivariate regression, multi-label classification, multi-task learning, dyadic prediction, zero-shot learning, network inference, and matrix completion. In this paper, we present a unifying view on MTP problems and methods. First, we formally discuss commonalities and differences between existing MTP problems. To this end, we introduce a general framework that covers the above subfields as special cases. As a second contribution, we provide a structured overview of MTP methods. This is accomplished by identifying a number of key properties, which distinguish such methods and determine their suitability for different types of problems. Finally, we also discuss a few challenges for future research."
1805.11765,2018-09-02 11:31:11,Approximate LTL model checking,"Weijun Zhu,Shaohuan Ban,Yongwen Fan",https://arxiv.org/abs/1805.11765,    ,"13 pages, 7 figures",cs.LO,cs.LO,"The state explosion problem and the exponentially computational complexity restrict the further applications of LTL model checking. To this end, this study tries to seek an acceptable approximate solution for LTL model checking by introducing the  machine learning  (ML) technique, and a method for predicting results of LTL model checking via the Boosted Tree (BT) algorithm is proposed in this paper. First, for a number of Kripke structures and LTL formulas, a data set A containing their model checking results is obtained, using the existing LTL model checking algorithm. Second, the LTL model checking problem can be induced to a binary classification problem of  machine learning . In other words, some records in A form a training set for the BT algorithm. On the basis of it, a ML model M is obtained to predict the results of LTL model checking. As a result, an approximate LTL model checking technique occurs. The experiments show that the new method has the average accuracy of 95.6%, and its average efficiency is 2.67 million and 3.04 million times higher than that of the two representative model checking methods, respectively, if the length of each of LTL formulas equals to 500."
1805.11770,2018-09-06 21:03:43,AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks,"Chun-Chen Tu,Paishun Ting,Pin-Yu Chen,Sijia Liu,Huan Zhang,Jinfeng Yi,Cho-Jui Hsieh,Shin-Ming Cheng",https://arxiv.org/abs/1805.11770,    ,"Chun-Chen Tu, Paishun Ting and Pin-Yu Chen contribute equally to this work",cs.CV,"cs.CV,cs.CR,stat.ML","Recent studies have shown that adversarial examples in state-of-the-art image classifiers trained by deep neural networks (DNN) can be easily generated when the target model is transparent to an attacker, known as the white-box setting. However, when attacking a deployed  machine learning  service, one can only acquire the input-output correspondences of the target model; this is the so-called black-box attack setting. The major drawback of existing black-box attacks is the need for excessive model queries, which may give a false sense of model robustness due to inefficient query designs. To bridge this gap, we propose a generic framework for query-efficient black-box attacks. Our framework, AutoZOOM, which is short for Autoencoder-based Zeroth Order Optimization Method, has two novel building blocks towards efficient black-box attacks: (i) an adaptive random gradient estimation strategy to balance query counts and distortion, and (ii) an autoencoder that is either trained offline with unlabeled data or a bilinear resizing operation for attack acceleration. Experimental results suggest that, by applying AutoZOOM to a state-of-the-art black-box attack (ZOO), a significant reduction in model queries can be achieved without sacrificing the attack success rate and the visual quality of the resulting adversarial examples. In particular, when compared to the standard ZOO method, AutoZOOM can consistently reduce the mean query counts in finding successful adversarial examples (or reaching the same distortion level) by at least 93% on MNIST, CIFAR-10 and ImageNet datasets, leading to novel insights on adversarial robustness."
1805.12471,2018-09-11 03:34:37,Neural Network Acceptability Judgments,"Alex Warstadt,Amanpreet Singh,Samuel R. Bowman",https://arxiv.org/abs/1805.12471,    ,12 pages,cs.CL,cs.CL,"In this work, we explore the ability of artificial neural networks to judge the grammatical acceptability of a sentence.  machine learning  research of this kind is well placed to answer important open questions about the role of prior linguistic bias in language acquisition by providing a test for the Poverty of the Stimulus Argument. In service of this goal, we introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical by expert linguists. We train several recurrent neural networks to do binary acceptability classification. These models set a baseline for the task. Error-analysis testing the models on specific grammatical phenomena reveals that they learn some systematic grammatical generalizations like subject-verb-object word order without any grammatical supervision. We find that neural sequence models show promise on the acceptability classification task. However, human-like performance across a wide range of grammatical constructions remains far off."
1806.04819,2018-09-12 02:33:17,Integral Privacy for Sampling from Mollifier Densities with Approximation Guarantees,"Hisham Husain,Zac Cranko,Richard Nock",https://arxiv.org/abs/1806.04819,,,stat.ML,"stat.ML,cs.LG","Sampling encompasses old and central problems in statistics and  machine learning . There exists several approaches to cast this problem in a differential privacy framework but little is still comparatively known about the approximation guarantees of the unknown density by the private one learned. In this paper, we first introduce a general condition for a set of densities, called an $\varepsilon$-mollifier, to grant privacy for sampling in the $\varepsilon$-differential privacy model, and even in a stronger model where we remove the famed adjacency condition of inputs. We then show how to exploit the boosting toolkit to learn a density within an $\varepsilon$-mollifier with guaranteed approximation of the target density that degrade gracefully with the privacy budget. Approximation guarantees cover the mode capture problem, a problem which is receiving a lot of attention in the generative models literature. To our knowledge, the way we exploit the boosting toolkit has never been done before in the context of density estimation or sampling: we require access to a weak learner in the original boosting sense, so we learn a density out of \textit{classifiers}. Experimental results against a state of the art implementation of private kernel density estimation display that our technique consistently obtains improved results, managing in particular to get similar outputs for a privacy budget $ε$ which is however orders of magnitude smaller."
1806.05772,2018-09-05 18:45:12,Network analysis of synthesizable materials discovery,"Muratahan Aykol,Vinay I. Hegde,Santosh Suram,Linda Hung,Patrick Herring,Chris Wolverton,Jens S. Hummelshøj",https://arxiv.org/abs/1806.05772,    ,"6 pages, 4 figures, new figure added, text improved, typos corrected",cond-mat.mtrl-sci,"cond-mat.mtrl-sci,physics.comp-ph","Assessing the synthesizability of inorganic materials is a grand challenge for accelerating their discovery using computations.1-4 Synthesis of a material is a complex process that depends not only on its thermodynamic stability with respect to others, but also on factors from kinetics, to advances in synthesis techniques, to the availability of precursors. This complexity makes the development of a general theory or first-principles approach to synthesizability currently impractical.3,5 Here we show how an alternative pathway to predicting synthesizability emerges from the dynamics of the ""materials stability network"": a scale-free network constructed by combining the convex free-energy surface of inorganic materials computed by high-throughput density functional theory6-9 and their experimental discovery timelines extracted from citations. The time-evolution of the underlying network properties allows us to use  -  to predict the likelihood that hypothetical, computer-generated materials will be amenable to successful experimental synthesis. In other words, we can predict the synthesizability of novel compounds."
1806.07687,2018-09-05 12:47:39,"Automated Fact Checking: Task formulations, methods and future directions","James Thorne,Andreas Vlachos",https://arxiv.org/abs/1806.07687,    ,Published at the 27th International Conference on Computational Linguistics (COLING 2018),cs.CL,cs.CL,"The recently increased focus on misinformation has stimulated research in fact checking, the task of assessing the truthfulness of a claim. Research in automating this task has been conducted in a variety of disciplines including natural language processing,  machine learning , knowledge representation, databases, and journalism. While there has been substantial progress, relevant papers and articles have been published in research communities that are often unaware of each other and use inconsistent terminology, thus impeding understanding and further progress. In this paper we survey automated fact checking research stemming from natural language processing and related disciplines, unifying the task formulations and methodologies across papers and authors. Furthermore, we highlight the use of evidence as an important distinguishing factor among them cutting across task formulations and methods. We conclude with proposing avenues for future NLP research on automated fact checking."
1806.11554,2018-09-09 22:37:00,Crystal nucleation along an entropic pathway: Teaching liquids how to transition,"Caroline Desgranges,Jerome Delhommelle",https://arxiv.org/abs/1806.11554,,,physics.comp-ph,"physics.comp-ph,cond-mat.soft","We combine  machine learning  (ML) with Monte Carlo (MC) simulations to study the crystal nucleation process. Using ML, we evaluate the canonical partition function of the system over the range of densities and temperatures spanned during crystallization. We achieve this on the example of the Lennard-Jones system by training an artificial neural network using, as a reference dataset, equations of state for the Helmholtz free energy for the liquid and solid phases. The accuracy of the ML predictions is tested over a wide range of thermodynamic conditions, and results are shown to provide an accurate estimate for the canonical partition function, when compared to the results from flat-histogram simulations. Then, the ML predictions are used to calculate the entropy of the system during MC simulations in the isothermal-isobaric ensemble. This approach is shown to yield results in very good agreement with the experimental data for both the liquid and solid phases of Argon. Finally, taking entropy as a reaction coordinate and using the umbrella sampling technique, we are able to determine the Gibbs free energy profile for the crystal nucleation process. In particular, we obtain a free energy barrier in very good agreement with the results from previous simulation studies. The approach developed here can be readily extended to molecular systems and complex fluids, and is especially promising for the study of entropy-driven processes."
1807.04119,2018-09-11 12:30:54,Exploiting statistical dependencies of time series with hierarchical correlation reconstruction,Jarek Duda,https://arxiv.org/abs/1807.04119,    ,"8 pages, 9 figures",cs.LG,"cs.LG,stat.ML","While we are usually focused on forecasting future values of time series, it is often valuable to additionally predict their entire probability distributions, e.g. to evaluate risk, Monte Carlo simulations. On example of time series of $\approx$ 30000 Dow Jones Industrial Averages, there will be presented application of hierarchical correlation reconstruction for this purpose: mean-square estimating polynomial as joint density for (current value, context), where context is for example a few previous values. Then substituting the currently observed context and normalizing density to 1, we get predicted probability distribution for the current value. In contrast to standard  machine learning  approaches like neural networks, optimal polynomial coefficients here can be inexpensively directly calculated, have controllable accuracy, are unique and independent, each has a specific cumulant-like interpretation, and such approximation using can approach complete description of any real joint distribution - providing a perfect tool to quantitatively describe and exploit statistical dependencies in time series. There is also discussed application for non-stationary time series like calculating linear time trend, or adapting coefficients to local statistical behavior."
1807.05051,2018-09-07 11:31:05,Many-body (de)localization in large quantum chains,"Elmer V. H. Doggen,Frank Schindler,Konstantin S. Tikhonov,Alexander D. Mirlin,Titus Neupert,Dmitry G. Polyakov,Igor V. Gornyi",https://arxiv.org/abs/1807.05051,    ,"14 pages, 11 figures. Comments welcome",cond-mat.dis-nn,"cond-mat.dis-nn,cond-mat.str-el","We theoretically study the quench dynamics for an isolated Heisenberg spin chain with a random on-site magnetic field, which is one of the paradigmatic models of a many-body localization transition. We use the time-dependent variational principle as applied to matrix product states, which allows us to controllably study chains of a length up to $L=100$ spins, i.e., much larger than $L \simeq 20$ that can be treated via exact diagonalization. For the analysis of the data, three complementary approaches are used: (i) determination of the exponent $β$ which characterizes the power-law decay of the antiferromagnetic imbalance with time; (ii) similar determination of the exponent $β_Λ$ which characterizes the decay of a Schmidt gap in the entanglement spectrum, (iii)  machine learning  with the use, as an input, of the time dependence of the spin densities in the whole chain. We find that the consideration of the larger system sizes substantially increases the estimate for the critical disorder $W_c$ that separates the ergodic and many-body localized regimes, compared to the values of $W_c$ in the literature. On the ergodic side of the transition, there is a broad interval of the strength of disorder with slow subdiffusive transport. In this regime, the exponents $β$ and $β_Λ$ increase, with increasing $L$, for relatively small $L$ but saturate for $L \simeq 50$, indicating that these slow power laws survive in the thermodynamic limit. From a technical perspective, we develop an adaptation of the ""learning by confusion""  machine learning  approach that can determine $W_c$."
1807.05605,2018-09-07 18:35:43,Characterization of Model-Based Uncertainties in Incompressible Turbulent Flows by,"Mustafa Usta,Ali Tosyali",https://arxiv.org/abs/1807.05605,    ,ASME IMECE 2018,physics.flu-dyn,physics.flu-dyn,"This work determines the inaccuracy of using Reynolds averaged Navier Stokes (RANS) turbulence models in transition to turbulent flow regimes by predicting the model-based discrepancies between RANS and large eddy simulation (LES) models and then incorporates the capabilities of  machine learning  algorithms to characterize the discrepancies which are defined as a function of mean flow properties of RANS simulations. First, three-dimensional CFD simulations using k-omega Shear Stress Transport (SST) and dynamic one-equation subgrid-scale models are conducted in a wall-bounded channel containing a cylinder for RANS and LES, respectively, to identify the turbulent kinetic energy discrepancy. Second, several flow features such as viscosity ratio, wall-distance based Reynolds number, and vortex stretching are calculated from the mean flow properties of RANS. Then these flow features are regressed onto the discrepancy using a Random Forests regression algorithm. Finally, the discrepancy of the test flow is predicted using the trained algorithm. The results reveal that a significant discrepancy exists between RANS and LES simulations and ML algorithm successfully predicts the increased model uncertainties caused by the employment of k-omega SST turbulence model for transitional fluid flows."
1807.07215,2018-09-03 05:46:13,A,"Sarah Cornell-Farrow,Robert Garrard",https://arxiv.org/abs/1807.07215,    ,"20 pages, 6 tables, 6 figures",stat.ML,"stat.ML,cs.LG,econ.EM","We aim to predict whether a primary school student will perform in the `below standard' band of a national standardized test. We exploit a data set containing test performance on the National Assessment Program - Literacy and Numeracy (NAPLAN); a test given annually to all Australian school students in grades 3, 5, 7, and 9. We separate the analysis into students in grade 5 and above, for which previous achievement may be used as a predictor; and students in grade 3, which must rely on family- and school-level predictors only. We train and compare a set of classifiers for reading and numeracy learning areas respectively. The classifiers achieve good predictive power in terms of area under the ROC curve, suggesting that it is feasible for schools to more accurately screen a large number of students for academic risk."
1807.07680,2018-09-07 20:54:22,"Generalized Stochastic Frank-Wolfe Algorithm with Stochastic ""Substitute"" Gradient for Structured Convex Optimization","Haihao Lu,Robert M. Freund",https://arxiv.org/abs/1807.07680,,,math.OC,math.OC,"The stochastic Frank-Wolfe method has recently attracted much general interest in the context of optimization for statistical and  machine learning  due to its ability to work with a more general feasible region. However, there has been a complexity gap in the guaranteed convergence rate for stochastic Frank-Wolfe compared to its deterministic counterpart. In this work, we present a new stochastic Frank-Wolfe method which closes this gap by introducing the notion of a `substitute' gradient"" that is a not-necessarily unbiased sample of the gradient. Moreover, we show that this new approach is equivalent to a randomized coordinate mirror descent algorithm applied to the dual problem, which in turn provides a new interpretation of dual coordinate descent method in the primal space. When the regularizer is furthermore strongly convex, we show that the generalized stochastic Frank-Wolfe method as well as the randomized dual coordinate descent present linear convergence. These new results are benefited from the understanding that first-order methods can inherently minimize the primal-dual gap."
1807.06403,2018-09-10 10:08:43,Iterative Residual Network for Deep Joint Image Demosaicking and Denoising,"Filippos Kokkinos,Stamatios Lefkimmiatis",https://arxiv.org/abs/1807.06403,    ,Code and results can be found at https://github.com/cig-skoltech/deep_demosaick. arXiv admin note: text overlap with arXiv:1803.05215,cs.CV,cs.CV,"Modern digital cameras rely on sequential execution of separate image processing steps to produce realistic images. The first two steps are usually related to denoising and demosaicking where the former aims to reduce noise from the sensor and the latter converts a series of light intensity readings to color images. Modern approaches try to jointly solve these problems, i.e joint denoising-demosaicking which is an inherently ill-posed problem given that two-thirds of the intensity information are missing and the rest are perturbed by noise. While there are several  machine learning  systems that have been recently introduced to tackle this problem, in this work we propose a novel algorithm which is inspired by powerful classical image regularization methods, large-scale optimization and deep learning techniques. Consequently, our derived iterative neural network has a transparent and clear interpretation compared to other black-box data driven approaches. The extensive comparisons that we report demonstrate the superiority of our proposed network, which outperforms any previous approaches on both noisy and noise-free data across many different datasets using less training samples. This improvement in reconstruction quality is attributed to the principled way we design and train our network architecture, which as a result requires fewer trainable parameters than the current state-of-the-art solution."
1807.08108,2018-09-10 02:13:28,Simultaneous Adversarial Training - Learn from Others Mistakes,Zukang Liao,https://arxiv.org/abs/1807.08108,,,cs.CV,"cs.CV,cs.LG,stat.ML","Adversarial examples are maliciously tweaked images that can easily fool  machine learning  techniques, such as neural networks, but they are normally not visually distinguishable for human beings. One of the main approaches to solve this problem is to retrain the networks using those adversarial examples, namely adversarial training. However, standard adversarial training might not actually change the decision boundaries but cause the problem of gradient masking, resulting in a weaker ability to generate adversarial examples. Therefore, it cannot alleviate the problem of black-box attacks, where adversarial examples generated from other networks can transfer to the targeted one. In order to reduce the problem of black-box attacks, we propose a novel method that allows two networks to learn from each others' adversarial examples and become resilient to black-box attacks. We also combine this method with a simple domain adaptation to further improve the performance."
1807.09586,2018-09-04 11:30:12,Perturb and Combine to Identify Influential Spreaders in Real-World Networks,"Antoine J. -P. Tixier,Maria-Evgenia G. Rossi,Fragkiskos D. Malliaros,Jesse Read,Michalis Vazirgiannis",https://arxiv.org/abs/1807.09586,    ,More compact format,cs.SI,"cs.SI,cs.LG,stat.ML","Recent research has shown that graph degeneracy algorithms, which decompose a network into a hierarchy of nested subgraphs of decreasing size and increasing density, are very effective at detecting the good spreaders in a network. However, it is also known that degeneracy-based decompositions of a graph are unstable to small perturbations of the network structure. In  machine learning , the performance of unstable classification and regression methods, such as fully-grown decision trees, can be greatly improved by using Perturb and Combine (P&C) strategies such as bagging (bootstrap aggregating). Therefore, we propose a P&C procedure for networks that (1) creates many perturbed versions of a given graph, (2) applies a node scoring function separately to each graph (such as a degeneracy-based one), and (3) combines the results. We conduct real-world experiments on the tasks of identifying influential spreaders in large social networks, and influential words (keywords) in small word co-occurrence networks. We use the k-core, generalized k-core, and PageRank algorithms as our vertex scoring functions. In each case, using the aggregated scores brings significant improvements compared to using the scores computed on the original graphs. Finally, a bias-variance analysis suggests that our P&C procedure works mainly by reducing bias, and that therefore, it should be capable of improving the performance of all vertex scoring functions, not only unstable ones."
1807.10261,2018-09-11 09:35:58,Novelty Detection Meets Collider Physics,"Jan Hajer,Ying-Ying Li,Tao Liu,He Wang",https://arxiv.org/abs/1807.10261,    ,6 pages. 5 figures. Version for journal submission. Comments are welcome,hep-ph,"hep-ph,cs.LG,hep-ex","Novelty detection is the  machine learning  task to recognize data, which belong to an unknown pattern. Complementary to supervised learning, it allows to analyze data model-independently. We demonstrate the potential role of novelty detection in collider physics, using autoencoder-based deep neural network. Explicitly, we develop a set of density-based novelty evaluators, which are sensitive to the clustering of unknown-pattern testing data or new-physics signal events, for the design of detection algorithms. We also explore the influence of the known-pattern data fluctuations, arising from non-signal regions, on detection sensitivity. Strategies to address it are proposed. The algorithms are applied to detecting fermionic di-top partner and resonant di-top productions at LHC, and exotic Higgs decays of two specific modes at a $e^+e^-$ future collider. With parton-level analysis, we conclude that potentially the new-physics benchmarks can be recognized with high efficiency."
1807.11876,2018-09-12 10:32:07,Predicting Solution Summaries to Integer Linear Programs under Imperfect Information with,"Eric Larsen,Sébastien Lachapelle,Yoshua Bengio,Emma Frejinger,Simon Lacoste-Julien,Andrea Lodi",https://arxiv.org/abs/1807.11876,,,cs.LG,"cs.LG,stat.ML","The paper provides a methodological contribution at the intersection of  machine learning  and operations research. Namely, we propose a methodology to quickly predict solution summaries (i.e., solution descriptions at a given level of detail) to discrete stochastic optimization problems. We approximate the solutions based on supervised learning and the training dataset consists of a large number of deterministic problems that have been solved independently and offline. Uncertainty regarding a missing subset of the inputs is addressed through sampling and aggregation methods.
  Our motivating application concerns booking decisions of intermodal containers on double-stack trains. Under perfect information, this is the so-called load planning problem and it can be formulated by means of integer linear programming. However, the formulation cannot be used for the application at hand because of the restricted computational budget and unknown container weights. The results show that standard deep learning algorithms allow one to predict descriptions of solutions with high accuracy in very short time (milliseconds or less)."
1808.01531,2018-09-11 19:41:27,Global Convergence to the Equilibrium of GANs using Variational Inequalities,"Ian Gemp,Sridhar Mahadevan",https://arxiv.org/abs/1808.01531,,,cs.LG,"cs.LG,stat.ML","In optimization, the negative gradient of a function denotes the direction of steepest descent. Furthermore, traveling in any direction orthogonal to the gradient maintains the value of the function. In this work, we show that these orthogonal directions that are ignored by gradient descent can be critical in equilibrium problems. Equilibrium problems have drawn heightened attention in  machine learning  due to the emergence of the Generative Adversarial Network (GAN). We use the framework of Variational Inequalities to analyze popular training algorithms for a fundamental GAN variant: the Wasserstein Linear-Quadratic GAN. We show that the steepest descent direction causes divergence from the equilibrium, and guaranteed convergence to the equilibrium is achieved through following a particular orthogonal direction. We call this successful technique Crossing-the-Curl, named for its mathematical derivation as well as its intuition: identify the game's axis of rotation and move ""across"" space in the direction towards smaller ""curling""."
1808.01630,2018-09-01 16:29:56,A Review of Learning with Deep Generative Models from perspective of graphical modeling,Zhijian Ou,https://arxiv.org/abs/1808.01630,    ,"add SN-GANs, SA-GANs, conditional generation (cGANs, AC-GANs)",cs.LG,"cs.LG,stat.ML","This document aims to provide a review on learning with deep generative models (DGMs), which is an highly-active area in  machine learning  and more generally, artificial intelligence. This review is not meant to be a tutorial, but when necessary, we provide self-contained derivations for completeness. This review has two features. First, though there are different perspectives to classify DGMs, we choose to organize this review from the perspective of graphical modeling, because the learning methods for directed DGMs and undirected DGMs are fundamentally different. Second, we differentiate model definitions from model learning algorithms, since different learning algorithms can be applied to solve the learning problem on the same model, and an algorithm can be applied to learn different models. We thus separate model definition and model learning, with more emphasis on reviewing, differentiating and connecting different learning algorithms. We also discuss promising future research directions."
1808.01696,2018-09-03 21:46:29,Physically-informed artificial neural networks for atomistic modeling of materials,"G. P. Purja Pun,R. Batra,R. Ramprasad,Y. Mishin",https://arxiv.org/abs/1808.01696,,,cond-mat.mtrl-sci,cond-mat.mtrl-sci,"Large-scale atomistic computer simulations of materials heavily rely on interatomic potentials predicting the potential energy and Newtonian forces on atoms. Traditional interatomic potentials are based on physical intuition but contain few adjustable parameters and are usually not accurate. The emerging  -  (ML) potentials achieve highly accurate interpolation between the energies in a large DFT database but, being purely mathematical constructions, suffer from poor transferability to unknown structures. We propose a new approach that can drastically improve the transferability of ML potentials by informing them of the physical nature of interatomic bonding. This is achieved by combining a rather general physics-based model (analytical bond-order potential) with a neural-network regression. The network adjusts the parameters of the physics-based model on the fly during the simulations according to the local environments of individual atoms. This approach, called the physically-informed neural network (PINN) potential, is demonstrated by developing a general-purpose PINN potential for Al. The potential provides a DFT-level accuracy of energy predictions and excellent agreement with experimental and DFT data for a wide range of physical properties. We suggest that the development of physics-based ML potentials is the most effective way forward in the field of atomistic simulations."
1808.05754,2018-09-04 12:41:39,Auto-Classification of Retinal Diseases in the Limit of Sparse Data Using a Two-Streams,"C. -H. Huck Yang,Fangyu Liu,Jia-Hong Huang,Meng Tian,Yi-Chieh Liu,I-Hung Lin,Jesper Tegner",https://arxiv.org/abs/1808.05754,    ,A extension work of a workshop paper (did not published in the proceeding ) arXiv admin note: substantial text overlap with arXiv:1806.06423,cs.CV,cs.CV,"Automatic clinical diagnosis of retinal diseases has emerged as a promising approach to facilitate discovery in areas with limited access to specialists. Based on the fact that fundus structure and vascular disorders are the main characteristics of retinal diseases, we propose a novel visual-assisted diagnosis hybrid model mixing the support vector machine (SVM) and deep neural networks (DNNs). Furthermore, we present a new clinical retina dataset, called EyeNet2, for ophthalmology incorporating 52 retina diseases classes. Using EyeNet2, our model achieves 90.43\% diagnosis accuracy, and the model performance is comparable to the professional ophthalmologists."
1703.00864,2018-09-03 08:55:55,The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings,"Krzysztof Choromanski,Mark Rowland,Adrian Weller",https://arxiv.org/abs/1703.00864,,,stat.ML,"stat.ML,stat.CO","We examine a class of embeddings based on structured random matrices with orthogonal rows which can be applied in many  machine learning  applications including dimensionality reduction and kernel approximation. For both the Johnson-Lindenstrauss transform and the angular kernel, we show that we can select matrices yielding guaranteed improved performance in accuracy and/or speed compared to earlier methods. We introduce matrices with complex entries which give significant further accuracy improvement. We provide geometric and Markov chain-based perspectives to help understand the benefits, and empirical results which suggest that the approach is helpful in a wider range of applications."
1808.07216,2018-09-08 16:17:09,Model Interpretation: A Unified Derivative-based Framework for Nonparametric Regression and Supervised,"Xiaoyu Liu,Jie Chen,Joel Vaughan,Vijayan Nair,Agus Sudjianto",https://arxiv.org/abs/1808.07216,,,stat.ML,"stat.ML,cs.LG","Interpreting a nonparametric regression model with many predictors is known to be a challenging problem. There has been renewed interest in this topic due to the extensive use of  machine learning  algorithms and the difficulty in understanding and explaining their input-output relationships. This paper develops a unified framework using a derivative-based approach for existing tools in the literature, including the partial-dependence plots, marginal plots and accumulated effects plots. It proposes a new interpretation technique called the accumulated total derivative effects plot and demonstrates how its components can be used to develop extensive insights in complex regression models with correlated predictors. The techniques are illustrated through simulation results."
1804.08685,2018-09-07 15:38:04,Crawling in Rogue's dungeons with (partitioned) A3C,"Andrea Asperti,Daniele Cortesi,Francesco Sovrano",https://arxiv.org/abs/1804.08685,"          I.2.6
        
      ",Accepted at the Fourth International Conference on ,cs.LG,"cs.LG,stat.ML","Rogue is a famous dungeon-crawling video-game of the 80ies, the ancestor of its gender. Rogue-like games are known for the necessity to explore partially observable and always different randomly-generated labyrinths, preventing any form of level replay. As such, they serve as a very natural and challenging task for reinforcement learning, requiring the acquisition of complex, non-reactive behaviors involving memory and planning. In this article we show how, exploiting a version of A3C partitioned on different situations, the agent is able to reach the stairs and descend to the next level in 98% of cases."
1505.00398,2018-09-12 21:48:23,Block Basis Factorization for Scalable Kernel Matrix Evaluation,"Ruoxi Wang,Yingzhou Li,Michael W. Mahoney,Eric Darve",https://arxiv.org/abs/1505.00398,    ,"16 pages, 5 figures",stat.ML,"stat.ML,cs.LG,cs.NA","Kernel methods are widespread in  machine learning ; however, they are limited by the quadratic complexity of the construction, application, and storage of kernel matrices. Low-rank matrix approximation algorithms are widely used to address this problem and reduce the arithmetic and storage cost. However, we observed that for some datasets with wide intra-class variability, the optimal kernel parameter for smaller classes yields a matrix that is less well approximated by low-rank methods. In this paper, we propose an efficient structured low-rank approximation method---the Block Basis Factorization (BBF)---and its fast construction algorithm to approximate radial basis function (RBF) kernel matrices. Our approach has linear memory cost and floating point operations. BBF works for a wide range of kernel bandwidth parameters and extends the domain of applicability of low-rank approximation methods significantly. Our empirical results demonstrate the stability and superiority over the state-of-art kernel approximation algorithms."
1608.08306,2018-09-02 03:39:34,,"Faris B. Mismar,Brian L. Evans",https://arxiv.org/abs/1608.08306,    ,"4 pages, 3 figures, to be submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing 2019",stat.ML,"stat.ML,cs.NI",We propose a method for practical downlink coordinated multipoint (DL CoMP) implementation in the fifth generation of wireless communications (5G) also known as New Radio (NR). We base our method on supervised  machine learning . Contributions of this paper are to 1) demonstrate that a support vector machine (SVM) classifier can learn improved conditions at which DL CoMP can be dynamically triggered in a scalable realistic environment and 2) increase user throughput in a heterogeneous network as a result of learning improved triggering conditions of CoMP. Our simulation results show an improvement in both the macro and pico base station peak throughputs due to the informed triggering of the multiple DL CoMP radio streams as learned from the SVM classifier.
1610.00168,2018-09-07 17:18:35,Learning Optimized Risk Scores,"Berk Ustun,Cynthia Rudin",https://arxiv.org/abs/1610.00168,,,stat.ML,"stat.ML,math.OC,stat.ME","Risk scores are simple classification models that let users make quick risk predictions by adding and subtracting a few small numbers. These models are widely used in medicine and criminal justice, but are difficult to learn from data because they need to be calibrated, sparse, use small integer coefficients and obey application-specific constraints. In this paper, we present a new  machine learning  approach to learn risk scores. We formulate the risk score problem as a mixed integer nonlinear program, and present a new cutting plane algorithm for non-convex settings to efficiently recover its optimal solution. We improve our algorithm with specialized techniques to generate feasible solutions, narrow the optimality gap, and reduce data-related computation. Our approach can fit risk scores in a way that scales linearly in the number of samples, provides a certificate of optimality, and obeys real-world constraints without parameter tuning or post-processing. We illustrate the performance benefits of this approach through an extensive set of numerical experiments, where we compare risk scores built using our approach to those built using heuristic approaches. We also discuss the practical benefits of our approach through an application where we build a customized risk score for ICU seizure prediction in collaboration with the Massachusetts General Hospital."
1611.07612,2018-09-05 19:35:03,Faster Population Counts Using AVX2 Instructions,"Wojciech Muła,Nathan Kurz,Daniel Lemire",https://arxiv.org/abs/1611.07612,"        Computer Journal, Volume 61, Issue 1, 1 January 2018
      ",Software is at https://github.com/CountOnes/hamming_weight,cs.DS,cs.DS,"Counting the number of ones in a binary stream is a common operation in database, information-retrieval, cryptographic and  -  applications. Most processors have dedicated instructions to count the number of ones in a word (e.g., popcnt on x64 processors). Maybe surprisingly, we show that a vectorized approach using SIMD instructions can be twice as fast as using the dedicated instructions on recent Intel processors. The benefits can be even greater for applications such as similarity measures (e.g., the Jaccard index) that require additional Boolean operations. Our approach has been adopted by LLVM: it is used by its popular C compiler (clang)."
1612.06003,2018-09-08 12:38:31,Inexact Proximal Gradient Methods for Non-convex and Non-smooth Optimization,"Bin Gu,De Wang,Zhouyuan Huo,Heng Huang",https://arxiv.org/abs/1612.06003,    ,AAAI 2018,cs.LG,"cs.LG,stat.ML","In  machine learning  research, the proximal gradient methods are popular for solving various optimization problems with non-smooth regularization. Inexact proximal gradient methods are extremely important when exactly solving the proximal operator is time-consuming, or the proximal operator does not have an analytic solution. However, existing inexact proximal gradient methods only consider convex problems. The knowledge of inexact proximal gradient methods in the non-convex setting is very limited. % Moreover, for some  machine learning  models, there is still no proposed solver for exactly solving the proximal operator. To address this challenge, in this paper, we first propose three inexact proximal gradient algorithms, including the basic version and Nesterov's accelerated version. After that, we provide the theoretical analysis to the basic and Nesterov's accelerated versions. The theoretical results show that our inexact proximal gradient algorithms can have the same convergence rates as the ones of exact proximal gradient algorithms in the non-convex setting.
  Finally, we show the applications of our inexact proximal gradient algorithms on three representative non-convex learning problems. All experimental results confirm the superiority of our new inexact proximal gradient algorithms."
1710.00760,2018-09-09 00:30:18,Scalable Nonlinear AUC Maximization Methods,"Majdi Khalid,Indrakshi Ray,Hamidreza Chitsaz",https://arxiv.org/abs/1710.00760,,,cs.LG,cs.LG,"The area under the ROC curve (AUC) is a measure of interest in various  machine learning  and data mining applications. It has been widely used to evaluate classification performance on heavily imbalanced data. The kernelized AUC maximization machines have established a superior generalization ability compared to linear AUC machines because of their capability in modeling the complex nonlinear structure underlying most real-world data. However, the high training complexity renders the kernelized AUC machines infeasible for large-scale data. In this paper, we present two nonlinear AUC maximization algorithms that optimize pairwise linear classifiers over a finite-dimensional feature space constructed via the k-means Nyström method. Our first algorithm maximize the AUC metric by optimizing a pairwise squared hinge loss function using the truncated Newton method. However, the second-order batch AUC maximization method becomes expensive to optimize for extremely massive datasets. This motivate us to develop a first-order stochastic AUC maximization algorithm that incorporates a scheduled regularization update and scheduled averaging techniques to accelerate the convergence of the classifier. Experiments on several benchmark datasets demonstrate that the proposed AUC classifiers are more efficient than kernelized AUC machines while they are able to surpass or at least match the AUC performance of the kernelized AUC machines. The experiments also show that the proposed stochastic AUC classifier outperforms the state-of-the-art online AUC maximization methods in terms of AUC classification accuracy."
1708.07469,2018-09-05 19:39:17,DGM: A deep learning algorithm for solving partial differential equations,"Justin Sirignano,Konstantinos Spiliopoulos",https://arxiv.org/abs/1708.07469,    ,"Deep learning, ",q-fin.MF,"q-fin.MF,math.NA,q-fin.CP,stat.ML","High-dimensional PDEs have been a longstanding computational challenge. We propose to solve high-dimensional PDEs by approximating the solution with a deep neural network which is trained to satisfy the differential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary PDEs, which we are able to accurately solve in up to $200$ dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE and Burgers' equation. The deep learning algorithm approximates the general solution to the Burgers' equation for a continuum of different boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a ""Deep Galerkin Method (DGM)"" since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic PDEs."
1710.02605,2018-09-03 08:17:54,Combined,"Rajesh Jha,Nirupam Chakraborti,David Diercks,Aaron Stebner,Cristian V. Ciobanu",https://arxiv.org/abs/1710.02605,"        Computational Materials Science 150(2018), 202-211
      ","10 pages, 15 figures",cond-mat.mtrl-sci,cond-mat.mtrl-sci,"We aim to investigate relationships between select processing parameters or inputs (composition, temperature, annealing time) and two structural parameters, specifically, the mean radius and volume fraction of the Fe$_3$Si nanocrystals. To this end, we have deviced a combined CALPHAD and  machine learning  approach that led to well-calibrated metamodels able to predict structural parameters quickly and accurately for any desired inputs. In order to generate data for the mean radius and volume fraction of Fe$_3$Si nanocrystals, we have used a precipitation model based in the software Thermocalc to perform annealing simulations at a set of temperatures (490-550~\degree C) and for varying Fe and Si concentrations (Fe$_{72.89 +x}$Si$_{16.21-x}$B$_{6.90}$Nb$_{3}$Cu$_{1}$, $-3\leq x \leq 3$ atomic \%). Thereafter, we used the data to develop metamodels for the mean radius and volume fraction via the \emph{k}-Nearest Neighbour algorithm. The metamodels are shown to reproduce closely the trends obtained from the precipitation model over the entire annealing timescale. Our further analysis via parallel coordinate charts shows the effect of composition, temperature, and annealing time, and helps identify combinations thereof that lead to the desired mean radius and volume fraction for the nanocrystalline phase. This approach utilizes experimental (thermodynamic and kinetic) databases from the CALPHAD approach so as to capture the physics of nucleation and growth, while the  machine learning  algorithm provides the robustness needed to analyze the effects of processing parameters for this complex precipitation problem. This work contributes to understanding the linkages between processing parameters and desired microstructural characteristics (crystal size and volume fraction) responsible for achieving targeted properties, and illustrates ways to reduce the time from alloy discovery to deployment."
1710.03213,2018-09-11 13:48:57,,Peiyuan Teng,https://arxiv.org/abs/1710.03213,,,quant-ph,"quant-ph,cond-mat.dis-nn,physics.comp-ph","Inspired by the recent work of Carleo and Troyer[1], we apply  machine learning  methods to quantum mechanics in this article. The radial basis function network in a discrete basis is used as the variational wavefunction for the ground state of a quantum system. Variational Monte Carlo(VMC) calculations are carried out for some simple Hamiltonians. The results are in good agreements with theoretical values. The smallest eigenvalue of a Hermitian matrix can also be acquired using VMC calculations. Our results demonstrate that  machine learning  techniques are capable of solving quantum mechanical problems."
1710.05724,2018-09-04 14:01:33,Reactive Planar Manipulation with Convex Hybrid MPC,"Francois Robert Hogan,Eudald Romo Grau,Alberto Rodriguez",https://arxiv.org/abs/1710.05724,,,cs.RO,cs.RO,"This paper presents a reactive controller for planar manipulation tasks that leverages  machine learning  to achieve real-time performance. The approach is based on a Model Predictive Control (MPC) formulation, where the goal is to find an optimal sequence of robot motions to achieve a desired object motion. Due to the multiple contact modes associated with frictional interactions, the resulting optimization program suffers from combinatorial complexity when tasked with determining the optimal sequence of modes.
  To overcome this difficulty, we formulate the search for the optimal mode sequences offline, separately from the search for optimal control inputs online. Using tools from  machine learning , this leads to a convex hybrid MPC program that can be solved in real-time. We validate our algorithm on a planar manipulation experimental setup where results show that the convex hybrid MPC formulation with learned modes achieves good closed-loop performance on a trajectory tracking problem."
1711.06505,2018-09-04 09:11:57,Image Matters: Visually modeling user behaviors using Advanced Model Server,"Tiezheng Ge,Liqin Zhao,Guorui Zhou,Keyu Chen,Shuying Liu,Huimin Yi,Zelin Hu,Bochao Liu,Peng Sun,Haoyu Liu,Pengtao Yi,Sui Huang,Zhiqiang Zhang,Xiaoqiang Zhu,Yu Zhang,Kun Gai",https://arxiv.org/abs/1711.06505,    ,CIKM 2018,cs.CV,cs.CV,"In Taobao, the largest e-commerce platform in China, billions of items are provided and typically displayed with their images. For better user experience and business effectiveness, Click Through Rate (CTR) prediction in online advertising system exploits abundant user historical behaviors to identify whether a user is interested in a candidate ad. Enhancing behavior representations with user behavior images will help understand user's visual preference and improve the accuracy of CTR prediction greatly. So we propose to model user preference jointly with user behavior ID features and behavior images. However, training with user behavior images brings tens to hundreds of images in one sample, giving rise to a great challenge in both communication and computation. To handle these challenges, we propose a novel and efficient distributed  machine learning  paradigm called Advanced Model Server (AMS). With the well known Parameter Server (PS) framework, each server node handles a separate part of parameters and updates them independently. AMS goes beyond this and is designed to be capable of learning a unified image descriptor model shared by all server nodes which embeds large images into low dimensional high level features before transmitting images to worker nodes. AMS thus dramatically reduces the communication load and enables the arduous joint training process. Based on AMS, the methods of effectively combining the images and ID features are carefully studied, and then we propose a Deep Image CTR Model. Our approach is shown to achieve significant improvements in both online and offline evaluations, and has been deployed in Taobao display advertising system serving the main traffic."
1711.06664,2018-09-07 00:48:55,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer,"David Madras,Toniann Pitassi,Richard Zemel",https://arxiv.org/abs/1711.06664,    ,Accepted as a conference paper at Neural Information Processing Systems 2018,stat.ML,"stat.ML,cs.LG","In many  machine learning  applications, there are multiple decision-makers involved, both automated and human. The interaction between these agents often goes unaddressed in algorithmic development. In this work, we explore a simple version of this interaction with a two-stage framework containing an automated model and an external decision-maker. The model can choose to say ""Pass"", and pass the decision downstream, as explored in rejection learning. We extend this concept by proposing ""learning to defer"", which generalizes rejection learning by considering the effect of other agents in the decision-making process. We propose a learning algorithm which accounts for potential biases held by external decision-makers in a system. Experiments demonstrate that learning to defer can make systems not only more accurate but also less biased. Even when working with inconsistent or biased users, we show that deferring models still greatly improve the accuracy and/or fairness of the entire system."
1712.00961,2018-09-08 08:17:44,Learning Independent Causal Mechanisms,"Giambattista Parascandolo,Niki Kilbertus,Mateo Rojas-Carulla,Bernhard Schölkopf",https://arxiv.org/abs/1712.00961,", PMLR 80:4036-4044, 2018
      ",ICML 2018,cs.LG,"cs.LG,stat.ML","Statistical learning relies upon data sampled from a distribution, and we usually do not care what actually generated it in the first place. From the point of view of causal modeling, the structure of each distribution is induced by physical mechanisms that give rise to dependences between observables. Mechanisms, however, can be meaningful autonomous modules of generative models that make sense beyond a particular entailed data distribution, lending themselves to transfer between problems. We develop an algorithm to recover a set of independent (inverse) mechanisms from a set of transformed data points. The approach is unsupervised and based on a set of experts that compete for data generated by the mechanisms, driving specialization. We analyze the proposed method in a series of experiments on image data. Each expert learns to map a subset of the transformed data back to a reference distribution. The learned mechanisms generalize to novel domains. We discuss implications for transfer learning and links to recent trends in generative modeling."
1712.04573,2018-09-12 07:22:36,Online Nonlinear Estimation via Iterative L2-Space Projections: Reproducing Kernel of Subspace,"Motoya Ohnishi,Masahiro Yukawa",https://arxiv.org/abs/1712.04573,"        IEEE Trans. Signal Processing. Vol. 66, No. 15, August 1, 2018
      ","Published in IEEE Trans. Signal Processing This is not the published version, but is the accepted version. Please refer https://ieeexplore.ieee.org/document/8379456/?arnumber=8379456&source=authoralert for the published version",eess.SP,eess.SP,"We propose a novel online learning paradigm for nonlinear-function estimation tasks based on the iterative projections in the L2 space with probability measure reflecting the stochastic property of input signals. The proposed learning algorithm exploits the reproducing kernel of the so-called dictionary subspace, based on the fact that any finite-dimensional space of functions has a reproducing kernel characterized by the Gram matrix. The L2-space geometry provides the best decorrelation property in principle. The proposed learning paradigm is significantly different from the conventional kernel-based learning paradigm in two senses: (i) the whole space is not a reproducing kernel Hilbert space and (ii) the minimum mean squared error estimator gives the best approximation of the desired nonlinear function in the dictionary subspace. It preserves efficiency in computing the inner product as well as in updating the Gram matrix when the dictionary grows. Monotone approximation, asymptotic optimality, and convergence of the proposed algorithm are analyzed based on the variable-metric version of adaptive projected subgradient method. Numerical examples show the efficacy of the proposed algorithm for real data over a variety of methods including the extended Kalman filter and many batch  -  methods such as the multilayer perceptron."
1712.06979,2018-09-05 10:31:33,An Automorphic Distance Metric and its Application to Node Embedding for Role Mining,"Víctor Martínez,Fernando Berzal,Juan-Carlos Cubero",https://arxiv.org/abs/1712.06979,,,cs.SI,"cs.SI,physics.soc-ph","Role is a fundamental concept in the analysis of the behavior and function of interacting entities represented by network data. Role discovery is the task of uncovering hidden roles. Node roles are commonly defined in terms of equivalence classes, where two nodes have the same role if they fall within the same equivalence class. Automorphic equivalence, where two nodes are equivalent when they can swap their labels to form an isomorphic graph, captures this common notion of role. The binary concept of equivalence is too restrictive and nodes in real-world networks rarely belong to the same equivalence class. Instead, a relaxed definition in terms of similarity or distance is commonly used to compute the degree to which two nodes are equivalent. In this paper, we propose a novel distance metric called automorphic distance, which measures how far two nodes are of being automorphically equivalent. We also study its application to node embedding, showing how our metric can be used to generate vector representations of nodes preserving their roles for data visualization and  machine learning . Our experiments confirm that the proposed metric outperforms the RoleSim automorphic equivalence-based metric in the generation of node embeddings for different networks."
1712.01272,2018-09-12 08:22:24,Layer-wise Learning of Stochastic Neural Networks with Information Bottleneck,"Thanh T. Nguyen,Jaesik Choi",https://arxiv.org/abs/1712.01272,    ,11 pages,cs.LG,cs.LG,"Deep neural networks (DNNs) offer flexible modeling capability for various important  machine learning  problems. Given the same neural modeling capability, the success of DNNs is attributed to how effectively we could learn the networks. Currently, the maximum likelihood estimate (MLE) principle has been a de-facto standard for learning DNNs. However, the MLE principle is not explicitly tailored to the hierarchical structure of DNNs. In this work, we propose the Parametric Information Bottleneck (PIB) framework as a fully information-theoretic learning principle of DNNs. Motivated by the Information Bottleneck principle, our framework efficiently induces relevant information under compression constraint into each layer of DNNs via multi-objective learning. Consequently, PIB generalizes the MLE principle in DNNs, indeed empirically exploits the neural representations better than MLE and a partially information-theoretic treatment, and offers better generalization and adversarial robustness on MNIST and CIFAR10."
1801.02762,2018-09-09 14:15:30,Physics-Informed,"Jin-Long Wu,Heng Xiao,Eric Paterson",https://arxiv.org/abs/1801.02762,"        Phys. Rev. Fluids 3, 074602 (2018)
      ",This manuscript is for substitution purpose of a previous arXiv submission (arXiv:1701.07102). That previous arXiv submission is no longer under consideration for any journal publication and is only for archive purpose,physics.flu-dyn,physics.flu-dyn,"Reynolds-averaged Navier-Stokes (RANS) equations are widely used in engineering turbulent flow simulations. However, RANS predictions may have large discrepancies due to the uncertainties in modeled Reynolds stresses. Recently, Wang et al. demonstrated that  machine learning  can be used to improve the RANS modeled Reynolds stresses by leveraging data from high fidelity simulations (Physics informed  machine learning  approach for reconstructing Reynolds stress modeling discrepancies based on DNS data. Physical Review Fluids. 2, 034603, 2017). However, solving for mean flows from the improved Reynolds stresses still poses significant challenges due to potential ill-conditioning of RANS equations with Reynolds stress closures. Enabling improved predictions of mean velocities are of profound practical importance, because often the velocity and its derived quantities (QoIs, e.g., drag, lift, surface friction), and not the Reynolds stress itself, are of ultimate interest in RANS simulations. To this end, we present a comprehensive framework for augmenting turbulence models with physics-informed  machine learning , illustrating a complete workflow from identification of input features to final prediction of mean velocities. This work has two innovations. First, we demonstrate a systematic procedure to generate mean flow features based on the integrity basis for mean flow tensors. Second, we propose using  machine learning  to predict linear and nonlinear parts of the Reynolds stress tensor separately. Inspired by the finite polynomial representation of tensors in classical turbulence modeling, such a decomposition is instrumental in overcoming the ill-conditioning of RANS equations. Numerical tests demonstrated merits of the proposed framework."
1801.04405,2018-09-03 20:42:21,A Survey on Compiler Autotuning using,"Amir H. Ashouri,William Killian,John Cavazos,Gianluca Palermo,Cristina Silvano",https://arxiv.org/abs/1801.04405,    ,version 5.0 (updated on September 2018)- Preprint Version For our Accepted Journal @ ACM CSUR 2018 (42 pages) - This survey will be updated quarterly here (Send me your new published papers to be added in the subsequent version) History: Received November 2016; Revised August 2017; Revised February 2018; Accepted March 2018-,cs.PL,"cs.PL,cs.LG","Since the mid-1990s, researchers have been trying to use  -  based approaches to solve a number of different compiler optimization problems. These techniques primarily enhance the quality of the obtained results and, more importantly, make it feasible to tackle two main compiler optimization problems: optimization selection (choosing which optimizations to apply) and phase-ordering (choosing the order of applying optimizations). The compiler optimization space continues to grow due to the advancement of applications, increasing number of compiler optimizations, and new target architectures. Generic optimization passes in compilers cannot fully leverage newly introduced optimizations and, therefore, cannot keep up with the pace of increasing options. This survey summarizes and classifies the recent advances in using  machine learning  for the compiler optimization field, particularly on the two major problems of (1) selecting the best optimizations and (2) the phase-ordering of optimizations. The survey highlights the approaches taken so far, the obtained results, the fine-grain classification among different approaches and finally, the influential papers of the field."
1802.02195,2018-09-07 12:15:56,Granger-causal Attentive Mixtures of Experts: Learning Important Features with Neural Networks,"Patrick Schwab,Djordje Miladinovic,Walter Karlen",https://arxiv.org/abs/1802.02195,,,cs.LG,"cs.LG,cs.AI,cs.NE","Knowledge of the importance of input features towards decisions made by  -  models is essential to increase our understanding of both the models and the underlying data. Here, we present a new approach to estimating feature importance with neural networks based on the idea of distributing the features of interest among experts in an attentive mixture of experts (AME). AMEs use attentive gating networks trained with a Granger-causal objective to learn to jointly produce accurate predictions as well as estimates of feature importance in a single model. Our experiments on an established benchmark and two real-world datasets show (i) that the feature importance estimates provided by AMEs compare favourably to those provided by state-of-the-art methods, (ii) that AMEs are significantly faster than existing methods, and (iii) that the associations discovered by AMEs are consistent with those reported by domain experts."
1802.04589,2018-09-12 10:42:42,When and when not to use optimal model averaging,"Michael Schomaker,Christian Heumann",https://arxiv.org/abs/1802.04589,,,stat.ME,stat.ME,"Traditionally model averaging has been viewed as an alternative to model selection with the ultimate goal to incorporate the uncertainty associated with the model selection process in standard errors and confidence intervals by using a weighted combination of candidate models. In recent years, a new class of model averaging estimators has emerged in the literature, suggesting to combine models such that the squared risk, or other risk functions, are minimized. We argue that, contrary to popular belief, these estimators do not necessarily address the challenges induced by model selection uncertainty, but should be regarded as attractive complements for the  machine learning  and forecasting literature, as well as tools to identify causal parameters. We illustrate our point by means of several targeted simulation studies."
1802.03446,2018-09-06 19:14:26,Pros and Cons of GAN Evaluation Measures,Ali Borji,https://arxiv.org/abs/1802.03446,,,cs.CV,cs.CV,"Generative models, in particular generative adversarial networks (GANs), have received significant attention recently. A number of GAN variants have been proposed and have been utilized in many applications. Despite large strides in terms of theoretical progress, evaluating and comparing GANs remains a daunting task. While several measures have been introduced, as of yet, there is no consensus as to which measure best captures strengths and limitations of models and should be used for fair model comparison. As in other areas of computer vision and  machine learning , it is critical to settle on one or few good measures to steer the progress in this field. In this paper, I review and critically discuss more than 24 quantitative and 5 qualitative measures for evaluating generative models with a particular emphasis on GAN-derived models. I also provide a set of 7 desiderata followed by an evaluation of whether a given measure or a family of measures is compatible with them."
1802.06355,2018-09-02 16:04:16,Stochastic Chebyshev Gradient Descent for Spectral Optimization,"Insu Han,Haim Avron,Jinwoo Shin",https://arxiv.org/abs/1802.06355,,,cs.LG,"cs.LG,cs.CC,stat.ML","A large class of  machine learning  techniques requires the solution of optimization problems involving spectral functions of parametric matrices, e.g. log-determinant and nuclear norm. Unfortunately, computing the gradient of a spectral function is generally of cubic complexity, as such gradient descent methods are rather expensive for optimizing objectives involving the spectral function. Thus, one naturally turns to stochastic gradient methods in hope that they will provide a way to reduce or altogether avoid the computation of full gradients. However, here a new challenge appears: there is no straightforward way to compute unbiased stochastic gradients for spectral functions. In this paper, we develop unbiased stochastic gradients for spectral-sums, an important subclass of spectral functions. Our unbiased stochastic gradients are based on combining randomized trace estimators with stochastic truncation of the Chebyshev expansions. A careful design of the truncation distribution allows us to offer distributions that are variance-optimal, which is crucial for fast and stable convergence of stochastic gradient methods. We further leverage our proposed stochastic gradients to devise stochastic methods for objective functions involving spectral-sums, and rigorously analyze their convergence rate. The utility of our methods is demonstrated in numerical experiments."
1803.00805,2018-09-03 08:41:15,Unsupervised Deep Single-Image Intrinsic Decomposition using Illumination-Varying Image Sequences,"Louis Lettry,Kenneth Vanhoey,Luc van Gool",https://arxiv.org/abs/1803.00805,    ,To appear in Pacific Graphics 2018,cs.CV,cs.CV,"machine learning  based Single Image Intrinsic Decomposition (SIID) methods decompose a captured scene into its albedo and shading images by using the knowledge of a large set of known and realistic ground truth decompositions. Collecting and annotating such a dataset is an approach that cannot scale to sufficient variety and realism. We free ourselves from this limitation by training on unannotated images.
  Our method leverages the observation that two images of the same scene but with different lighting provide useful information on their intrinsic properties: by definition, albedo is invariant to lighting conditions, and cross-combining the estimated albedo of a first image with the estimated shading of a second one should lead back to the second one's input image. We transcribe this relationship into a siamese training scheme for a deep convolutional neural network that decomposes a single image into albedo and shading. The siamese setting allows us to introduce a new loss function including such cross-combinations, and to train solely on (time-lapse) images, discarding the need for any ground truth annotations.
  As a result, our method has the good properties of i) taking advantage of the time-varying information of image sequences in the (pre-computed) training step, ii) not requiring ground truth data to train on, and iii) being able to decompose single images of unseen scenes at runtime. To demonstrate and evaluate our work, we additionally propose a new rendered dataset containing illumination-varying scenes and a set of quantitative metrics to evaluate SIID algorithms. Despite its unsupervised nature, our results compete with state of the art methods, including supervised and non data-driven methods."
1803.01416,2018-09-11 18:19:28,,"Tristan A. Sharp,Spencer L. Thomas,Ekin D. Cubuk,Samuel S. Schoenholz,David J. Srolovitz,Andrea J. Liu",https://arxiv.org/abs/1803.01416,,,cond-mat.mtrl-sci,cond-mat.mtrl-sci,"In polycrystalline materials, grain boundaries are sites of enhanced atomic motion, but the complexity of the atomic structures within a grain boundary network makes it difficult to link the structure and atomic dynamics. Here we use a  machine learning  technique to establish a connection between local structure and dynamics of these materials. Following previous work on bulk glassy materials, we define a purely structural quantity, softness, that captures the propensity of an atom to rearrange. This approach correctly identifies crystalline regions, stacking faults, and twin boundaries as having low likelihood of atomic rearrangements, while finding a large variability within high-energy grain boundaries. As has been found in glasses [9,19,26], the probability that atoms of a given softness will rearrange is nearly Arrhenius. This indicates a well-defined energy barrier as well as a well-defined prefactor for the Arrhenius form for atoms of a given softness. The decrease in the prefactor for low-softness atoms indicates that variations in entropy exhibit a dominant influence on the atomic dynamics in grain boundaries."
1803.01164,2018-09-12 15:57:23,The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches,"Md Zahangir Alom,Tarek M. Taha,Christopher Yakopcic,Stefan Westberg,Paheding Sidike,Mst Shamima Nasrin,Brian C Van Esesn,Abdul A S. Awwal,Vijayan K. Asari",https://arxiv.org/abs/1803.01164,    ,"39 pages, 46 figures, 3 tables. arXiv admin note: text overlap with arXiv:1408.3264, arXiv:1411.4046",cs.CV,cs.CV,"Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of  machine learning  has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional  machine learning  approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1]."
1803.02781,2018-09-07 20:22:38,Fast Dawid-Skene: A Fast Vote Aggregation Scheme for Sentiment Classification,"Vaibhav B Sinha,Sukrut Rao,Vineeth N Balasubramanian",https://arxiv.org/abs/1803.02781,    ,"8 pages, 5 tables, 1 figure, KDD Workshop on Issues of Sentiment Discovery and Opinion Mining (WISDOM) 2018",stat.ML,"stat.ML,cs.LG","Many real world problems can now be effectively solved using supervised  machine learning . A major roadblock is often the lack of an adequate quantity of labeled data for training. A possible solution is to assign the task of labeling data to a crowd, and then infer the true label using aggregation methods. A well-known approach for aggregation is the Dawid-Skene (DS) algorithm, which is based on the principle of Expectation-Maximization (EM). We propose a new simple, yet effective, EM-based algorithm, which can be interpreted as a `hard' version of DS, that allows much faster convergence while maintaining similar accuracy in aggregation. We show the use of this algorithm as a quick and effective technique for online, real-time sentiment annotation. We also prove that our algorithm converges to the estimated labels at a linear rate. Our experiments on standard datasets show a significant speedup in time taken for aggregation - upto $\sim$8x over Dawid-Skene and $\sim$6x over other fast EM methods, at competitive accuracy performance. The code for the implementation of the algorithms can be found at https://github.com/GoodDeeds/Fast-Dawid-Skene"
1803.08118,2018-09-06 19:45:08,Seglearn: A Python Package for Learning Sequences and Time Series,"David M. Burns,Cari M. Whyne",https://arxiv.org/abs/1803.08118,"          I.2.5
        
      ",,stat.ML,"stat.ML,cs.LG","Seglearn is an open-source python package for  machine learning  time series or sequences using a sliding window segmentation approach. The implementation provides a flexible pipeline for tackling classification, regression, and forecasting problems with multivariate sequence and contextual data. This package is compatible with scikit-learn and is listed under scikit-learn Related Projects. The package depends on numpy, scipy, and scikit-learn. Seglearn is distributed under the BSD 3-Clause License. Documentation includes a detailed API description, user guide, and examples. Unit tests provide a high degree of code coverage."
1803.06397,2018-09-10 09:07:30,Deep learning for affective computing: text-based emotion recognition in decision support,"Bernhard Kratzwald,Suzana Ilic,Mathias Kraus,Stefan Feuerriegel,Helmut Prendinger",https://arxiv.org/abs/1803.06397,    ,Accepted by Decision Support Systems (DSS),cs.CL,cs.CL,"Emotions widely affect human decision-making. This fact is taken into account by affective computing with the goal of tailoring decision support to the emotional states of individuals. However, the accurate recognition of emotions within narrative documents presents a challenging undertaking due to the complexity and ambiguity of language. Performance improvements can be achieved through deep learning; yet, as demonstrated in this paper, the specific nature of this task requires the customization of recurrent neural networks with regard to bidirectional processing, dropout layers as a means of regularization, and weighted loss functions. In addition, we propose sent2affect, a tailored form of transfer learning for affective computing: here the network is pre-trained for a different task (i.e. sentiment analysis), while the output layer is subsequently tuned to the task of emotion recognition. The resulting performance is evaluated in a holistic setting across 6 benchmark datasets, where we find that both recurrent neural networks and transfer learning consistently outperform traditional  machine learning . Altogether, the findings have considerable implications for the use of affective computing."
1803.10846,2018-09-07 19:11:49,Non-Convex Matrix Completion Against a Semi-Random Adversary,"Yu Cheng,Rong Ge",https://arxiv.org/abs/1803.10846,    ,added references and fixed typos,cs.LG,"cs.LG,cs.DS,math.OC,stat.ML","Matrix completion is a well-studied problem with many  machine learning  applications. In practice, the problem is often solved by non-convex optimization algorithms. However, the current theoretical analysis for non-convex algorithms relies heavily on the assumption that every entry is observed with exactly the same probability $p$, which is not realistic in practice.
  In this paper, we investigate a more realistic semi-random model, where the probability of observing each entry is at least $p$. Even with this mild semi-random perturbation, we can construct counter-examples where existing non-convex algorithms get stuck in bad local optima.
  In light of the negative results, we propose a pre-processing step that tries to re-weight the semi-random input, so that it becomes ""similar"" to a random input. We give a nearly-linear time algorithm for this problem, and show that after our pre-processing, all the local minima of the non-convex objective can be used to approximately recover the underlying ground-truth matrix."
1804.08150,2018-09-01 14:43:38,Deep Learning in Spiking Neural Networks,"Amirhossein Tavanaei,Masoud Ghodrati,Saeed Reza Kheradpisheh,Timothee Masquelier,Anthony S. Maida",https://arxiv.org/abs/1804.08150,,,cs.NE,"cs.NE,cs.AI","In recent years, deep learning has been a revolution in the field of  machine learning , for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained in a supervised manner using backpropagation. Huge amounts of labeled examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and arguably the only viable option if one wants to understand how the brain computes. SNNs are also more hardware friendly and energy-efficient than ANNs, and are thus appealing for technology, especially for portable devices. However, training deep SNNs remains a challenge. Spiking neurons' transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy, but also computational cost and hardware friendliness. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while the SNNs typically require much fewer operations."
1804.07351,2018-09-02 20:00:32,Sampling-free Uncertainty Estimation in Gated Recurrent Units with Exponential Families,"Seong Jae Hwang,Ronak Mehta,Hyunwoo J. Kim,Vikas Singh",https://arxiv.org/abs/1804.07351,    ,Version 2,cs.LG,"cs.LG,cs.CV,stat.ML","There has recently been a concerted effort to derive mechanisms in vision and  machine learning  systems to offer uncertainty estimates of the predictions they make. Clearly, there are enormous benefits to a system that is not only accurate but also has a sense for when it is not sure. Existing proposals center around Bayesian interpretations of modern deep architectures -- these are effective but can often be computationally demanding. We show how classical ideas in the literature on exponential families on probabilistic networks provide an excellent starting point to derive uncertainty estimates in Gated Recurrent Units (GRU). Our proposal directly quantifies uncertainty deterministically, without the need for costly sampling-based estimation. We demonstrate how our model can be used to quantitatively and qualitatively measure uncertainty in unsupervised image sequence prediction. To our knowledge, this is the first result describing sampling-free uncertainty estimation for powerful sequential models such as GRUs."
1804.01973,2018-09-03 18:54:53,The power of block-encoded matrix powers: improved regression techniques via faster Hamiltonian simulation,"Shantanav Chakraborty,András Gilyén,Stacey Jeffery",https://arxiv.org/abs/1804.01973,    ,58 pages,quant-ph,"quant-ph,cs.DS","We apply the framework of block-encodings, introduced by Low and Chuang (under the name standard-form), to the study of quantum  machine learning  algorithms and derive general results that are applicable to a variety of input models, including sparse matrix oracles and matrices stored in a data structure. We develop several tools within the block-encoding framework, such as singular value estimation of a block-encoded matrix, and quantum linear system solvers using block-encodings. The presented results give new techniques for Hamiltonian simulation of non-sparse matrices, which could be relevant for certain quantum chemistry applications, and which in turn imply an exponential improvement in the dependence on precision in quantum linear systems solvers for non-sparse matrices.
  In addition, we develop a technique of variable-time amplitude estimation, based on Ambainis' variable-time amplitude amplification technique, which we are also able to apply within the framework.
  As applications, we design the following algorithms: (1) a quantum algorithm for the quantum weighted least squares problem, exhibiting a 6-th power improvement in the dependence on the condition number and an exponential improvement in the dependence on the precision over the previous best algorithm of Kerenidis and Prakash; (2) the first quantum algorithm for the quantum generalized least squares problem; and (3) quantum algorithms for estimating electrical-network quantities, including effective resistance and dissipated power, improving upon previous work."
1804.08778,2018-09-07 11:29:11,Low Resource Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers,"Ishai Rosenberg,Asaf Shabtai,Yuval Elovici,Lior Rokach",https://arxiv.org/abs/1804.08778,    ,Submitted as a conference paper to ACSAC2018,cs.CR,"cs.CR,cs.LG","In this paper, we present a black-box attack against API call based  machine learning  malware classifiers. We generate adversarial examples combining API call sequences and static features (e.g., printable strings) that will be misclassified by the classifier without affecting the malware functionality. Our attack only requires access to the predicted label of the attacked model (without the confidence level) and minimizes the number of target classifier queries. We evaluate the attack's effectiveness against many classifiers such as RNN variants, DNN, SVM, GBDT, etc. We show that the attack requires fewer queries and less knowledge about the attacked model's architecture than other existing black-box attacks, making it optimal to attack cloud based models with a minimal cost. We also implement BADGER, a software framework to recraft any malware binary so that it won't be detected by classifiers, without access to the malware source code. Finally, we discuss the robustness of this attack to existing defense mechanisms."
1804.11192,2018-09-04 02:22:46,Explainable Recommendation: A Survey and New Perspectives,"Yongfeng Zhang,Xu Chen",https://arxiv.org/abs/1804.11192,    ,90 pages,cs.IR,"cs.IR,cs.AI,cs.MM","Explainable Recommendation refers to the personalized recommendation algorithms that address the problem of why - they not only provide users with the recommendations, but also provide explanations to make the user or system designer aware of why such items are recommended. In this way, it helps to improve the effectiveness, efficiency, persuasiveness, and user satisfaction of recommendation systems. In recent years, a large number of explainable recommendation approaches -- especially model-based explainable recommendation algorithms -- have been proposed and adopted in real-world systems.
  In this survey, we review the work on explainable recommendation that has been published in or before the year of 2018. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation itself in terms of three aspects: 1) We provide a chronological research line of explanations in recommender systems, including the user study approaches in the early years, as well as the more recent model-based approaches. 2) We provide a taxonomy for explainable recommendation algorithms, including user-based, item-based, model-based, and post-model explanations. 3) We summarize the application of explainable recommendation in different recommendation tasks, including product recommendation, social recommendation, POI recommendation, etc. We devote a section to discuss the explanation perspectives in the broader IR and  machine learning  settings, as well as their relationship with explainable recommendation research. We end the survey by discussing potential future research directions to promote the explainable recommendation research area."
1805.01053,2018-09-05 20:43:45,Mean Field Analysis of Neural Networks,"Justin Sirignano,Konstantinos Spiliopoulos",https://arxiv.org/abs/1805.01053,,,math.PR,math.PR,"machine learning , and in particular neural network models, have revolutionized fields such as image, text, and speech recognition. Today, many important real-world applications in these areas are driven by neural networks. There are also growing applications in engineering, robotics, medicine, and finance. Despite their immense success in practice, there is limited mathematical understanding of neural networks. This paper illustrates how neural networks can be studied via stochastic analysis, and develops approaches for addressing some of the technical challenges which arise. We analyze one-layer neural networks in the asymptotic regime of simultaneously (A) large network sizes and (B) large numbers of stochastic gradient descent training iterations. We rigorously prove that the empirical distribution of the neural network parameters converges to the solution of a nonlinear partial differential equation. This result can be considered a law of large numbers for neural networks. In addition, a consequence of our analysis is that the trained parameters of the neural network asymptotically become independent, a property which is commonly called ""propagation of chaos""."
1805.05052,2018-09-05 12:43:31,,Alexander Jung,https://arxiv.org/abs/1805.05052,,,cs.LG,"cs.LG,stat.ML","This tutorial is based on the lecture notes for the courses "" machine learning : Basic Principles"" and ""Artificial Intelligence"", which I have (co-)taught since 2015 at Aalto University. The aim is to provide an accessible introduction to some of the main concepts and methods within  machine learning . Many of the current systems which are considered (artificial) intelligent are based on combinations of few basic  machine learning  methods. After formalizing the main building blocks of a  machine learning  problem, some popular algorithmic design patterns for  machine learning  methods are discussed in some detail."
1805.05409,2018-09-11 15:32:10,,"L. Jason Anastasopoulos,Andrew B. Whitford",https://arxiv.org/abs/1805.05409,,,cs.CY,"cs.CY,cs.LG,stat.ML","machine learning  methods have gained a great deal of popularity in recent years among public administration scholars and practitioners. These techniques open the door to the analysis of text, image and other types of data that allow us to test foundational theories of public administration and to develop new theories. Despite the excitement surrounding  machine learning  methods, clarity regarding their proper use and potential pitfalls is lacking. This paper attempts to fill this gap in the literature through providing a  machine learning  ""guide to practice"" for public administration scholars and practitioners. Here, we take a foundational view of  machine learning  and describe how these methods can enrich public administration research and practice through their ability develop new measures, tap into new sources of data and conduct statistical inference and causal inference in a principled manner. We then turn our attention to the pitfalls of using these methods such as unvalidated measures and lack of interpretability. Finally, we demonstrate how  machine learning  techniques can help us learn about organizational reputation in federal agencies through an illustrated example using tweets from 13 executive federal agencies."
1805.07431,2018-09-10 01:45:24,Can,Chai Wah Wu,https://arxiv.org/abs/1805.07431,    ,"9 pages, minor edits and fixed typos",cs.LG,"cs.LG,cs.AI,stat.ML","We explore the possibility of using  machine learning  to identify interesting mathematical structures by using certain quantities that serve as fingerprints. In particular, we extract features from integer sequences using two empirical laws: Benford's law and Taylor's law and experiment with various classifiers to identify whether a sequence is, for example, nice, important, multiplicative, easy to compute or related to primes or palindromes."
1805.08672,2018-09-12 00:16:45,Information Constraints on Auto-Encoding Variational Bayes,"Romain Lopez,Jeffrey Regier,Michael I. Jordan,Nir Yosef",https://arxiv.org/abs/1805.08672,"        Advances in Neural Information Processing Systems 2018
      ",,cs.LG,"cs.LG,q-bio.GN,stat.ML","Parameterizing the approximate posterior of a generative model with neural networks has become a common theme in recent  machine learning  research. While providing appealing flexibility, this approach makes it difficult to impose or assess structural constraints such as conditional independence. We propose a framework for learning representations that relies on Auto-Encoding Variational Bayes and whose search space is constrained via kernel-based measures of independence. In particular, our method employs the $d$-variable Hilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between the latent representations and arbitrary nuisance factors. We show how to apply this method to a range of problems, including the problems of learning invariant representations and the learning of interpretable representations. We also present a full-fledged application to single-cell RNA sequencing (scRNA-seq). In this setting the biological signal in mixed in complex ways with sequencing errors and sampling effects. We show that our method out-performs the state-of-the-art in this domain."
1805.07683,2018-09-11 18:19:09,Learning Graph-Level Representations with Recurrent Neural Networks,"Yu Jin,Joseph F. JaJa",https://arxiv.org/abs/1805.07683,    ,Submit to AAAI 2019,cs.LG,"cs.LG,cs.AI,stat.ML","Recently a variety of methods have been developed to encode graphs into low-dimensional vectors that can be easily exploited by  machine learning  algorithms. The majority of these methods start by embedding the graph nodes into a low-dimensional vector space, followed by using some scheme to aggregate the node embeddings. In this work, we develop a new approach to learn graph-level representations, which includes a combination of unsupervised and supervised learning components. We start by learning a set of node representations in an unsupervised fashion. Graph nodes are mapped into node sequences sampled from random walk approaches approximated by the Gumbel-Softmax distribution. Recurrent neural network (RNN) units are modified to accommodate both the node representations as well as their neighborhood information. Experiments on standard graph classification benchmarks demonstrate that our proposed approach achieves superior or comparable performance relative to the state-of-the-art algorithms in terms of convergence speed and classification accuracy. We further illustrate the effectiveness of the different components used by our approach."
1805.07594,2018-09-05 11:53:24,Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions,"Boris Muzellec,Marco Cuturi",https://arxiv.org/abs/1805.07594,,,stat.ML,"stat.ML,cs.LG","Embedding complex objects as vectors in low dimensional spaces is a longstanding problem in  machine learning . We propose in this work an extension of that approach, which consists in embedding objects as elliptical probability distributions, namely distributions whose densities have elliptical level sets. We endow these measures with the 2-Wasserstein metric, with two important benefits: (i) For such measures, the squared 2-Wasserstein metric has a closed form, equal to the sum of the squared Euclidean distance between means and the squared Bures metric between covariance matrices. The latter is a Riemannian metric between positive semi-definite matrices, which turns out to be Euclidean on a suitable factor representation of such matrices, which is valid on the entire geodesic between these matrices. (ii) The 2-Wasserstein distance boils down to the usual Euclidean metric when comparing Diracs, and therefore provides the natural framework to extend point embeddings. We show that for these reasons Wasserstein elliptical embeddings are more intuitive and yield tools that are better behaved numerically than the alternative choice of Gaussian embeddings with the Kullback-Leibler divergence. In particular, and unlike previous work based on the KL geometry, we learn elliptical distributions that are not necessarily diagonal. We demonstrate the advantages of elliptical embeddings by using them for visualization, to compute embeddings of words, and to reflect entailment or hypernymy."
1808.07980,2018-09-04 18:14:04,Ontology Reasoning with Deep Neural Networks,"Patrick Hohenecker,Thomas Lukasiewicz",https://arxiv.org/abs/1808.07980,,,cs.AI,cs.AI,"The ability to conduct logical reasoning is a fundamental aspect of intelligent behavior, and thus an important problem along the way to human-level artificial intelligence. Traditionally, symbolic methods from the field of knowledge representation and reasoning have been used to equip agents with capabilities that resemble human logical reasoning qualities. More recently, however, there has been an increasing interest in using  machine learning  rather than logic-based formalisms to tackle these tasks. In this paper, we employ state-of-the-art methods for training deep neural networks to devise a novel model that is able to learn how to effectively perform basic ontology reasoning. This is an important and at the same time very natural reasoning problem, which is why the presented approach is applicable to a plethora of important real-world problems. We present the outcomes of several experiments, which show that our model learned to perform precise reasoning on diverse and challenging tasks. Furthermore, it turned out that the suggested approach suffers much less from different obstacles that prohibit symbolic reasoning, and, at the same time, is surprisingly plausible from a biological point of view."
1805.11648,2018-09-11 01:44:51,Teaching Meaningful Explanations,"Noel C. F. Codella,Michael Hind,Karthikeyan Natesan Ramamurthy,Murray Campbell,Amit Dhurandhar,Kush R. Varshney,Dennis Wei,Aleksandra Mojsilovic",https://arxiv.org/abs/1805.11648,    ,9 pages,cs.AI,cs.AI,"The adoption of  machine learning  in high-stakes applications such as healthcare and law has lagged in part because predictions are not accompanied by explanations comprehensible to the domain user, who often holds the ultimate responsibility for decisions and outcomes. In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users. A joint model is then learned to produce both labels and explanations from the input features. This simple idea ensures that explanations are tailored to the complexity expectations and domain knowledge of the consumer. Evaluation spans multiple modeling techniques on a game dataset, a (visual) aesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that our approach is generalizable across domains and algorithms. Results demonstrate that meaningful explanations can be reliably taught to  machine learning  algorithms, and in some cases, also improve modeling accuracy."
1808.10101,2018-09-03 18:22:30,DP-ADMM: ADMM-based Distributed Learning with Differential Privacy,"Zonghao Huang,Rui Hu,Eric Chan-Tin,Yanmin Gong",https://arxiv.org/abs/1808.10101,    ,"16 pages, 24 figures",cs.LG,"cs.LG,stat.ML","Privacy-preserving distributed  machine learning  has become more important than ever due to the high demand of large-scale data processing. This paper focuses on a class of  machine learning  problems that can be formulated as regularized empirical risk minimization, and develops a privacy-preserving approach to such learning problems. We use Alternating Direction Method of Multipliers (ADMM) to decentralize the learning algorithm, and apply Gaussian mechanisms to provide local differential privacy guarantee. However, simply combining ADMM and local randomization mechanisms would result in a nonconvergent algorithm with bad performance even under moderate privacy guarantees. Besides, this approach cannot be applied when the objective functions of the learning problems are non-smooth. To address these concerns, we propose an improved ADMM-based Differentially Private distributed learning algorithm, DP-ADMM, where an approximate augmented Lagrangian function and Gaussian mechanisms with time-varying variance are utilized. We also apply the moment accountant method to bound the total privacy loss. Our theoretical analysis shows that DP-ADMM can be applied to convex learning problems with both smooth and non-smooth objectives, provides differential privacy guarantee, and achieves a convergence rate of $O(1/\sqrt{t})$, where $t$ is the number of iterations. Our evaluations demonstrate that our approach can achieve good convergence and accuracy with strong privacy guarantee."
1808.07380,2018-09-07 00:41:55,On the Predictability of non-CGM Diabetes Data for Personalized Recommendation,"Tu Ngoc Nguyen,Markus Rokicki",https://arxiv.org/abs/1808.07380,    ,In Proceedings of ACM CIKM 2018 Workshops,cs.CY,"cs.CY,cs.LG,stat.ML","With continuous glucose monitoring (CGM), data-driven models on blood glucose prediction have been shown to be effective in related work. However, such (CGM) systems are not always available, e.g., for a patient at home. In this work, we conduct a study on 9 patients and examine the predictability of data-driven (aka.  machine learning ) based models on patient-level blood glucose prediction; with measurements are taken only periodically (i.e., after several hours). To this end, we propose several post-prediction methods to account for the noise nature of these data, that marginally improves the performance of the end system."
1808.10561,2018-09-08 02:58:37,A Quantum Model for Multilayer Perceptron,Changpeng Shao,https://arxiv.org/abs/1808.10561,"          68Q12; 92B20
        

        
      ","23 pages, 3 figures",quant-ph,quant-ph,"Multilayer perceptron is the most common used class of feed-forward artificial neural network. It contains many applications in diverse fields such as speech recognition, image recognition, and machine translation software. To cater for the fast development of quantum  machine learning , in this paper, we propose a new model to study multilayer perceptron in quantum computer. This contains the tasks to prepare the quantum state of the output signal in each layer and to establish the quantum version of learning algorithm about the weights in each layer. We will show that the corresponding quantum versions can achieve at least quadratic speedup or even exponential speedup over the classical algorithms. This provide us an efficient method to study multilayer perceptron and its applications in  machine learning  in quantum computer. Finally, as an inspiration, an exponential fast learning algorithm (based on Hebb's learning rule) of Hopfield network will be proposed."
1809.00238,2018-09-01 19:11:53,A,"Yasser Alsouda,Sabri Pllana,Arianit Kurti",https://arxiv.org/abs/1809.00238,,,cs.SD,"cs.SD,cs.LG,eess.AS,stat.ML","We present a  machine learning  based method for noise classification using a low-power and inexpensive IoT unit. We use Mel-frequency cepstral coefficients for audio feature extraction and supervised classification algorithms (that is, support vector machine and k-nearest neighbors) for noise classification. We evaluate our approach experimentally with a dataset of about 3000 sound samples grouped in eight sound classes (such as, car horn, jackhammer, or street music). We explore the parameter space of support vector machine and k-nearest neighbors algorithms to estimate the optimal parameter values for classification of sound samples in the dataset under study. We achieve a noise classification accuracy in the range 85% -- 100%. Training and testing of our k-nearest neighbors (k = 1) implementation on Raspberry Pi Zero W is less than a second for a dataset with features of more than 3000 sound samples."
1809.00175,2018-09-01 13:33:31,Hyperparameter Learning for Conditional Mean Embeddings with Rademacher Complexity Bounds,"Kelvin Hsu,Richard Nock,Fabio Ramos",https://arxiv.org/abs/1809.00175,    ,To appear in the European Conference on ,stat.ML,"stat.ML,cs.LG","Conditional mean embeddings are nonparametric models that encode conditional expectations in a reproducing kernel Hilbert space. While they provide a flexible and powerful framework for probabilistic inference, their performance is highly dependent on the choice of kernel and regularization hyperparameters. Nevertheless, current hyperparameter tuning methods predominantly rely on expensive cross validation or heuristics that is not optimized for the inference task. For conditional mean embeddings with categorical targets and arbitrary inputs, we propose a hyperparameter learning framework based on Rademacher complexity bounds to prevent overfitting by balancing data fit against model complexity. Our approach only requires batch updates, allowing scalable kernel hyperparameter tuning without invoking kernel approximations. Experiments demonstrate that our learning framework outperforms competing methods, and can be further extended to incorporate and learn deep neural network weights to improve generalization."
1809.00343,2018-09-02 14:18:40,Towards an Intelligent Edge: Wireless Communication Meets,"Guangxu Zhu,Dongzhu Liu,Yuqing Du,Changsheng You,Jun Zhang,Kaibin Huang",https://arxiv.org/abs/1809.00343,    ,submitted to IEEE for possible publication,cs.IT,"cs.IT,cs.LG,cs.NI,eess.SP","The recent revival of artificial intelligence (AI) is revolutionizing almost every branch of science and technology. Given the ubiquitous smart mobile gadgets and Internet of Things (IoT) devices, it is expected that a majority of intelligent applications will be deployed at the edge of wireless networks. This trend has generated strong interests in realizing an ""intelligent edge"" to support AI-enabled applications at various edge devices. Accordingly, a new research area, called edge learning, emerges, which crosses and revolutionizes two disciplines: wireless communication and  machine learning . A major theme in edge learning is to overcome the limited computing power, as well as limited data, at each edge device. This is accomplished by leveraging the mobile edge computing (MEC) platform and exploiting the massive data distributed over a large number of edge devices. In such systems, learning from distributed data and communicating between the edge server and devices are two critical and coupled aspects, and their fusion poses many new research challenges. This article advocates a new set of design principles for wireless communication in edge learning, collectively called learning-driven communication. Illustrative examples are provided to demonstrate the effectiveness of these design principles, and unique research opportunities are identified."
1809.00267,2018-09-01 23:48:44,,"Reese E. Jones,Jeremy A. Templeton,Clay M. Sanders,Jakob T. Ostien",https://arxiv.org/abs/1809.00267,    ,"32 pages, 12 figures (44 subfigures)",physics.comp-ph,physics.comp-ph,"We use  machine learning  (ML) to infer stress and plastic flow rules using data from repre- sentative polycrystalline simulations. In particular, we use so-called deep (multilayer) neural networks (NN) to represent the two response functions. The ML process does not choose ap- propriate inputs or outputs, rather it is trained on selected inputs and output. Likewise, its discrimination of features is crucially connected to the chosen input-output map. Hence, we draw upon classical constitutive modeling to select inputs and enforce well-accepted symmetries and other properties. With these developments, we enable rapid model building in real-time with experiments, and guide data collection and feature discovery."
1809.00486,2018-09-03 08:24:18,Automated,"Felix Mohr,Marcel Wever,Eyke Hüllermeier",https://arxiv.org/abs/1809.00486,,,cs.SE,cs.SE,"Automated service composition as the process of creating new software in an automated fashion has been studied in many different ways over the last decade. However, the impact of automated service composition has been rather small as its utility in real-world applications has not been demonstrated so far. This paper presents \tool, an algorithm for automated service composition applied to the area of  machine learning . Empirically, we show that \tool is competitive and sometimes beats algorithms that solve the same task but not benefit of the advantages of a service model. Thereby, we present a real-world example that demonstrates the utility of automated service composition in contrast to non-service oriented solutions in the same area."
1809.00438,2018-09-06 01:41:56,Beta-Skeleton Analysis of the Cosmic Web,"Feng Fang,Jaime Forero-Romero,Graziano Rossi,Xiao-Dong Li,Long-Long Feng",https://arxiv.org/abs/1809.00438,    ,"11 pages, 9 figures. Submitted to MNRAS",astro-ph.CO,"astro-ph.CO,astro-ph.GA","The $β$-skeleton is a mathematical method to construct graphs from a set of points that has been widely applied in the areas of image analysis,  machine learning , visual perception, and pattern recognition. In this work, we apply the $β$-skeleton to study the cosmic web. We use this tool on observed and simulated data to identify the filamentary structures and characterize the statistical properties of the skeleton. In particular, we compare the $β$-skeletons built from SDSS-III galaxies to those obtained from MD-PATCHY mocks, and also to mocks directly built from the Big MultiDark $N$-body simulation. We find that the $β$-skeleton is able to reveal the underlying structures in observed and simulated samples without any parameter fine-tuning. A different degree of sparseness can be obtained by adjusting the value of $β$; in addition, the statistical properties of the length and direction of the skeleton connections show a clear dependence on redshift space distortions (RSDs), cosmological effects and galaxy bias. We also find that the $N$-body simulation accurately reproduces the RSD effect in the data, while the MD-PATCHY mocks appear to underestimate its magnitude. Our proof-of-concept study shows that the statistical properties of the $β$-skeleton can be used to probe cosmological parameters and galaxy evolution."
1809.00542,2018-09-03 10:43:02,,"Matej Petković,Redouane Boumghar,Martin Breskvar,Sašo Džeroski,Dragi Kocev,Jurica Levatić,Luke Lucas,Aljaž Osojnik,Bernard Ženko,Nikola Simidjievski",https://arxiv.org/abs/1809.00542,,,cs.LG,"cs.LG,stat.ML","The thermal subsystem of the Mars Express (MEX) spacecraft keeps the on-board equipment within its pre-defined operating temperatures range. To plan and optimize the scientific operations of MEX, its operators need to estimate in advance, as accurately as possible, the power consumption of the thermal subsystem. The remaining power can then be allocated for scientific purposes. We present a  machine learning  pipeline for efficiently constructing accurate predictive models for predicting the power of the thermal subsystem on board MEX. In particular, we employ state-of-the-art feature engineering approaches for transforming raw telemetry data, in turn used for constructing accurate models with different state-of-the-art  machine learning  methods. We show that the proposed pipeline considerably improve our previous (competition-winning) work in terms of time efficiency and predictive performance. Moreover, while achieving superior predictive performance, the constructed models also provide important insight into the spacecraft's behavior, allowing for further analyses and optimal planning of MEX's operation."
1809.00581,2018-09-03 12:40:07,Distributed Real-Time Data Stream Analysis for CTA,"Kai Brügge,Alexey Egorov,Christian Bockermann,Katharina Morik,Wolfgang Rhode",https://arxiv.org/abs/1809.00581,    ,"4 pages, 5 figures, ADASS 26 2017 in Satiange de Chile",astro-ph.IM,astro-ph.IM,"Once completed, the Cherenkov Telescope Array (CTA) will be able to map the gamma-ray sky in a wide energy range from several tens of GeV to some hundreds of TeV and will be more sensitive than previous experiments by an order of magnitude. It opens up the opportunity to observe transient phenomena like gamma-ray bursts (GRBs) and flaring active galactic nuclei (AGN). In order to successfully trigger multi-wavelength observations of transients, CTA has to be able to alert other observatories as quickly as possible. Multi-wavelength observations are essential for gaining insights into the processes occurring within these sources of such high energy radiation. CTA will consist of approximately 100 telescopes of different sizes and designs. Images are streamed from all the telescopes into a central computing facility on site. During observation CTA will produce a stream of up to 20 000 images per second. Noise suppression and feature extraction algorithms are applied to each image in the stream as well as previously trained  machine learning  models. Restricted computing power of a single machine and the limits of network's data transfer rates become a bottleneck for stream processing systems in a traditional single-machine setting. We explore several different distributed streaming technologies from the Apache Big-Data eco-system like Spark, Flink, Storm to handle the large amount of data coming from the telescopes. To share a single code base while executing on different streaming engines we employ abstraction layers such as the streams-framework. These use a high level language to build up processing pipelines that can transformed into the native pipelines of the different platforms. Here we present results of our investigation and show a first prototype capable of analyzing CTA data in real-time."
1809.00593,2018-09-03 13:21:28,IoU is not submodular,"Tanguy Kerdoncuff,Rémi Emonet",https://arxiv.org/abs/1809.00593,,,cs.LG,"cs.LG,stat.ML",This short article aims at demonstrate that the Intersection over Union (or Jaccard index) is not a submodular function. This mistake has been made in an article which is cited and used as a foundation in another article. The Intersection of Union is widely used in  machine learning  as a cost function especially for imbalance data and semantic segmentation.
1809.00615,2018-09-03 14:25:46,Have You Stolen My Model? Evasion Attacks Against Deep Neural Network Watermarking Techniques,"Dorjan Hitaj,Luigi V. Mancini",https://arxiv.org/abs/1809.00615,    ,"7 pages, 4 figures, 1 table",cs.CR,"cs.CR,cs.LG","Deep neural networks have had enormous impact on various domains of computer science, considerably outperforming previous state of the art  machine learning  techniques. To achieve this performance, neural networks need large quantities of data and huge computational resources, which heavily increases their construction costs. The increased cost of building a good deep neural network model gives rise to a need for protecting this investment from potential copyright infringements. Legitimate owners of a  machine learning  model want to be able to reliably track and detect a malicious adversary that tries to steal the intellectual property related to the model. Recently, this problem was tackled by introducing in deep neural networks the concept of watermarking, which allows a legitimate owner to embed some secret information(watermark) in a given model. The watermark allows the legitimate owner to detect copyright infringements of his model. This paper focuses on verifying the robustness and reliability of state-of- the-art deep neural network watermarking schemes. We show that, a malicious adversary, even in scenarios where the watermark is difficult to remove, can still evade the verification by the legitimate owners, thus avoiding the detection of model theft."
1809.00695,2018-09-03 19:27:48,Topological recognition of critical transitions in time series of cryptocurrencies,"Marian Gidea,Daniel Goldsmith,Yuri Katz,Pablo Roldan,Yonah Shmalo",https://arxiv.org/abs/1809.00695,,,q-fin.MF,"q-fin.MF,math.DS,physics.soc-ph","We analyze the time series of four major cryptocurrencies (Bitcoin, Ethereum, Litecoin, and Ripple) before the digital market crash at the end of 2017 - beginning 2018. We introduce a methodology that combines topological data analysis with a  machine learning  technique -- $k$-means clustering -- in order to automatically recognize the emerging chaotic regime in a complex system approaching a critical transition. We first test our methodology on the complex system dynamics of a Lorenz-type attractor, and then we apply it to the four major cryptocurrencies. We find early warning signals for critical transitions in the cryptocurrency markets, even though the relevant time series exhibit a highly erratic behavior."
1809.00741,2018-09-03 23:13:00,"""Read My Lips"": Using Automatic Text Analysis to Classify Politicians by Party and Ideology",Eitan Sapiro-Gheiler,https://arxiv.org/abs/1809.00741,,,econ.GN,"econ.GN,cs.CL","The increasing digitization of political speech has opened the door to studying a new dimension of political behavior using text analysis. This work investigates the value of word-level statistical data from the US Congressional Record--which contains the full text of all speeches made in the US Congress--for studying the ideological positions and behavior of senators. Applying  machine learning  techniques, we use this data to automatically classify senators according to party, obtaining accuracy in the 70-95% range depending on the specific method used. We also show that using text to predict DW-NOMINATE scores, a common proxy for ideology, does not improve upon these already-successful results. This classification deteriorates when applied to text from sessions of Congress that are four or more years removed from the training set, pointing to a need on the part of voters to dynamically update the heuristics they use to evaluate party based on political speech. Text-based predictions are less accurate than those based on voting behavior, supporting the theory that roll-call votes represent greater commitment on the part of politicians and are thus a more accurate reflection of their ideological preferences. However, the overall success of the  machine learning  approaches studied here demonstrates that political speeches are highly predictive of partisan affiliation. In addition to these findings, this work also introduces the computational tools and methods relevant to the use of political speech data."
1809.00745,2018-09-03 23:43:10,IoTDots: A Digital Forensics Framework for Smart Environments,"Leonardo Babun,Amit Kumar Sikder,Abbas Acar,A. Selcuk Uluagac",https://arxiv.org/abs/1809.00745,,,cs.CR,cs.CR,"IoT devices and sensors have been utilized in a cooperative manner to enable the concept of a smart environment. In these smart settings, abundant data is generated as a result of the interactions between devices and users' day-to-day activities. Such data contain valuable forensic information about events and actions occurring inside the smart environment and, if analyzed, may help hold those violating security policies accountable. In this paper, we introduce IoTDots, a novel digital forensic framework for a smart environment such as smart homes and smart offices. IoTDots has two main components: IoTDots-Modifier and IoTDots-Analyzer. At compile time, IoTDots-Modifier performs the source code analysis of smart apps, detects forensically-relevant information, and automatically insert tracing logs. Then, at runtime, the logs are stored into a IoTDots database. Later, in the event of a forensic investigation, the IoTDots-Analyzer applies data processing and  machine learning  techniques to extract valuable and usable forensic information from the devices' activity. In order to test the performance of IoTDots, we tested IoTDots in a realistic smart office environment with a total of 22 devices and sensors. The evaluation results show that IoTDots can achieve, on average, over 98% of accuracy on detecting user activities and over 96% accuracy on detecting the behavior of users, devices, and apps in a smart environment. Finally, IoTDots performance yields no overhead to the smart devices and very minimal overhead to the cloud server."
1809.00862,2018-09-04 09:54:25,Handwriting styles: benchmarks and evaluation metrics,"Omar Mohammed,Gerard Bailly,Damien Pellier",https://arxiv.org/abs/1809.00862,    ,Submitted to IEEE International Workshop on Deep and Transfer Learning (DTL 2018),cs.CV,"cs.CV,cs.LG,stat.ML","Evaluating the style of handwriting generation is a challenging problem, since it is not well defined. It is a key component in order to develop in developing systems with more personalized experiences with humans. In this paper, we propose baseline benchmarks, in order to set anchors to estimate the relative quality of different handwriting style methods. This will be done using deep learning techniques, which have shown remarkable results in different  machine learning  tasks, learning classification, regression, and most relevant to our work, generating temporal sequences. We discuss the challenges associated with evaluating our methods, which is related to evaluation of generative models in general. We then propose evaluation metrics, which we find relevant to this problem, and we discuss how we evaluate the evaluation metrics. In this study, we use IRON-OFF dataset. To the best of our knowledge, there is no work done before in generating handwriting (either in terms of methodology or the performance metrics), our in exploring styles using this dataset."
1809.00905,2018-09-04 11:55:34,Bangla License Plate Recognition Using Convolutional Neural Networks (CNN),"M M Shaifur Rahman,Mst Shamima Nasrin,Moin Mostakim,Md Zahangir Alom",https://arxiv.org/abs/1809.00905,    ,"6 pages,10 figures",cs.CV,cs.CV,"In the last few years, the deep learning technique in particular Convolutional Neural Networks (CNNs) is using massively in the field of computer vision and  machine learning . This deep learning technique provides state-of-the-art accuracy in different classification, segmentation, and detection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100, Microsoft COCO, and ImageNet. However, there are a lot of research has been conducted for Bangla License plate recognition with traditional  machine learning  approaches in last decade. None of them are used to deploy a physical system for Bangla License Plate Recognition System (BLPRS) due to their poor recognition accuracy. In this paper, we have implemented CNNs based Bangla license plate recognition system with better accuracy that can be applied for different purposes including roadside assistance, automatic parking lot management system, vehicle license status detection and so on. Along with that, we have also created and released a very first and standard database for BLPRS."
1809.01018,2018-09-04 14:24:19,Parameter Transfer Extreme Learning Machine based on Projective Model,"Chao Chen,Boyuan Jiang,Xinyu Jin",https://arxiv.org/abs/1809.01018,    ,This paper was accepted as an oral paper by IJCNN 2018,cs.LG,"cs.LG,stat.ML","Recent years, transfer learning has attracted much attention in the community of  machine learning . In this paper, we mainly focus on the tasks of parameter transfer under the framework of extreme learning machine (ELM). Unlike the existing parameter transfer approaches, which incorporate the source model information into the target by regularizing the di erence between the source and target domain parameters, an intuitively appealing projective-model is proposed to bridge the source and target model parameters. Specifically, we formulate the parameter transfer in the ELM networks by the means of parameter projection, and train the model by optimizing the projection matrix and classifier parameters jointly. Further more, the `L2,1-norm structured sparsity penalty is imposed on the source domain parameters, which encourages the joint feature selection and parameter transfer. To evaluate the e ectiveness of the proposed method, comprehensive experiments on several commonly used domain adaptation datasets are presented. The results show that the proposed method significantly outperforms the non-transfer ELM networks and other classical transfer learning methods."
1809.01106,2018-09-04 17:19:18,Distributed Nonconvex Constrained Optimization over Time-Varying Digraphs,"Gesualdo Scutari,Ying Sun",https://arxiv.org/abs/1809.01106,    ,"Submitted June 3, 2017, revised June 5, 2108. Part of this work has been presented at the 2016 Asilomar Conference on System, Signal and Computers and the 2017 IEEE ICASSP Conference",math.OC,"math.OC,cs.DC,cs.MA","This paper considers nonconvex distributed constrained optimization over networks, modeled as directed (possibly time-varying) graphs. We introduce the first algorithmic framework for the minimization of the sum of a smooth nonconvex (nonseparable) function--the agent's sum-utility--plus a Difference-of-Convex (DC) function (with nonsmooth convex part). This general formulation arises in many applications, from statistical  machine learning  to engineering. The proposed distributed method combines successive convex approximation techniques with a judiciously designed perturbed push-sum consensus mechanism that aims to track locally the gradient of the (smooth part of the) sum-utility. Sublinear convergence rate is proved when a fixed step-size (possibly different among the agents) is employed whereas asymptotic convergence to stationary solutions is proved using a diminishing step-size. Numerical results show that our algorithms compare favorably with current schemes on both convex and nonconvex problems."
1809.01185,2018-09-06 04:17:27,DeepPINK: reproducible feature selection in deep neural networks,"Yang Young Lu,Yingying Fan,Jinchi Lv,William Stafford Noble",https://arxiv.org/abs/1809.01185,,,cs.LG,"cs.LG,stat.ML","Deep learning has become increasingly popular in both supervised and unsupervised  machine learning  thanks to its outstanding empirical performance. However, because of their intrinsic complexity, most deep learning methods are largely treated as black box tools with little interpretability. Even though recent attempts have been made to facilitate the interpretability of deep neural networks (DNNs), existing methods are susceptible to noise and lack of robustness.
  Therefore, scientists are justifiably cautious about the reproducibility of the discoveries, which is often related to the interpretability of the underlying statistical models. In this paper, we describe a method to increase the interpretability and reproducibility of DNNs by incorporating the idea of feature selection with controlled error rate. By designing a new DNN architecture and integrating it with the recently proposed knockoffs framework, we perform feature selection with a controlled error rate, while maintaining high power. This new method, DeepPINK (Deep feature selection using Paired-Input Nonlinear Knockoffs), is applied to both simulated and real data sets to demonstrate its empirical utility."
1809.01225,2018-09-07 14:57:46,Compositional Stochastic Average Gradient for,"Tsung-Yu Hsieh,Yasser EL-Manzalawy,Yiwei Sun,Vasant Honavar",https://arxiv.org/abs/1809.01225,,,cs.LG,"cs.LG,cs.CC,stat.ML","Many  machine learning , statistical inference, and portfolio optimization problems require minimization of a composition of expected value functions (CEVF). Of particular interest is the finite-sum versions of such compositional optimization problems (FS-CEVF). Compositional stochastic variance reduced gradient (C-SVRG) methods that combine stochastic compositional gradient descent (SCGD) and stochastic variance reduced gradient descent (SVRG) methods are the state-of-the-art methods for FS-CEVF problems. We introduce compositional stochastic average gradient descent (C-SAG) a novel extension of the stochastic average gradient method (SAG) to minimize composition of finite-sum functions. C-SAG, like SAG, estimates gradient by incorporating memory of previous gradient information. We present theoretical analyses of C-SAG which show that C-SAG, like SAG, and C-SVRG, achieves a linear convergence rate when the objective function is strongly convex; However, C-CAG achieves lower oracle query complexity per iteration than C-SVRG. Finally, we present results of experiments showing that C-SAG converges substantially faster than full gradient (FG), as well as C-SVRG."
1809.01263,2018-09-04 22:43:13,An Efficient Approach for Polyps Detection in Endoscopic Videos Based on Faster R-CNN,"Xi Mo,Ke Tao,Quan Wang,Guanghui Wang",https://arxiv.org/abs/1809.01263,    ,"6 pages, 10 figures,2018 International Conference on Pattern Recognition",q-bio.TO,"q-bio.TO,cs.CV","Polyp has long been considered as one of the major etiologies to colorectal cancer which is a fatal disease around the world, thus early detection and recognition of polyps plays a crucial role in clinical routines. Accurate diagnoses of polyps through endoscopes operated by physicians becomes a challenging task not only due to the varying expertise of physicians, but also the inherent nature of endoscopic inspections. To facilitate this process, computer-aid techniques that emphasize fully-conventional image processing and novel  machine learning  enhanced approaches have been dedicatedly designed for polyp detection in endoscopic videos or images. Among all proposed algorithms, deep learning based methods take the lead in terms of multiple metrics in evolutions for algorithmic performance. In this work, a highly effective model, namely the faster region-based convolutional neural network (Faster R-CNN) is implemented for polyp detection. In comparison with the reported results of the state-of-the-art approaches on polyps detection, extensive experiments demonstrate that the Faster R-CNN achieves very competing results, and it is an efficient approach for clinical practice."
1809.01341,2018-09-07 18:13:10,Embedding Multimodal Relational Data for Knowledge Base Completion,"Pouya Pezeshkpour,Liyan Chen,Sameer Singh",https://arxiv.org/abs/1809.01341,    ,Published at EMNLP 2018,cs.AI,"cs.AI,cs.CL,stat.ML","Representing entities and relations in an embedding space is a well-studied approach for  machine learning  on relational data. Existing approaches, however, primarily focus on simple link structure between a finite set of entities, ignoring the variety of data types that are often used in knowledge bases, such as text, images, and numerical values. In this paper, we propose multimodal knowledge base embeddings (MKBE) that use different neural encoders for this variety of observed data, and combine them with existing relational models to learn embeddings of the entities and multimodal data. Further, using these learned embedings and different neural decoders, we introduce a novel multimodal imputation model to generate missing multimodal values, like text and images, from information in the knowledge base. We enrich existing relational datasets to create two novel benchmarks that contain additional information such as textual descriptions and images of the original entities. We demonstrate that our models utilize this additional information effectively to provide more accurate link prediction, achieving state-of-the-art results with a considerable gap of 5-7% over existing methods. Further, we evaluate the quality of our generated multimodal values via a user study. We have release the datasets and the open-source implementation of our models at https://github.com/pouyapez/mkbe"
1809.01316,2018-09-05 04:15:13,Learning User Preferences and Understanding Calendar Contexts for Event Scheduling,"Donghyeon Kim,Jinhyuk Lee,Donghee Choi,Jaehoon Choi,Jaewoo Kang",https://arxiv.org/abs/1809.01316,"          68T50; 68U35
        

        
      ",Accepted by CIKM 2018,cs.LG,"cs.LG,cs.CL,stat.ML","With online calendar services gaining popularity worldwide, calendar data has become one of the richest context sources for understanding human behavior. However, event scheduling is still time-consuming even with the development of online calendars. Although  machine learning  based event scheduling models have automated scheduling processes to some extent, they often fail to understand subtle user preferences and complex calendar contexts with event titles written in natural language. In this paper, we propose Neural Event Scheduling Assistant (NESA) which learns user preferences and understands calendar contexts, directly from raw online calendars for fully automated and highly effective event scheduling. We leverage over 593K calendar events for NESA to learn scheduling personal events, and we further utilize NESA for multi-attendee event scheduling. NESA successfully incorporates deep neural networks such as Bidirectional Long Short-Term Memory, Convolutional Neural Network, and Highway Network for learning the preferences of each user and understanding calendar context based on natural languages. The experimental results show that NESA significantly outperforms previous baseline models in terms of various evaluation metrics on both personal and multi-attendee event scheduling tasks. Our qualitative analysis demonstrates the effectiveness of each layer in NESA and learned user preferences."
1809.01357,2018-09-05 07:13:30,Zero Shot Learning for Code Education: Rubric Sampling with Deep Learning Inference,"Mike Wu,Milan Mosse,Noah Goodman,Chris Piech",https://arxiv.org/abs/1809.01357,    ,8 pages,cs.LG,"cs.LG,cs.CY,stat.ML","In modern computer science education, massive open online courses (MOOCs) log thousands of hours of data about how students solve coding challenges. Being so rich in data, these platforms have garnered the interest of the  machine learning  community, with many new algorithms attempting to autonomously provide feedback to help future students learn. But what about those first hundred thousand students? In most educational contexts (i.e. classrooms), assignments do not have enough historical data for supervised learning. In this paper, we introduce a human-in-the-loop ""rubric sampling"" approach to tackle the ""zero shot"" feedback challenge. We are able to provide autonomous feedback for the first students working on an introductory programming assignment with accuracy that substantially outperforms data-hungry algorithms and approaches human level fidelity. Rubric sampling requires minimal teacher effort, can associate feedback with specific parts of a student's solution and can articulate a student's misconceptions in the language of the instructor. Deep learning inference enables rubric sampling to further improve as more assignment specific student data is acquired. We demonstrate our results on a novel dataset from Code.org, the world's largest programming education platform."
1809.01410,2018-09-06 09:39:44,Generating Highly Realistic Images of Skin Lesions with GANs,"Christoph Baur,Shadi Albarqouni,Nassir Navab",https://arxiv.org/abs/1809.01410,    ,Accepted at the MICCAI 2018 ISIC Skin Lesion Workshop,cs.CV,"cs.CV,eess.IV","As many other  machine learning  driven medical image analysis tasks, skin image analysis suffers from a chronic lack of labeled data and skewed class distributions, which poses problems for the training of robust and well-generalizing models. The ability to synthesize realistic looking images of skin lesions could act as a reliever for the aforementioned problems. Generative Adversarial Networks (GANs) have been successfully used to synthesize realistically looking medical images, however limited to low resolution, whereas  machine learning  models for challenging tasks such as skin lesion segmentation or classification benefit from much higher resolution data. In this work, we successfully synthesize realistically looking images of skin lesions with GANs at such high resolution. Therefore, we utilize the concept of progressive growing, which we both quantitatively and qualitatively compare to other GAN architectures such as the DCGAN and the LAPGAN. Our results show that with the help of progressive growing, we can synthesize highly realistic dermoscopic images of skin lesions that even expert dermatologists find hard to distinguish from real ones."
1809.02386,2018-09-07 10:08:01,A geometrical description of global dynamics in trained feedback networks,"Francesca Mastrogiuseppe,Srdjan Ostojic",https://arxiv.org/abs/1809.02386,,,q-bio.NC,q-bio.NC,"Recurrent neural networks have been extensively studied in the context of neuroscience and  machine learning  due to their ability to implement complex computations. While substantial progress in designing effective learning algorithms has been achieved in the last years, a full understanding of trained recurrent networks is still lacking. Specifically, the mechanisms that allow computations to emerge from the underlying recurrent dynamics are largely unknown. Here we focus on a simple, yet underexplored computational setup: a feedback architecture trained to associate a stationary output to a stationary input. By deriving an approximate mean-field description of the global network dynamics, we show that this task admits several classes of solutions, characterized by different stability properties. These classes of solutions differ in the geometrical arrangement of the readout with respect to the input vectors, defined in the high-dimensional space spanned by the network population. We show that our theoretical approach can be used to understand how standard training techniques implement the input-output task in finite-size feedback networks. In particular, our approximate description captures the local and the global stability properties of the target solution, and predicts training performance."
1809.02547,2018-09-07 15:46:43,,"Daniel Klaewer,Lorenz Schlechter",https://arxiv.org/abs/1809.02547,"          MPP-2018-222
        

        

        
      ","8 pages, 6 figures, 5 tables",hep-th,hep-th,"Different techniques form  machine learning  are applied to the problem of computing line bundle cohomologies of (hypersurfaces in) toric varieties. While a naive approach of training a neural net- work to reproduce the cohomologies fails in the general case, by inspecting the underlying functional form of the data we propose a second approach. The cohomologies depend in a piecewise polynomial way on the line bundle charges. We use an unsupervised neural network to separate the different polynomial phases. The result is an analytic formula for the cohomologies. This can be turned into an algorithm for computing analytic expressions for arbitrary (hypersurfaces in) toric varieties."
1809.02479,2018-09-07 13:56:06,Convolutional Neural Network: Text Classification Model for Open Domain Question Answering System,"Muhammad Zain Amin,Noman Nadeem",https://arxiv.org/abs/1809.02479,    ,"11 pages,5 figures, An approved research report from Wavy Artificial Intelligence Research Foundation on Topics in ",cs.IR,cs.IR,"Recently  machine learning  is being applied to almost every data domain one of which is Question Answering Systems (QAS). A typical Question Answering System is fairly an information retrieval system, which matches documents or text and retrieve the most accurate one. The idea of open domain question answering system put forth, involves convolutional neural network text classifiers. The Classification model presented in this paper is multi-class text classifier. The neural network classifier can be trained on large dataset. We report series of experiments conducted on Convolution Neural Network (CNN) by training it on two different datasets. Neural network model is trained on top of word embedding. Softmax layer is applied to calculate loss and mapping of semantically related words. Gathered results can help justify the fact that proposed hypothetical QAS is feasible. We further propose a method to integrate Convolutional Neural Network Classifier to an open domain question answering system. The idea of Open domain will be further explained, but the generality of it indicates to the system of domain specific trainable models, thus making it an open domain."
1809.02403,2018-09-07 11:13:44,Deep Recurrent Survival Analysis,"Kan Ren,Jiarui Qin,Lei Zheng,Zhengyu Yang,Weinan Zhang,Lin Qiu,Yong Yu",https://arxiv.org/abs/1809.02403,,,cs.LG,"cs.LG,stat.ML","Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to  machine learning  models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at fine-grained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the non-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three real-world tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics."
1809.02591,2018-09-07 17:32:19,Learning Invariances for Policy Generalization,"Remi Tachet des Combes,Philip Bachman,Harm van Seijen",https://arxiv.org/abs/1809.02591,    ,"7 pages, 1 figure",cs.LG,"cs.LG,cs.AI,stat.ML","While recent progress has spawned very powerful  machine learning  systems, those agents remain extremely specialized and fail to transfer the knowledge they gain to similar yet unseen tasks. In this paper, we study a simple reinforcement learning problem and focus on learning policies that encode the proper invariances for generalization to different settings. We evaluate three potential methods for policy generalization: data augmentation, meta-learning and adversarial training. We find our data augmentation method to be effective, and study the potential of meta-learning and adversarial learning as alternative task-agnostic approaches.
  Keywords: reinforcement learning, generalization, data augmentation, meta-learning, adversarial learning."
1809.02397,2018-09-07 10:39:47,Detecting Potential Local Adversarial Examples for Human-Interpretable Defense,"Xavier Renard,Thibault Laugel,Marie-Jeanne Lesot,Christophe Marsala,Marcin Detyniecki",https://arxiv.org/abs/1809.02397,    ,presented at 2018 ECML/PKDD Workshop on Recent Advances in Adversarial ,stat.ML,"stat.ML,cs.CR,cs.LG","machine learning  models are increasingly used in the industry to make decisions such as credit insurance approval. Some people may be tempted to manipulate specific variables, such as the age or the salary, in order to get better chances of approval. In this ongoing work, we propose to discuss, with a first proposition, the issue of detecting a potential local adversarial example on classical tabular data by providing to a human expert the locally critical features for the classifier's decision, in order to control the provided information and avoid a fraud."
1809.02610,2018-09-01 22:10:45,,"Mouhammad Alkasassbeh,Mohammad Almseidin",https://arxiv.org/abs/1809.02610,    ,"ICCCNT 2018 - The 20th International Conference on Computing, Communication. arXiv admin note: substantial text overlap with arXiv:1805.10458",cs.NI,"cs.NI,cs.CR","Network security engineers work to keep services available all the time by handling intruder attacks. Intrusion Detection System (IDS) is one of the obtainable mechanisms that is used to sense and classify any abnormal actions. Therefore, the IDS must be always up to date with the latest intruder attacks signatures to preserve confidentiality, integrity, and availability of the services. The speed of the IDS is a very important issue as well learning the new attacks. This research work illustrates how the Knowledge Discovery and Data Mining (or Knowledge Discovery in Databases) KDD dataset is very handy for testing and evaluating different  machine learning  Techniques. It mainly focuses on the KDD preprocess part in order to prepare a decent and fair experimental data set. The J48, MLP, and Bayes Network classifiers have been chosen for this study. It has been proven that the J48 classifier has achieved the highest accuracy rate for detecting and classifying all KDD dataset attacks, which are of type DOS, R2L, U2R, and PROBE."
1809.02622,2018-09-07 18:04:32,Quantum algorithm for non-homogeneous linear partial differential equations,"Juan Miguel Arrazola,Timjan Kalajdzievski,Christian Weedbrook,Seth Lloyd",https://arxiv.org/abs/1809.02622,    ,"9 pages, 6 figures",quant-ph,quant-ph,"We describe a quantum algorithm for preparing states that encode solutions of non-homogeneous linear partial differential equations. The algorithm is a continuous-variable version of matrix inversion: it efficiently inverts differential operators that are polynomials in the variables and their partial derivatives. The output is a quantum state whose wavefunction is proportional to a specific solution of the non-homogeneous differential equation, which can be measured to reveal features of the solution. The algorithm consists of three stages: preparing fixed resource states in ancillary systems, performing Hamiltonian simulation, and measuring the ancilla systems. The algorithm can be carried out using standard methods for gate decompositions, but we improve this in two ways. First, we show that for a wide class of differential operators, it is possible to derive exact decompositions for the gates employed in Hamiltonian simulation. This avoids the need for costly commutator approximations, reducing gate counts by orders of magnitude. Additionally, we employ methods from  machine learning  to find explicit circuits that prepare the required resource states. We conclude by studying an example application of the algorithm: solving Poisson's equation in electrostatics."
1809.02611,2018-09-04 11:29:31,Exploiting SNMP-MIB Data to Detect Network Anomalies using,"Ghazi Al-Naymat,Mouhammd Al-kasassbeh,Eshraq Al-Hawari",https://arxiv.org/abs/1809.02611,"        Intelligent Systems Conference 2018
      ",7,cs.NI,cs.NI,"The exponential increase in the number of malicious threats on computer networks and Internet services due to a large number of attacks makes the network security at continuous risk. One of the most prevalent network attacks that threaten networks is Denial of Service (DoS) flooding attack. DoS attacks have recently become the most attractive type of attacks to attackers and these have posed devastating threats to network services. So, there is a need for effective approaches, which can efficiently detect any intrusion in the network. This paper presents an efficient mechanism for network attacks detection and types of attack classification using the Management Information Base (MIB) database associated with the Simple Network Management Protocol (SNMP) through  machine learning  techniques. This paper also investigates the impact of SNMP-MIB data on network anomalies detection. Three classifiers, namely, Random Forest, AdaboostM1 and MLP are used to build the detection model. The use of different classifiers presents a comprehensive study on the effectiveness of SNMP-MIB data in detecting different types of attack. Empirical results show that the  machine learning  techniques were quite successful in detecting and classifying the attacks with a high detection rate."
1809.02673,2018-09-07 21:06:11,Migration as Submodular Optimization,"Paul Gölz,Ariel D. Procaccia",https://arxiv.org/abs/1809.02673,    ,Simulation code is available at https://github.com/pgoelz/migration/,cs.GT,cs.GT,"Migration presents sweeping societal challenges that have recently attracted significant attention from the scientific community. One of the prominent approaches that have been suggested employs optimization and  machine learning  to match migrants to localities in a way that maximizes the expected number of migrants who find employment. However, it relies on a strong additivity assumption that, we argue, does not hold in practice, due to competition effects; we propose to enhance the data-driven approach by explicitly optimizing for these effects. Specifically, we cast our problem as the maximization of an approximately submodular function subject to matroid constraints, and prove that the worst-case guarantees given by the classic greedy algorithm extend to this setting. We then present three different models for competition effects, and show that they all give rise to submodular objectives. Finally, we demonstrate via simulations that our approach leads to significant gains across the board."
1809.02727,2018-09-12 23:21:35,Decentralized Differentially Private Without-Replacement Stochastic Gradient Descent,"Richeng Jin,Xiaofan He,Huaiyu Dai",https://arxiv.org/abs/1809.02727,    ,The Abstract is revised,cs.LG,"cs.LG,stat.ML","While  machine learning  has achieved remarkable results in a wide variety of domains, the training of models often requires large datasets that may need to be collected from different individuals. As sensitive information may be contained in the individual's dataset, sharing training data may lead to severe privacy concerns. Therefore, there is a compelling need to develop privacy-aware  machine learning  methods, for which one effective approach is to leverage the generic framework of differential privacy. Considering that stochastic gradient descent (SGD) is one of the mostly adopted methods for large-scale  machine learning  problems, two decentralized differentially private SGD algorithms are proposed in this work. Particularly, we focus on SGD without replacement due to its favorable structure for practical implementation. In addition, both privacy and convergence analysis are provided for the proposed algorithms. Finally, extensive experiments are performed to verify the theoretical results and demonstrate the effectiveness of the proposed algorithms."
1809.02786,2018-09-08 10:26:50,Structure-Preserving Transformation: Generating Diverse and Transferable Adversarial Examples,"Dan Peng,Zizhan Zheng,Xiaofeng Zhang",https://arxiv.org/abs/1809.02786,,,cs.LG,"cs.LG,cs.AI,cs.CR,cs.CV,stat.ML","Adversarial examples are perturbed inputs designed to fool  machine learning  models. Most recent works on adversarial examples for image classification focus on directly modifying pixels with minor perturbations. A common requirement in all these works is that the malicious perturbations should be small enough (measured by an $L_p$ norm for some $p$) so that they are imperceptible to humans. However, small perturbations can be unnecessarily restrictive and limit the diversity of adversarial examples generated. Further, an $L_p$ norm based distance metric ignores important structure patterns hidden in images that are important to human perception. Consequently, even the minor perturbation introduced in recent works often makes the adversarial examples less natural to humans. More importantly, they often do not transfer well and are therefore less effective when attacking black-box models especially for those protected by a defense mechanism. In this paper, we propose a structure-preserving transformation (SPT) for generating natural and diverse adversarial examples with extremely high transferability. The key idea of our approach is to allow perceptible deviation in adversarial examples while keeping structure patterns that are central to a human classifier. Empirical results on the MNIST and the fashion-MNIST datasets show that adversarial examples generated by our approach can easily bypass strong adversarial training. Further, they transfer well to other target models with no loss or little loss of successful attack rate."
1809.02723,2018-09-08 00:17:56,Deep Neural Network Computes Electron Densities and Energies of a Large Set of Organic Molecules Faster than Density Functional Theory (DFT),"Anton V. Sinitskiy,Vijay S. Pande",https://arxiv.org/abs/1809.02723,,,physics.chem-ph,"physics.chem-ph,physics.comp-ph","Density functional theory (DFT) is one of the main methods in Quantum Chemistry that offers an attractive trade off between the cost and accuracy of quantum chemical computations. The electron density plays a key role in DFT. In this work, we explore whether  machine learning  - more specifically, deep neural networks (DNNs) - can be trained to predict electron densities faster than DFT. First, we choose a practically efficient combination of a DFT functional and a basis set (PBE0/pcS-3) and use it to generate a database of DFT solutions for more than 133,000 organic molecules from a previously published database QM9. Next, we train a DNN to predict electron densities and energies of such molecules. The only input to the DNN is an approximate electron density computed with a cheap quantum chemical method in a small basis set (HF/cc-VDZ). We demonstrate that the DNN successfully learns differences in the electron densities arising both from electron correlation and small basis set artifacts in the HF computations. All qualitative features in density differences, including local minima on lone pairs, local maxima on nuclei, toroidal shapes around C-H and C-C bonds, complex shapes around aromatic and cyclopropane rings and CN group, etc. are captured by the DNN. Accuracy of energy predictions by the DNN is ~ 1 kcal/mol, on par with other models reported in the literature, while those models do not predict the electron density. Computations with the DNN, including HF computations, take much less time that DFT computations (by a factor of ~20-30 for most QM9 molecules in the current version, and it is clear how it could be further improved)."
1809.02797,2018-09-08 13:08:26,Fast Gradient Attack on Network Embedding,"Jinyin Chen,Yangyang Wu,Xuanheng Xu,Yixian Chen,Haibin Zheng,Qi Xuan",https://arxiv.org/abs/1809.02797,,,physics.soc-ph,"physics.soc-ph,cs.SI","Network embedding maps a network into a low-dimensional Euclidean space, and thus facilitate many network analysis tasks, such as node classification, link prediction and community detection etc, by utilizing  machine learning  methods. In social networks, we may pay special attention to user privacy, and would like to prevent some target nodes from being identified by such network analysis methods in certain cases. Inspired by successful adversarial attack on deep learning models, we propose a framework to generate adversarial networks based on the gradient information in Graph Convolutional Network (GCN). In particular, we extract the gradient of pairwise nodes based on the adversarial network, and select the pair of nodes with maximum absolute gradient to realize the Fast Gradient Attack (FGA) and update the adversarial network. This process is implemented iteratively and terminated until certain condition is satisfied, i.e., the number of modified links reaches certain predefined value. Comprehensive attacks, including unlimited attack, direct attack and indirect attack, are performed on six well-known network embedding methods. The experiments on real-world networks suggest that our proposed FGA behaves better than some baseline methods, i.e., the network embedding can be easily disturbed using FGA by only rewiring few links, achieving state-of-the-art attack performance."
1809.02823,2018-09-08 15:29:47,Extracting and Analyzing Semantic Relatedness between Cities Using News Articles,"Yingjie Hu,Xinyue Ye,Shih-Lung Shaw",https://arxiv.org/abs/1809.02823,    ,"International Journal of Geographical Information Science, 2017",cs.SI,"cs.SI,cs.CL","News articles capture a variety of topics about our society. They reflect not only the socioeconomic activities that happened in our physical world, but also some of the cultures, human interests, and public concerns that exist only in the perceptions of people. Cities are frequently mentioned in news articles, and two or more cities may co-occur in the same article. Such co-occurrence often suggests certain relatedness between the mentioned cities, and the relatedness may be under different topics depending on the contents of the news articles. We consider the relatedness under different topics as semantic relatedness. By reading news articles, one can grasp the general semantic relatedness between cities, yet, given hundreds of thousands of news articles, it is very difficult, if not impossible, for anyone to manually read them. This paper proposes a computational framework which can ""read"" a large number of news articles and extract the semantic relatedness between cities. This framework is based on a natural language processing model and employs a  machine learning  process to identify the main topics of news articles. We describe the overall structure of this framework and its individual modules, and then apply it to an experimental dataset with more than 500,000 news articles covering the top 100 U.S. cities spanning a 10-year period. We perform exploratory visualization of the extracted semantic relatedness under different topics and over multiple years. We also analyze the impact of geographic distance on semantic relatedness and find varied distance decay effects. The proposed framework can be used to support large-scale content analysis in city network research."
1809.02849,2018-09-08 18:14:29,Context-dependent architecture of brain state dynamics is explained by white matter connectivity and theories of network control,"Eli J. Cornblath,Arian Ashourvan,Jason Z. Kim,Richard F. Betzel,Rastko Ciric,Graham L. Baum,Xiaosong He,Kosha Ruparel,Tyler M. Moore,Ruben C. Gur,Raquel E. Gur,Russell T. Shinohara,David R. Roalf,Theodore D. Satterthwaite,Danielle S. Bassett",https://arxiv.org/abs/1809.02849,,,q-bio.NC,q-bio.NC,"A diverse white matter network and finely tuned neuronal membrane properties allow the brain to transition seamlessly between cognitive states. However, it remains unclear how static structural connections guide the temporal progression of large-scale brain activity patterns in different cogni- tive states. Here, we deploy an unsupervised  machine learning  algorithm to define brain states as time point level activity patterns from functional magnetic resonance imaging data acquired dur- ing passive visual fixation (rest) and an n-back working memory task. We find that brain states are composed of interdigitated functional networks and exhibit context-dependent dynamics. Using diffusion-weighted imaging acquired from the same subjects, we show that structural connectivity constrains the temporal progression of brain states. We also combine tools from network control theory with geometrically conservative null models to demonstrate that brains are wired to sup- port states of high activity in default mode areas, while requiring relatively low energy. Finally, we show that brain state dynamics change throughout development and explain working mem- ory performance. Overall, these results elucidate the structural underpinnings of cognitively and developmentally relevant spatiotemporal brain dynamics."
1809.02861,2018-09-08 19:44:47,"On the Intriguing Connections of Regularization, Input Gradients and Transferability of Evasion and Poisoning Attacks","Ambra Demontis,Marco Melis,Maura Pintor,Matthew Jagielski,Battista Biggio,Alina Oprea,Cristina Nita-Rotaru,Fabio Roli",https://arxiv.org/abs/1809.02861,"          68T10; 68T45
        

        
      ",,cs.LG,"cs.LG,cs.CR,stat.ML","Transferability captures the ability of an attack against a  -  model to be effective against a different, potentially unknown, model. Studying transferability of attacks has gained interest in the last years due to the deployment of cyber-attack detection services based on  machine learning . For these applications of  machine learning , service providers avoid disclosing information about their  -  algorithms. As a result, attackers trying to bypass detection are forced to craft their attacks against a surrogate model instead of the actual target model used by the service. While previous work has shown that finding test-time transferable attack samples is possible, it is not well understood how an attacker may construct adversarial examples that are likely to transfer against different models, in particular in the case of training-time poisoning attacks. In this paper, we present the first empirical analysis aimed to investigate the transferability of both test-time evasion and training-time poisoning attacks. We provide a unifying, formal definition of transferability of such attacks and show how it relates to the input gradients of the surrogate and of the target classification models. We assess to which extent some of the most well-known  -  systems are vulnerable to transfer attacks, and explain why such attacks succeed (or not) across different models. To this end, we leverage some interesting connections highlighted in this work among the adversarial vulnerability of  -  models, their regularization hyperparameters and input gradients."
1809.02996,2018-09-09 16:01:16,Seeing Permeability From Images: Fast Prediction with Convolutional Neural Networks,"Jin-Long Wu,Xiao-Long Yin,Heng Xiao",https://arxiv.org/abs/1809.02996,"          76S05
        

        
      ","17 pages, 8 figures",physics.comp-ph,physics.comp-ph,"Fast prediction of permeability directly from images enabled by image recognition neural networks is a novel pore-scale modeling method that has a great potential. This article presents a framework that includes (1) generation of porous media samples, (2) computation of permeability via fluid dynamics simulations, (3) training of convolutional neural networks (CNN) with simulated data, and (4) validations against simulations. Comparison of  machine learning  results and the ground truths suggests excellent predictive performance across a wide range of porosities and pore geometries, especially for those with dilated pores. Owning to such heterogeneity, the permeability cannot be estimated using the conventional Kozeny-Carman approach. Computational time was reduced by several orders of magnitude compared to fluid dynamic simulations. We found that, by including physical parameters that are known to affect permeability into the neural network, the physics-informed CNN generated better results than regular CNN, however improvements vary with implemented heterogeneity."
1809.03006,2018-09-09 16:58:33,Performance Metrics (Error Measures) in,Alexei Botchkarev,https://arxiv.org/abs/1809.03006,,,stat.ME,"stat.ME,cs.LG,stat.ML","Performance metrics (error measures) are vital components of the evaluation frameworks in various fields. The intention of this study was to overview of a variety of performance metrics and approaches to their classification. The main goal of the study was to develop a typology that will help to improve our knowledge and understanding of metrics and facilitate their selection in  machine learning  regression, forecasting and prognostics. Based on the analysis of the structure of numerous performance metrics, we propose a framework of metrics which includes four (4) categories: primary metrics, extended metrics, composite metrics, and hybrid sets of metrics. The paper identified three (3) key components (dimensions) that determine the structure and properties of primary metrics: method of determining point distance, method of normalization, method of aggregation of point distances over a data set."
1809.03062,2018-09-09 23:50:37,Analysis of the generalization error: Empirical risk minimization over deep artificial neural networks overcomes the curse of dimensionality in the numerical approximation of Black-Scholes partial differential equations,"Julius Berner,Philipp Grohs,Arnulf Jentzen",https://arxiv.org/abs/1809.03062,,,cs.LG,"cs.LG,math.NA,stat.ML","The development of new classification and regression algorithms based on empirical risk minimization (ERM) over deep neural network hypothesis classes, coined Deep Learning, revolutionized the area of artificial intelligence,  machine learning , and data analysis. More recently, these methods have been applied to the numerical solution of high dimensional PDEs with great success. In particular, recent simulations indicate that deep learning based algorithms are capable of overcoming the curse of dimensionality for the numerical solution of linear Kolmogorov PDEs. Kolmogorov PDEs have been widely used in models from engineering, finance, and the natural sciences. Nearly all approximation methods for Kolmogorov PDEs in the literature suffer under the curse of dimensionality. By contrast, in recent work by some of the authors it was shown that deep ReLU neural networks are capable of approximating solutions of Kolmogorov PDEs without incurring the curse of dimensionality. The present paper considerably strengthens these results by providing an analysis of the generalization error. In particular we show that for Kolmogorov PDEs with affine drift and diffusion coefficients and a given accuracy $\varepsilon>0$, ERM over deep neural network hypothesis classes of size scaling polynomially in the dimension $d$ and $\varepsilon^{-1}$ and with a number of training samples scaling polynomially in the dimension $d$ and $\varepsilon^{-1}$ approximates the solution of the Kolmogorov PDE to within accuracy $\varepsilon$ with high probability. We conclude that ERM over deep neural network hypothesis classes breaks the curse of dimensionality for the numerical solution of linear Kolmogorov PDEs with affine drift and diffusion coefficients. To the best of our knowledge this is the first rigorous mathematical result that proves the efficiency of deep learning methods for high dimensional problems."
1809.03043,2018-09-09 20:50:23,Fast Radio Burst 121102 Pulse Detection and Periodicity: A,"Yunfan Gerry Zhang,Vishal Gajjar,Griffin Foster,Andrew Siemion,James Cordes,Casey Law,Yu Wang",https://arxiv.org/abs/1809.03043,    ,"32 pages, 10 figures",astro-ph.HE,"astro-ph.HE,astro-ph.IM","We report the detection of 72 new pulses from the repeating fast radio burst FRB 121102 in Breakthrough Listen C-band (4-8 GHz) observations at the Green Bank Telescope. The new pulses were found with a convolutional neural network in data taken on August 26, 2017, where 21 bursts have been previously detected. Our technique combines neural network detection with dedispersion verification. For the current application we demonstrate its advantage over a traditional brute-force dedis- persion algorithm in terms of higher sensitivity, lower false positive rates, and faster computational speed. Together with the 21 previously reported pulses, this observa- tion marks the highest number of FRB 121102 pulses from a single observation, total- ing 93 pulses in five hours, including 45 pulses within the first 30 minutes. The number of data points reveal trends in pulse fluence, pulse detection rate, and pulse frequency structure. We introduce a new periodicity search technique, based on the Rayleigh test, to analyze the time of arrivals, with which we exclude with 99% confidence pe- riodicity in time of arrivals with periods larger than 5.1 times the model-dependent time-stamp uncertainty. In particular, we rule out constant periods >10 ms in the barycentric arrival times, though intrinsic periodicity in the time of emission remains plausible."
1809.03048,2018-09-09 22:04:15,Clustering of graph vertex subset via Krylov subspace model reduction,"Vladimir Druskin,Alexander V. Mamonov,Mikhail Zaslavsky",https://arxiv.org/abs/1809.03048,"          I.5.3
        
      ","24 pages, 9 figures",cs.LG,"cs.LG,stat.ML","Clustering via graph-Laplacian spectral imbedding is ubiquitous in data science and  machine learning . However, it becomes less efficient for large data sets due to two factors. First, computing the partial eigendecomposition of the graph-Laplacian typically requires a large Krylov subspace. Second, after the spectral imbedding is complete, the clustering is typically performed with various relaxations of k-means, which may become prone to getting stuck in local minima and scale poorly in terms of computational cost for large data sets. Here we propose two novel algorithms for spectral clustering of a subset of the graph vertices (target subset) based on the theory of model order reduction. They rely on realizations of a reduced order model (ROM) that accurately approximates the diffusion transfer function of the original graph for inputs and outputs restricted to the target subset. While our focus is limited to this subset, our algorithms produce its clustering that is consistent with the overall structure of the graph. Moreover, working with a small target subset reduces greatly the required dimension of Krylov subspace and allows to exploit the approximations of k-means in the regimes when they are most robust and efficient, as verified by the numerical experiments. There are several uses for our algorithms. First, they can be employed on their own to clusterize a representative subset in cases when the full graph clustering is either infeasible or not required. Second, they may be used for quality control. Third, as they drastically reduce the problem size, they enable the application of more powerful approximations of k-means like those based on semi-definite programming (SDP) instead of the conventional Lloyd's algorithm. Finally, they can be used as building blocks of a divide-and-conquer algorithm for the full graph clustering. The latter will be reported in a separate article."
1809.03063,2018-09-09 23:57:29,The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure,"Saeed Mahloujifar,Dimitrios I. Diochnos,Mohammad Mahmoody",https://arxiv.org/abs/1809.03063,,,cs.LG,"cs.LG,stat.ML","Many modern  machine learning  classifiers are shown to be vulnerable to adversarial perturbations of the instances that can ""evade"" the classifier and get misclassified. Despite a massive amount of work focusing on making classifiers robust, the task seems quite challenging. In this work, through a theoretical study, we investigate the adversarial risk and robustness of classifiers and draw a connection to the well-known phenomenon of ""concentration of measure"" in metric measure spaces. We show that if the metric probability space of the test instance is concentrated, any classifier with some initial constant error is inherently vulnerable to adversarial perturbations.
  One class of concentrated metric probability spaces are the so-called Levy families that include many natural distributions. In this special case, our attacks only need to perturb the test instance by at most $O(\sqrt n)$ to make it misclassified, where $n$ is the data dimension. Using our general result about Levy instance spaces, we first recover as special case some of the previously proved results about the existence of adversarial examples. However, many more Levy families are known for which we immediately obtain new attacks finding adversarial examples (e.g., product distribution under the Hamming distance).
  Finally, we show that concentration of measure for product spaces implies the existence of so called ""poisoning"" attacks in which the adversary tampers with the training data with the goal of increasing the error of the classifier. We show that for any deterministic learning algorithm that uses $m$ training examples, there is an adversary who substitutes $O(\sqrt m)$ of the examples with other (still correctly labeled) ones and can almost fully degrade the confidence parameter of any PAC learning algorithm or alternatively increase the risk to almost 1 if the adversary also knows the final test example."
1809.03124,2018-09-10 03:52:13,Approaching the adiabatic timescale with,"Bryce M. Henson,Dong K. Shin,Kieran F. Thomas,Jacob A. Ross,Michael R. Hush,Sean S. Hodgman,Andrew G. Truscott",https://arxiv.org/abs/1809.03124,    ,"7 pages main text, 2 pages supporting information",quant-ph,"quant-ph,cond-mat.quant-gas","The control and manipulation of quantum systems without excitation is challenging, due to the complexities in fully modeling such systems accurately and the difficulties in controlling these inherently fragile systems experimentally. For example, while protocols to decompress Bose-Einstein condensates (BEC) faster than the adiabatic timescale (without excitation or loss) have been well developed theoretically, experimental implementations of these protocols have yet to reach speeds faster than the adiabatic timescale. In this work, we experimentally demonstrate an alternative approach based on a  machine learning  algorithm which makes progress towards this goal. The algorithm is given control of the coupled decompression and transport of a metastable helium condensate, with its performance determined after each experimental iteration by measuring the excitations of the resultant BEC. After each iteration the algorithm adjusts its internal model of the system to create an improved control output for the next iteration. Given sufficient control over the decompression, the algorithm converges to a novel solution that sets the current speed record in relation to the adiabatic timescale, beating out other experimental realizations based on theoretical approaches. This method presents a feasible approach for implementing fast state preparations or transformations in other quantum systems, without requiring a solution to a theoretical model of the system. Implications for fundamental physics and cooling are discussed."
1809.03069,2018-09-10 00:39:24,Mobile Collaborative Spectrum Sensing for Heterogeneous Networks: A Bayesian,"Yizhen Xu,Peng Cheng,Zhuo Chen,Yonghui Li,Branka Vucetic",https://arxiv.org/abs/1809.03069,    ,to appear in IEEE Transactions on Signal Processing 2018,cs.IT,cs.IT,"Spectrum sensing in a large-scale heterogeneous network is very challenging as it usually requires a large number of static secondary users (SUs) to obtain the global spectrum states. To tackle this problem, in this paper, we propose a new framework based on Bayesian  machine learning . We exploit the mobility of multiple SUs to simultaneously collect spectrum sensing data, and cooperatively derive the global spectrum states. We first develop a novel non-parametric Bayesian learning model, referred to as beta process sticky hidden Markov model (BP-SHMM), to capture the spatial-temporal correlation in the collected spectrum data, where SHMM models the latent statistical correlation within each mobile SU's time series data, while BP realizes the cooperation among multiple SUs. Bayesian inference is then carried out to automatically infer the heterogeneous spectrum states. Based on the inference results, we also develop a new algorithm with a refinement mechanism to predict the spectrum availability, which enables a newly joining SU to immediately access the unoccupied frequency band without sensing. Simulation results show that the proposed framework can significantly improve spectrum sensing performance compared with the existing spectrum sensing techniques."
1809.04188,2018-09-13 02:31:51,Layerwise Perturbation-Based Adversarial Training for Hard Drive Health Degree Prediction,"Jianguo Zhang,Ji Wang,Lifang He,Zhao Li,Philip S. Yu",https://arxiv.org/abs/1809.04188,    ,The 2018 IEEE International Conference on Data Mining (ICDM'18),cs.LG,"cs.LG,stat.ML","With the development of cloud computing and big data, the reliability of data storage systems becomes increasingly important. Previous researchers have shown that  machine learning  algorithms based on SMART attributes are effective methods to predict hard drive failures. In this paper, we use SMART attributes to predict hard drive health degrees which are helpful for taking different fault tolerant actions in advance. Given the highly imbalanced SMART datasets, it is a nontrivial work to predict the health degree precisely. The proposed model would encounter overfitting and biased fitting problems if it is trained by the traditional methods. In order to resolve this problem, we propose two strategies to better utilize imbalanced data and improve performance. Firstly, we design a layerwise perturbation-based adversarial training method which can add perturbations to any layers of a neural network to improve the generalization of the network. Secondly, we extend the training method to the semi-supervised settings. Then, it is possible to utilize unlabeled data that have a potential of failure to further improve the performance of the model. Our extensive experiments on two real-world hard drive datasets demonstrate the superiority of the proposed schemes for both supervised and semi-supervised classification. The model trained by the proposed method can correctly predict the hard drive health status 5 and 15 days in advance. Finally, we verify the generality of the proposed training method in other similar anomaly detection tasks where the dataset is imbalanced. The results argue that the proposed methods are applicable to other domains."
1809.04184,2018-09-11 22:36:01,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction,"Liang-Chieh Chen,Maxwell D. Collins,Yukun Zhu,George Papandreou,Barret Zoph,Florian Schroff,Hartwig Adam,Jonathon Shlens",https://arxiv.org/abs/1809.04184,    ,Accepted by NIPS 2018,cs.CV,"cs.CV,cs.LG,stat.ML","The design of neural network architectures is an important component for achieving state-of-the-art performance with  machine learning  systems across a broad array of tasks. Much work has endeavored to design and build architectures automatically through clever construction of a search space paired with simple learning algorithms. Recent progress has demonstrated that such meta-learning methods may exceed scalable human-invented architectures on image classification tasks. An open question is the degree to which such methods may generalize to new domains. In this work we explore the construction of meta-learning techniques for dense image prediction focused on the tasks of scene parsing, person-part segmentation, and semantic image segmentation. Constructing viable search spaces in this domain is challenging because of the multi-scale representation of visual information and the necessity to operate on high resolution imagery. Based on a survey of techniques in dense image prediction, we construct a recursive search space and demonstrate that even with efficient random search, we can identify architectures that outperform human-invented architectures and achieve state-of-the-art performance on three dense prediction tasks including 82.7\% on Cityscapes (street scene parsing), 71.3\% on PASCAL-Person-Part (person-part segmentation), and 87.9\% on PASCAL VOC 2012 (semantic image segmentation). Additionally, the resulting architecture is more computationally efficient, requiring half the parameters and half the computational cost as previous state of the art systems."
1809.04216,2018-09-12 01:39:13,On Markov Chain Gradient Descent,"Tao Sun,Yuejiao Sun,Wotao Yin",https://arxiv.org/abs/1809.04216,,,math.OC,"math.OC,stat.ML","Stochastic gradient methods are the workhorse (algorithms) of large-scale optimization problems in  machine learning , signal processing, and other computational sciences and engineering. This paper studies Markov chain gradient descent, a variant of stochastic gradient descent where the random samples are taken on the trajectory of a Markov chain. Existing results of this method assume convex objectives and a reversible Markov chain and thus have their limitations. We establish new non-ergodic convergence under wider step sizes, for nonconvex problems, and for non-reversible finite-state Markov chains. Nonconvexity makes our method applicable to broader problem classes. Non-reversible finite-state Markov chains, on the other hand, can mix substatially faster. To obtain these results, we introduce a new technique that varies the mixing levels of the Markov chains. The reported numerical results validate our contributions."
1809.04249,2018-09-12 04:13:48,A Fast Globally Linearly Convergent Algorithm for the Computation of Wasserstein Barycenters,"Lei Yang,Jia Li,Defeng Sun,Kim-Chuan Toh",https://arxiv.org/abs/1809.04249,,,math.OC,"math.OC,stat.ML","In this paper, we consider the problem of computing a Wasserstein barycenter for a set of discrete probability distributions with finite supports, which finds many applications in different areas such as statistics,  machine learning  and image processing. When the support points of the barycenter are pre-specified, this problem can be modeled as a linear programming (LP), while the problem size can be extremely large. To handle this large-scale LP, in this paper, we derive its dual problem, which is conceivably more tractable and can be reformulated as a well-structured convex problem with 3 kinds of block variables and a coupling linear equality constraint. We then adapt a symmetric Gauss-Seidel based alternating direction method of multipliers (sGS-ADMM) to solve the resulting dual problem and analyze its global convergence as well as its global linear convergence rate. We also show how all the subproblems involved can be solved exactly and efficiently. This makes our method suitable for computing a Wasserstein barycenter on a large dataset. In addition, our sGS-ADMM can be used as a subroutine in an alternating minimization method to compute a barycenter when its support points are not pre-specified. Numerical results on synthetic datasets and image datasets demonstrate that our method is more efficient for solving large-scale problems, comparing with two existing representative methods and the commercial software Gurobi."
1809.04262,2018-09-12 05:44:23,Extracting Fairness Policies from Legal Documents,"Rashmi Nagpal,Chetna Wadhwa,Mallika Gupta,Samiulla Shaikh,Sameep Mehta,Vikram Goyal",https://arxiv.org/abs/1809.04262,,,cs.LG,"cs.LG,cs.IR,stat.ML","machine learning  community is recently exploring the implications of bias and fairness with respect to the AI applications. The definition of fairness for such applications varies based on their domain of application. The policies governing the use of such  machine learning  system in a given context are defined by the constitutional laws of nations and regulatory policies enforced by the organizations that are involved in the usage. Fairness related laws and policies are often spread across the large documents like constitution, agreements, and organizational regulations. These legal documents have long complex sentences in order to achieve rigorousness and robustness. Automatic extraction of fairness policies, or in general, any specific kind of policies from large legal corpus can be very useful for the study of bias and fairness in the context of AI applications.
  We attempted to automatically extract fairness policies from publicly available law documents using two approaches based on semantic relatedness. The experiments reveal how classical Wordnet-based similarity and vector-based similarity differ in addressing this task. We have shown that similarity based on word vectors beats the classical approach with a large margin, whereas other vector representations of senses and sentences fail to even match the classical baseline. Further, we have presented thorough error analysis and reasoning to explain the results with appropriate examples from the dataset for deeper insights."
1809.04198,2018-09-11 23:41:47,"Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals","Andrew Cotter,Heinrich Jiang,Serena Wang,Taman Narayan,Maya Gupta,Seungil You,Karthik Sridharan",https://arxiv.org/abs/1809.04198,,,cs.LG,"cs.LG,cs.AI,cs.GT,math.OC,stat.ML","We show that many  machine learning  goals, such as improved fairness metrics, can be expressed as constraints on the model's predictions, which we call rate constraints. We study the problem of training non-convex models subject to these rate constraints (or any non-convex and non-differentiable constraints). In the non-convex setting, the standard approach of Lagrange multipliers may fail. Furthermore, if the constraints are non-differentiable, then one cannot optimize the Lagrangian with gradient-based methods. To solve these issues, we introduce the proxy-Lagrangian formulation. This new formulation leads to an algorithm that produces a stochastic classifier by playing a two-player non-zero-sum game solving for what we call a semi-coarse correlated equilibrium, which in turn corresponds to an approximately optimal and feasible solution to the constrained optimization problem. We then give a procedure which shrinks the randomized solution down to one that is a mixture of at most $m+1$ deterministic solutions, given $m$ constraints. This culminates in algorithms that can solve non-convex constrained optimization problems with possibly non-differentiable and non-convex constraints with theoretical guarantees. We provide extensive experimental results enforcing a wide range of policy goals including different fairness metrics, and other goals on accuracy, coverage, recall, and churn."
1809.04332,2018-09-12 09:38:47,Deep Learning in Information Security,"Stefan Thaler,Vlado Menkovski,Milan Petkovic",https://arxiv.org/abs/1809.04332,,,cs.CR,"cs.CR,cs.LG","machine learning  has a long tradition of helping to solve complex information security problems that are difficult to solve manually.  machine learning  techniques learn models from data representations to solve a task. These data representations are hand-crafted by domain experts. Deep Learning is a sub-field of  machine learning , which uses models that are composed of multiple layers. Consequently, representations that are used to solve a task are learned from the data instead of being manually designed.
  In this survey, we study the use of DL techniques within the domain of information security. We systematically reviewed 77 papers and presented them from a data-centric perspective. This data-centric perspective reflects one of the most crucial advantages of DL techniques -- domain independence. If DL-methods succeed to solve problems on a data type in one domain, they most likely will also succeed on similar data from another domain. Other advantages of DL methods are unrivaled scalability and efficiency, both regarding the number of examples that can be analyzed as well as with respect of dimensionality of the input data. DL methods generally are capable of achieving high-performance and generalize well.
  However, information security is a domain with unique requirements and challenges. Based on an analysis of our reviewed papers, we point out shortcomings of DL-methods to those requirements and discuss further research opportunities."
1809.04334,2018-09-12 09:51:42,Blind prediction of protein B-factor and flexibility,"David Bramer,Guo-Wei Wei",https://arxiv.org/abs/1809.04334,"        Journal of Chemical Physics, 2018
      ","5 figures, 23 pages",q-bio.BM,"q-bio.BM,q-bio.QM","Debye-Waller factor, a measure of X-ray attenuation, can be experimentally observed in protein X-ray crystallography. Previous theoretical models have made strong inroads in the analysis of B-factors by linearly fitting protein B-factors from experimental data. However, the blind prediction of B-factors for unknown proteins is an unsolved problem. This work integrates  machine learning  and advanced graph theory, namely, multiscale weighted colored graphs (MWCGs), to blindly predict B-factors of unknown proteins. MWCGs are local features that measure the intrinsic flexibility due to a protein structure. Global features that connect the B-factors of different proteins, e.g., the resolution of X-ray crystallography, are introduced to enable the cross-protein B-factor predictions. Several  machine learning  approaches, including ensemble methods and deep learning, are considered in the present work. The proposed method is validated with hundreds of thousands of experimental B-factors. Extensive numerical results indicate that the blind B-factor predictions obtained from the present method are more accurate than the least squares fittings using traditional methods."
1809.04392,2018-09-12 12:56:43,,Juan Rojo,https://arxiv.org/abs/1809.04392,    ,"12 pages, 9 figures, to appear in the proceedings of the XXIIIth Quark Confinement and the Hadron Spectrum conference, 1-6 August 2018, University of Maynooth, Ireland",hep-ph,hep-ph,"The use of  machine learning  algorithms in theoretical and experimental high-energy physics has experienced an impressive progress in recent years, with applications from trigger selection to jet substructure classification and detector simulation among many others. In this contribution, we review the  machine learning  tools used in the NNPDF family of global QCD analyses. These include multi-layer feed-forward neural networks for the model-independent parametrisation of parton distributions and fragmentation functions, genetic and covariance matrix adaptation algorithms for training and optimisation, and closure testing for the systematic validation of the fitting methodology."
1809.04507,2018-09-12 15:13:44,Investigating the generalizability of EEG-based Cognitive Load Estimation Across Visualizations,"Viral Parekh,Maneesh Bilalpur,Sharavan Kumar,Stefan Winkler,C V Jawahar,Ramanathan Subramanian",https://arxiv.org/abs/1809.04507,,,cs.HC,cs.HC,"We examine if EEG-based cognitive load (CL) estimation is generalizable across the character, spatial pattern, bar graph and pie chart-based visualizations for the nback~task. CL is estimated via two recent approaches: (a) Deep convolutional neural network, and (b) Proximal support vector machines. Experiments reveal that CL estimation suffers across visualizations motivating the need for effective  machine learning  techniques to benchmark visual interface usability for a given analytic task."
1809.04404,2018-09-12 13:15:48,Reconstruction of the Real Quantum Channel via Convex Optimization,"Xuan-Lun Huang,Jun Gao,Zhi-Qiang Jiao,Zeng-Quan Yan,Ling Ji,Xian-Min Jin",https://arxiv.org/abs/1809.04404,    ,"5 pages, 3 figures, 1 table",quant-ph,quant-ph,"Quantum process tomography is often used to completely characterize an unknown quantum process. However, it may lead to an unphysical process matrix, which will cause the loss of information respect to the tomography result. Convex optimization, widely used in  machine learning , is able to generate a global optimal model that best fits the raw data while keeping the process tomography in a legitimate region. Only by correctly revealing the original action of the process can we seek deeper into its properties like its phase transition and its Hamiltonian. Thus, we reconstruct the real quantum channel using convex optimization from our experimental result obtained in free-space seawater. In addition, we also put forward a criteria, state deviation, to evaluate how well the reconstructed process fits the tomography result. We believe that the crossover between quantum process tomography and convex optimization may help us move forward to  machine learning  of quantum channels."
1809.04432,2018-09-10 20:04:59,Addressing the Fundamental Tension of PCGML with Discriminative Learning,"Isaac Karth,Adam M. Smith",https://arxiv.org/abs/1809.04432,,,cs.LG,"cs.LG,stat.ML","Procedural content generation via  machine learning  (PCGML) is typically framed as the task of fitting a generative model to full-scale examples of a desired content distribution. This approach presents a fundamental tension: the more design effort expended to produce detailed training examples for shaping a generator, the lower the return on investment from applying PCGML in the first place. In response, we propose the use of discriminative models (which capture the validity of a design rather the distribution of the content) trained on positive and negative examples. Through a modest modification of WaveFunctionCollapse, a commercially-adopted PCG approach that we characterize as using elementary  machine learning , we demonstrate a new mode of control for learning-based generators. We demonstrate how an artist might craft a focused set of additional positive and negative examples by critique of the generator's previous outputs. This interaction mode bridges PCGML with mixed-initiative design assistance tools by working with a machine to define a space of valid designs rather than just one new design."
1809.04365,2018-09-12 11:41:05,NNCP: A citation count prediction methodology based on deep neural network learning techniques,"Ali Abrishami,Sadegh Aliakbary",https://arxiv.org/abs/1809.04365,,,cs.DL,"cs.DL,cs.LG,cs.SI","With the growing number of published scientific papers world-wide, the need to evaluation and quality assessment methods for research papers is increasing. Scientific fields such as scientometrics, informetrics and bibliometrics establish quantified analysis methods and measurements for scientific papers. In this area, an important problem is to predict the future influence of a published paper. Particularly, early discrimination between influential papers and insignificant papers may find important applications. In this regard, one of the most important metrics is the number of citations to the paper, since this metric is widely utilized in the evaluation of scientific publications and moreover, it serves as the basis for many other metrics such as h-index. In this paper, we propose a novel method for predicting long-term citations of a paper based on the number of its citations in the first few years after publication. In order to train a citations prediction model, we employed artificial neural networks which is a powerful  machine learning  tool with recently growing applications in many domains including image and text processing. The empirical experiments show that our proposed method out-performs state-of-the-art methods with respect to the prediction accuracy in both yearly and total prediction of the number of citations."
